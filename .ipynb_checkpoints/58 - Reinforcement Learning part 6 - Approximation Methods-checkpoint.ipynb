{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we'll be introducing the next notebook of this serie, which is all about approximation methods\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Approximation Methods notebook Introduction</h3>\n",
    "\n",
    "Previously in this series, we've studied reinforcement learning in the tabular case\n",
    "\n",
    "The state value $V(s)$ and the action value $Q(s,a)$, were always tables\n",
    "\n",
    "The key requirement for this was that the states and actions were both discrete and finite\n",
    "\n",
    "This is why Grid World is such a nice environment to hone our reinforcement learning skills\n",
    "\n",
    "But at some point we have to ask ourselves, is this practical?\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Are Tabular Methods Practical?</h3>\n",
    "\n",
    "Imagine building a self-driving car\n",
    "\n",
    "Our state may consist of lighter readings or images from the environment\n",
    "\n",
    "These are both clearly continuous values \n",
    "\n",
    "In computers, image pixel values are discrete, but in reality they are based on light intensity, which is, for all practical purposes, continuous\n",
    "\n",
    "---\n",
    "\n",
    "Or what if we were building a robot that walks?\n",
    "\n",
    "The state may consist of acceleration and force  measurements on various joints as well as positions and velocities\n",
    "\n",
    "Clearly, these are also continuous values\n",
    "\n",
    "What if we are building an agent to play chess or Go \n",
    "\n",
    "In this case, the states are discrete and finite, but there are way too many of them to enumerate\n",
    "\n",
    "In all of these cases, it would seem that tabular methods are too limited\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Function Approximation</h3>\n",
    "\n",
    "In this notebook, we'll study the concept of function approximation\n",
    "\n",
    "This is the idea that instead of using a table to store the value function, we use a function approximator\n",
    "\n",
    "$$\\large \\hat V(s) = f(s;\\theta)$$\n",
    "\n",
    "$f : \\text{ex: neural netowrk, k-nearest neighbor}$ \n",
    "\n",
    "$\\theta : \\text{model parameters}$\n",
    "\n",
    "The models that we use come from supervised machine learning\n",
    "\n",
    "For example, neural networks and K-nearest neighbor\n",
    "\n",
    "---\n",
    "\n",
    "<h3>notebook Outline</h3>\n",
    "\n",
    "So the outline for this notebook is as follows, first, we're going to review linear regression and stochastic gradient descent\n",
    "\n",
    "In this notebook, we'll be focused on linear models, although the concepts we will learn easily extend to neural networks and other nonlinear function approximators\n",
    "\n",
    "Next, we'll look at feature engineering\n",
    "\n",
    "This is a simple but very effective way of making a linear model approximate nonlinear functions\n",
    "\n",
    "Next, we'll return to reinforcement learning and look at how function approximation can be used for prediction\n",
    "\n",
    "As usual will well then turn our attention towards control with a focus on Q-Learning\n",
    "\n",
    "However, note that all the methods we learn in this notebook can be applied to the previous sections of the series, such as Monte Carlo and SARSA\n",
    "\n",
    "Finally, we will apply what we've learned to a new environment\n",
    "\n",
    "GridWorld is nice to start with because that's what we've been using all throughout this series\n",
    "\n",
    "But it doesn't really show us the true power of function approximation \n",
    "\n",
    "Because of this, we'll be looking at the Cartpole environment in OpenAI Gym\n",
    "\n",
    "<img src='extras/58.1.PNG' width='200'></img>\n",
    "\n",
    "Basically, our job is to build an agent that can balance a pole that sits on top of a moving car\n",
    "\n",
    "What we will see is that the methods we have learned in this series are very general\n",
    "\n",
    "We'll be able to apply what we've learned to this new environment, essentially without any change to the code\n",
    "\n",
    "This is why we always repeat our famous motto\n",
    "\n",
    "$$\\large \\text{All data is the same}$$\n",
    "\n",
    "---\n",
    "\n",
    "<h3>All data is the same</h3>\n",
    "\n",
    "Normally, we discuss this in the context of supervised and unsupervised learning, but we'll see that this applies to reinforcement learning as well\n",
    "\n",
    "How can the same code work for both GridWorld and Cartpole?\n",
    "\n",
    "The key is our computer sees only numbers\n",
    "\n",
    "It doesn't know anything about carts and poles or physics or grid worlds\n",
    "\n",
    "It just sees numbers\n",
    "\n",
    "This is what we mean when we say all data is the same\n",
    "\n",
    "What we've learned is very powerful because it means that we can apply it to any problem without having to learn new concepts or write new code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section will be briefly reviewing linear regression as part of our progression into prediction and control with function approximation\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Linear Regression Problem Setup</h3>\n",
    "\n",
    "So let's start with the basics of linear regression\n",
    "\n",
    "We'll start by assuming that we have some feature vector called $X$\n",
    "\n",
    "Imagine that we want to predict a students' exam grade\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td># hours studied</td>\n",
    "        <td># hours slept</td>\n",
    "        <td>Exam grade</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>8</td>\n",
    "        <td>8</td>\n",
    "        <td>95</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>3</td>\n",
    "        <td>12</td>\n",
    "        <td>80</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>6</td>\n",
    "        <td>4</td>\n",
    "        <td>65</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>...</td>\n",
    "        <td>...</td>\n",
    "        <td>...</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "In this case, $X$ can represent something like how many hours the student studied and how many hours they slept the night before the exam\n",
    "\n",
    "In this case, $X$ would be a two dimensional vector\n",
    "\n",
    "Then suppose that we want to model the exam grade as a linear function of $X$\n",
    "\n",
    "To do this we say \n",
    "\n",
    "$$\\large \\hat y = w^Tx$$\n",
    "\n",
    "We put a hat ($\\hat {\\ \\ \\ }$) on top of $Y$, hence $\\hat Y$ because it's our prediction of the true exam grade, which we would call $Y$\n",
    "\n",
    "Recall that $w^Tx$ is the matrix notation for an inner product \n",
    "\n",
    "When we convert it into scalar form, it simply means that we multiply each element of $w$ by each element of $x$ and then sum all the results together \n",
    "\n",
    "In general, we'll use the letter $D$ to represent the dimensionality of $x$\n",
    "\n",
    "And note that since $w$ is being multiplied by $x$, it must have the same dimensionality as $x$\n",
    "\n",
    "$$\\large \\hat y = w^Tx = \\sum^D_{i=1} w_ix_i$$\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Learning</h3>\n",
    "\n",
    "The key question we need to ask in linear regression is, how do we find the weights, all of the $w_i$s\n",
    "\n",
    "In order to do this, we must have a data set to train our model on\n",
    "\n",
    "Let's continue with our example of trying to predict a student's exam grades from how many hours they studied and how many hours they slept\n",
    "\n",
    "In order to find $w$, we would have to do something like make a survey and collect answers from students\n",
    "\n",
    "Once many students have filled out our survey, we would put them into an Excel spreadsheet and what we would have is a table of numbers\n",
    "\n",
    "Basically for each vector $x$ we have a corresponding $y$ \n",
    "\n",
    "That is for each student's inputs, for the number of hours they studied and the number of hours they slept, we also have a corresponding exam grade\n",
    "\n",
    "The key point is we want to find $w$ such that our predictions, the $\\hat y$s are close to the true $y$s\n",
    "\n",
    "This would of course mean that we have accurate model predictions\n",
    "\n",
    "$\\large \\text{Problem : find } w_i's$\n",
    "\n",
    "$\\large \\text{Solution : make } \\hat y \\text{ close to y for each row}$\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Loss Function / Squared Error</h3>\n",
    "\n",
    "So the way we accomplish this is by creating a loss function\n",
    "\n",
    "A loss function as a function that compares\n",
    "the predictions to the true targets\n",
    "\n",
    "It up puts a large number if the predictions are not close to the targets and it outputs a smaller number when the predictions are close to the targets\n",
    "\n",
    "So clearly, what we would like to do is minimise the loss \n",
    "\n",
    "For regression we normally use the squared error as our loss\n",
    "\n",
    "Basically, it ensures that all the errors are positive, but it has other convenient properties too\n",
    "\n",
    "So let's define a loss function $J$ \n",
    "\n",
    "$$\\large J = \\sum_{n=1}^N (y_n - \\hat y_n)^2$$\n",
    "\n",
    "---\n",
    "\n",
    "<h3>How to find w?</h3>\n",
    "\n",
    "Now, solving for the weights $w$ given the loss $j$ is pretty easy\n",
    "\n",
    "In fact, no other machine learning model is as easy to optimise\n",
    "\n",
    "Let's suppose that we take our table of inputs and we assign that to be a matrix called $X$\n",
    "\n",
    "$X$ is therefore a matrix of size $N \\times D$, since there are $N$ rows and $D$ columns\n",
    "\n",
    "Let's call the vector of targets $\\overrightarrow{y}$, with an arrow on top to denote it as a vector\n",
    "\n",
    "Clearly $\\overrightarrow{y}$ is a vector of size $N \\times 1$, since it has $N$ rows but only $1$ column \n",
    "\n",
    "<img src='extras/58.2.PNG' ></img>\n",
    "\n",
    "Using basic vector calculus, we can minimise $J$ with respect to the weight vector $w$ doing so, we arrive at the usual solution for $w$, which is what we see here\n",
    "\n",
    "$$\\large \\nabla_w J = 0 \\rightarrow w = (X^TX)^{-1} X^T \\overrightarrow{y}$$\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Closed-Form Solutions</h3>\n",
    "\n",
    "Now, in practice, modern problems do not have close form solutions\n",
    "\n",
    "That is, we can't find $w$ using a formula\n",
    "\n",
    "There are a few reasons for this\n",
    "\n",
    "Number one, there are other loss functions we might use other than the squared error\n",
    "\n",
    "The squared error is essentially the only lost function that has a nice closed form solution\n",
    "\n",
    "Number two, we might use a model other than linear regression, such as a neural network\n",
    "\n",
    "In this case, there won't be any closed from solution\n",
    "\n",
    "And number three, you might be doing reinforcement learning where you'd like your agents who learn in an online fashion as in the temporal difference method\n",
    "\n",
    "So in the general case, closed form solutions won't be used\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Gradient Descent</h3>\n",
    "\n",
    "The alternative, of course, is gradient descent\n",
    "\n",
    "In fact, in order to come up with the closed form solution, we would have had to compute the gradient anyway\n",
    "\n",
    "So it's not any more complicated mathematically than what we already know\n",
    "\n",
    "So the basic algorithm goes like this \n",
    "\n",
    "For some number of iterations, we simply update the weights by taking the current value and subtracting a small number $\\alpha$ times the gradient\n",
    "\n",
    "This small number $\\alpha$, is what we call the learning rate\n",
    "\n",
    "Typically, it's a small number, like $0.1,0.01$ and so forth\n",
    "\n",
    "The way that we would choose this learning rate is by trial and error or some variation thereof\n",
    "\n",
    "$$\\large \\nabla_w J = 2X^T (Xw - \\overrightarrow{y})$$\n",
    "\n",
    "$\\large Loop: \\\\ \\qquad  \\large w \\leftarrow w - \\alpha \\nabla_w J$\n",
    "\n",
    "<img src='extras/58.3.PNG' width='500'></img>\n",
    "\n",
    "Note that we typically drop the two from the gradient, which comes from the square term, since we have to choose the learning rate arbitrarily anyway\n",
    "\n",
    "So it doesn't matter if we remove any constants in front of the gradient since they are absorbed into the learning rate\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Descent vs. Ascent</h3>\n",
    "\n",
    "Now, one common point of confusion among beginners is the difference between gradient descent and gradient ascent\n",
    "\n",
    "We should be able to see that if our lost function had been the negative of what it was before then we could do gradient ascent to find its maximum\n",
    "\n",
    "$$\\large w \\rightarrow - \\alpha \\nabla_w J \\\\ \\large w \\rightarrow w + \\alpha \\nabla_w (-J)$$\n",
    "\n",
    "note : so both of the above are the same\n",
    "\n",
    "To see a simple example of this, imagine minimizing $x^2$ or maximizing $-x^2$\n",
    "\n",
    "<img src='extras/58.4.PNG' width='400'></img>\n",
    "\n",
    "Clearly, both of these have the same answer\n",
    "\n",
    "The optimal value is found at $x=0$\n",
    "\n",
    "The only difference between gradient descent and gradient descent is where we put the negative sign\n",
    "\n",
    "But mathematically we're doing the exact same operation\n",
    "\n",
    "Now, the reason we mention this is that in practice, we typically do gradient ascent in reinforcement learning\n",
    "\n",
    "So don't be surprised if we see a plus sign in front of the learning rate instead of a negative\n",
    "sign\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Stochastic Gradient Descent / Ascent</h3>\n",
    "\n",
    "The next point to mention is that in practice, we're not going to see all the data points at once\n",
    "\n",
    "In fact, we've seen that with temporal distance learning, we update our model after each step\n",
    "\n",
    "So the supervised learning equivalent of this would be stochastic gradient descent\n",
    "\n",
    "It essentially minimises the same loss function on average, but it looks at one data point at a time instead of all end data points at once\n",
    "\n",
    "So we can imagine that the pseudocode now looks like this\n",
    "\n",
    "$Loop: \\\\ \\qquad for \\ n=1 \\ldots N: \\\\ \\qquad \\qquad w \\leftarrow w + \\alpha(y_n - w^Tx_n)x_n$\n",
    "\n",
    "First, we have an outer loop that goes for some number of epochs\n",
    "\n",
    "Then we have an inner loop that goes through each of our $N$ samples\n",
    "\n",
    "At the $n$th sample, we do gradient descent or gradient ascent on the squared error for only that one sample\n",
    "\n",
    "Over time, this will minimise the loss\n",
    "\n",
    "In fact, sometimes it can do so faster than if we had used the full gradient descent\n",
    "\n",
    "For example, when we have a very large data set\n",
    "\n",
    "OK, so that's everything we need to know about linear regression for the purpose of reinforcement learning\n",
    "\n",
    "In the next few sections, we'll see how to apply these principles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll be looking at a concept called feature engineering\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Nonlinear Function Approximation</h3>\n",
    "\n",
    "So what's our motivation for this?\n",
    "\n",
    "Well, essentially, linear regression by itself is not a very expressive model\n",
    "\n",
    "Linear means that the model can only be a line a plane or hyper-plane so it can approximate a curved function like this\n",
    "\n",
    "<img src='extras/58.5.PNG' width='700'></img>\n",
    "\n",
    "And that's a problem if the true value function is actually a nonlinear function\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Value Function for Gridworld is Nonlinear!</h3>\n",
    "\n",
    "In fact, we should be able to convince ourselves that even the value function for grid world is not linear\n",
    "\n",
    "To see this, consider the policy shown here \n",
    "\n",
    "<img src='extras/58.6.PNG' ></img>\n",
    "\n",
    "In the top row, the value function is always one because we go directly to the goal state\n",
    "\n",
    "Note that this is without discounting and with a deterministic policy and environment\n",
    "\n",
    "However, in the middle row, the value function is one on the left but minus one on the right, since the policy there is to go into the losing state \n",
    "\n",
    "So we can see that in the top row, the value\n",
    "function is constant, but in the middle row the value function decreases from left to right\n",
    "\n",
    "In fact, it's actually a bit more complicated than this since the value function for the terminal states is zero\n",
    "\n",
    "So clearly this is a non-linear function\n",
    "\n",
    "It cannot be represented by a plane over the grid\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Why use linear regression?</h3>\n",
    "\n",
    "Now, one question we might have is, why do we need to use linear regression in the first place?\n",
    "\n",
    "There are plenty of other non-linear machine learning models like decision trees, support vector machines and so forth\n",
    "\n",
    "In fact, not all models can do online updating, which is what we really need in order to do reinforcement learning\n",
    "\n",
    "Gradient based methods that can learn using stochastic gradient descent are ideal\n",
    "\n",
    "So linear regression and deep neural networks are the most popular approaches\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Feature Engineering</h3>\n",
    "\n",
    "Now, that being said, there is an easy way to get a linear regression to model non-linear functions\n",
    "\n",
    "In fact, we've most likely encountered it before if we've ever studied machine learning or applied\n",
    "machine learning in the real world\n",
    "\n",
    "This is to do feature engineering\n",
    "\n",
    "Often researchers and industry professionals have to apply machine learning to their domain of expertise\n",
    "\n",
    "That might be something like drug discovery, reading MRI brain images, or trying to model automobile traffic in a city\n",
    "\n",
    "In these scenarios, those working with machine learning often use their domain knowledge to come up with useful features after which they can apply linear regression\n",
    "\n",
    "The key is they use their expertise in the domain to help them come up with features that are useful when using linear regression\n",
    "\n",
    "So if we're working in drug discovery, you might apply your specialised knowledge of chemistry and\n",
    "biology to help us come up with useful features\n",
    "\n",
    "But what if we are not an expert in such a domain?\n",
    "\n",
    "Are there any more generic methods of feature engineering?\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Polynomial Features</h3>\n",
    "\n",
    "One common method that most students learn when they study linear regression is the use polynomials\n",
    "\n",
    "So imagine that we have two features\n",
    "\n",
    "$x_1$ is how many hours a student has studied for an exam and $x_2$ is how many hours they slept the night before the exam\n",
    "\n",
    "Instead of creating a linear regression model \n",
    "\n",
    "$$\\large \\text{Linear Model} : \\hat y = w_1x_1 + w_2x_2$$ \n",
    "\n",
    "we create polynomial features\n",
    "\n",
    "For example, perhaps we believe there's a quadratic relationship between $x_1$ and $x_2$ and the exam grade\n",
    "\n",
    "In this case we could use $x_1^2$ and $x_2^2$ along with $x_1x_2$\n",
    "\n",
    "These are called the second order terms\n",
    "\n",
    "$$\\large Quadratic Model : \\hat y = w_1x_1^2 + w_2x_2^2 + w_3x_1x_2 + w_4x_1 + w_5x_2$$\n",
    "\n",
    "We can also add a third, fourth and fifth order terms, although we generally don't go too large since these models tend to overfit\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Feature Expansion</h3>\n",
    "\n",
    "In general, we can think of a future expansion as a function $\\varphi$ applied to the input feature $x$ \n",
    "\n",
    "$\\varphi$ can be any function that maps any input to a real valued output vector\n",
    "\n",
    "Using this notation are linear regression model becomes \n",
    "\n",
    "$$\\large \\hat y = w^T \\varphi(x)$$\n",
    "\n",
    "$\\large \\text{Example : } \\varphi(x) = (\\sin x_1,\\cos x+2, \\sin x_1 cos x_2, e^{x_1x_2}, \\ldots)$\n",
    "\n",
    "\n",
    "So instead of being a linear model of $x$ directly, it's now a linear model of $\\varphi(x)$\n",
    "\n",
    "And since $\\varphi$ can be any function, this model can now be applied to model arbitrary non-linear functions\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Radial Basis Function</h3>\n",
    "\n",
    "OK, so in practice, we don't actually use polynomials that often \n",
    "\n",
    "We might see them in our statistics class, but in machine learning, they don't actually work that well\n",
    "\n",
    "In this notebook, we'll study a kind of feature expansion that does tend to work well, called the radio basis function\n",
    "\n",
    "So the intuition behind the RBF is this\n",
    "\n",
    "Imagine that we have a space where our $x$ data points live\n",
    "\n",
    "Now, imagine that there are some important points in this space.\n",
    "\n",
    "We'll call them landmarks or exemplars\n",
    "\n",
    "So suppose we have three landmarks\n",
    "\n",
    "Let's call them $L_1$, $L_2$ and $L_3$\n",
    "\n",
    "<img src='extras/58.7.PNG'></img>\n",
    "\n",
    "The concept of the radial basis function is simple\n",
    "\n",
    "To map a new input $x$ to a feature vector, we just measure how close X is to each of these landmarks\n",
    "\n",
    "Imagine that we have some similarity measure\n",
    "\n",
    "So if $x$ is really close to a landmark, then this similarity measure should return a number very close to $1$\n",
    "\n",
    "If $x$ is very far away from a landmark, then the similarity measure should return a number very close to $0$\n",
    "\n",
    "$\\large \\text{Similarity}(x,L_i) = 1, \\text{ if }x = L_i \\\\ \\large \\text{Similarity}(x,L_i) = 0, \\text{ if }x \\text{ is far away from } L_1$\n",
    "\n",
    "So for the $x$ is shown here\n",
    "\n",
    "<img src='extras/58.8.PNG'></img>\n",
    "\n",
    "Since it's very close to $L_1$, maybe its similarity is $0.9$.\n",
    "\n",
    "But since it's moderately far away from $L_2$, it's similarity for that landmark is $0.3$\n",
    "\n",
    "Since it's very far away from $L_3$, it's similarity for that landmark is $0.01$\n",
    "\n",
    "OK, so that's the basic idea.\n",
    "\n",
    "The feature transformation for $x$ is then a vector containing the numbers $\\varphi(x)=(0.9,0.3,0.01)$\n",
    "\n",
    "<img src='extras/58.9.PNG'></img>\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Similarity Function</h3>\n",
    "\n",
    "So what kind of similarity function do we use?\n",
    "\n",
    "Well, in this notebook, the details aren't too important since we'll be using a class from scikit-learn, but if we're interested, here it is\n",
    "\n",
    "$$\\large sim(x,l_i) = \\exp \\left( -\\beta \\Vert x - l_i \\Vert^2 \\right)$$\n",
    "\n",
    "<img src='extras/58.10.PNG' width='500'></img>\n",
    "\n",
    "So basically, the function is a Gaussian \n",
    "\n",
    "We take the square Euclidean distance between $x$ and the landmark, weight that distance by some parameter $\\beta$, negate it and then take the exponential\n",
    "\n",
    "We should recognize this function as being shaped like a bell curve\n",
    "\n",
    "It's equal to one if $x$ is equal to the landmark, and it approaches zero as the distance between $x$ and the landmark approaches infinity\n",
    "\n",
    "$\\beta$ controls how skinny or fat the Gaussian bell curve is\n",
    "\n",
    "But again, unless we want to implement this oursleves in Python, the details aren't too important\n",
    "\n",
    "As an exercise, you might actually want to try to implement this on our own\n",
    "\n",
    "For landmarks, we can simply choose positions on the grid or samples from the environment\n",
    "\n",
    "---\n",
    "\n",
    "<h3>RBFSampler</h3>\n",
    "\n",
    "So in practice, since we don't want to have to worry about how RBFs are implemented, in this notebook, we're going to use a scikit-learn class called `RBFSampler`\n",
    "\n",
    "Basically, it's an approximation to the RBF kernel that works well in practice and is much more efficient\n",
    "\n",
    "```python\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "\n",
    "rbf = RBFSampler()\n",
    "X_train = gather_samples() # training data, enviroment\n",
    "rbf.fit(X_train)\n",
    "phi_X = rbf.transform(X_val) # other data to transform\n",
    "```\n",
    "\n",
    "As is typical, `the RBFSampler` has `fit` and `transform` functions\n",
    "\n",
    "So the way to use it is this\n",
    "\n",
    "First we instantiate an object of type `RBFSampler`\n",
    "\n",
    "Then we gather a bunch of samples\n",
    "\n",
    "So if we're doing supervised learning, then this would be our training set\n",
    "\n",
    "And if it's reinforcement learning, they might be sample states from the environment\n",
    "\n",
    "If we call that set of samples `X`, then we call the fit function passing in `X`\n",
    "\n",
    "Then when we encounter new samples in the future, we can transform them by calling the `transform` function\n",
    "\n",
    "OK, so pretty simple\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Optional Detail</h3>\n",
    "\n",
    "One caveat to the RBF samplers is that, although it seems like it should depend on `X` when we call the fit function, it actually doesn't \n",
    "\n",
    "note : This means that when we call the `fit()` function, the model parameters dont actually depend on the data we passed in\n",
    "\n",
    "For those advanced students who want to research this further, we recommend looking up the technique called \"Random Kitchen Sinks\"\n",
    "\n",
    "This is outside the scope of this notebook and has nothing to do with reinforcement learning, but if we're interested, it's an interesting topic to read about\n",
    "\n",
    "Now, of course, we may ask, well, if the RBF sampler doesn't depend on the data we pass into the `fit` function, then what's the point of collecting data and calling the fit function?\n",
    "\n",
    "The answer is that we don't want to build a crappy program that only works for the RBF sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in this section, we're going to return to reinforcement learning \n",
    "\n",
    "---\n",
    "\n",
    "<h3>Function Approximation for Prediction</h3>\n",
    "\n",
    "Now that we understand the basics of function approximation, it's time to get back to our usual path of solving prediction and then control\n",
    "\n",
    "So this section is about how to solve the prediction task using function approximation\n",
    "\n",
    "To begin, let's assume that we have a feature expansion $\\varphi$ which is applied to the state $s$ \n",
    "\n",
    "We'll call the output of this feature transformation $x$ \n",
    "\n",
    "$$\\large x = \\varphi(s)$$\n",
    "\n",
    "So this is a bit different from before when we were discussing feature expansions more generically\n",
    "\n",
    "In that case, we thought of $x$ as the input to $\\varphi$\n",
    "\n",
    "In any case, it's not that big of a deal\n",
    "\n",
    "Just remember that $s$ is the state, and we want to transform that into a feature vector using $\\varphi$ and we call that feature vector $x$\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Function Approximation for Prediction</h3>\n",
    "\n",
    "OK, so our model for the value function is then\n",
    "\n",
    "$$\\large \\hat V_\\pi(s) = w^Tx = w^T \\varphi(s)$$\n",
    "\n",
    "So what does this mean?\n",
    "\n",
    "Well, recall that previously we thought of the value function as a table\n",
    "\n",
    "If we wanted to look up the value function estimate for a specific state $s$ we would just go into the table and plug in $s$ to find the corresponding value\n",
    "\n",
    "But this only works when $s$ was discrete, in which case the table makes sense\n",
    "\n",
    "In this case now $s$ can be either discrete or continuous\n",
    "\n",
    "When we want to find the value estimate for $s$, we first pass it through the function $\\varphi$ and then dot it with the weights $w$\n",
    "\n",
    "So this is one big difference between how we obtain values given a state $s$ \n",
    "\n",
    "Previously we would just look it up in a table or dictionary\n",
    "\n",
    "Now we plug it into a function approximator\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Squared Error</h3>\n",
    "\n",
    "So how do we learn or in other words, improve our $V(s)$ estimates\n",
    "\n",
    "As you recall, this can be done via stochastic gradient descent\n",
    "\n",
    "So imagine that we've just obtained a sample return $g$ for a given state using some policy $\\pi$\n",
    "\n",
    "How do we update the value for $s$ given this new sample $G$?\n",
    "\n",
    "Well, more correctly, we are not updating the value itself\n",
    "\n",
    "We are updating the weights $w$ which in turn makes $\\hat V$ more accurate\n",
    "\n",
    "So how do we do this?\n",
    "\n",
    "We recall that we use the squared error\n",
    "\n",
    "So let's say $J$ is equal to \n",
    "\n",
    "$$\\large J = \\left(G - \\hat V_\\pi(s)\\right)^2$$\n",
    "\n",
    "What we would like to do is take one small step using gradient descent where the gradient is the gradient of $J$ with respect to $W$\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Gradient</h3>\n",
    "\n",
    "So after doing some basic calculus, we arrive at the following expression for the gradient\n",
    "\n",
    "$$\\large \\nabla_w J = 2(w^Tx - G)x$$\n",
    "\n",
    "As an exercise, we may want to derive this on our own on paper if we cant immediately see how we got this answer\n",
    "\n",
    "And as usual, we normally drop the constant, $2$, for convenience\n",
    "\n",
    "OK, so the gradient is equal to the prediction minus the target times the feature vector $x$\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Update Rule</h3>\n",
    "\n",
    "So if we apply this to our gradient descent step, here's what we get\n",
    "\n",
    "$$\\large w \\leftarrow w - \\alpha \\left(w^Tx - G \\right)x$$\n",
    "\n",
    "And again, note that in reinforcement learning, we typically present this as gradient ascent and\n",
    "use $+ \\alpha$ instead\n",
    "\n",
    "$$\\large w \\leftarrow w + \\alpha \\left(G - w^Tx \\right)x$$\n",
    "\n",
    "This is because we get the target in front of the prediction, as we had in earlier\n",
    "\n",
    "But either way, these two expressions yield the same results\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Pseudocode for Monte Carlo Prediction</h3>\n",
    "\n",
    "OK, so now that we have our update, we can look at the full pseudocode from Monte Carlo prediction using function approximation\n",
    "\n",
    "$\\text{Given: }\\pi \\\\ \\text{Initialise: } w = zeros(D) \\text{ # or random} \\\\ \\text{Loop until convergance: } \\\\ \\qquad \\text{Play episode following }\\pi \\text{, obtain s(0),a(0),r(1),s(1),a(1),...,r(T),s(T)} \\\\ \\qquad G = 0 \\\\ \\qquad \\text{for t in \\{T-1,T-2,...,0\\}:} \\\\ \\qquad \\qquad G = r(t+1) + \\gamma G \\\\ \\qquad \\qquad x = \\varphi(s(t)) \\\\ \\qquad \\qquad w = w + \\alpha(G-w^Tx)x$\n",
    "\n",
    "So we're given as input some policy $\\pi$ whose value we want to find\n",
    "\n",
    "We then initialie a wave vector $w$ the same size as our feature vectors, let's call that size $D$\n",
    "\n",
    "Then we play some number of episodes \n",
    "\n",
    "Inside the Loop, Ww play an episode using our given policy, which gives us a sequence of states and rewards\n",
    "\n",
    "Next, we initialize our return $G$ to zero\n",
    "\n",
    "Then we enter a loop from timestep $T-1$ down to $0$\n",
    "\n",
    "Inside the loop we update $G$ using the usual recursive formula\n",
    "\n",
    "Next we find $X$ using our feature transformation function $\\phi$\n",
    "\n",
    "Then we update the weight vector $w$ using stochastic gradient descent\n",
    "\n",
    "OK, so as we can see, this is essentially the same as the Monte Carlo pseudocode we saw before, except that we've replaced the tabular update with gradient descent on $w$\n",
    "\n",
    "---\n",
    "\n",
    "<h3>From Monte Carlo to Temporal Difference Learning</h3>\n",
    "\n",
    "Now, in the coming code sections, note that we're going to skip straight ahead to temporal difference learning\n",
    "\n",
    "We may want to try to implement the Monte Carlo version as an exercise, but for this notebook, TD learning will be the focus\n",
    "\n",
    "Basically, the only difference between Monte Carlo and TD learning is that our target is now $r + \\gamma \\hat V_\\pi(s^\\prime)$ instead of the full return $G$\n",
    "\n",
    "$\\large \\text{Monte Carlo Target}: G \\\\ \\large \\text{TD Target: } r + \\gamma \\hat V_\\pi(s^\\prime)$\n",
    "\n",
    "One thing to be mindful of is that, when we do gradient descent, although the target depends\n",
    "on $w$, we do not differentiate the target when finding the gradient of the squared error\n",
    "\n",
    "So we treat the target as a fixed value despite the fact that it depends on $w$\n",
    "\n",
    "So here is the pseudocode for TD Learning\n",
    "\n",
    "$\\text{Given: }\\pi \\\\ \\text{Initialise: w = zeros(D) # or random} \\\\ \\text{Loop until convergence: } \\\\ \\qquad \\text{s = env.reset()} \\\\ \\qquad \\text{while s is not terminal:} \\\\ \\qquad \\qquad a \\sim \\pi(s) \\\\ \\qquad \\qquad s^\\prime,r = env.move(a) \\\\ \\qquad \\qquad \\text{if } s^\\prime \\text{ is terminal:} \\\\ \\qquad \\qquad \\qquad y = r \\\\ \\qquad \\qquad \\text{else:} \\\\ \\qquad \\qquad \\qquad y = r + \\gamma w^T \\varphi(s^\\prime) \\\\ \\qquad \\qquad w = w + \\alpha(y-w^T \\varphi(s)) \\varphi(s) \\\\ \\qquad \\qquad s = s^\\prime$\n",
    "\n",
    "Again, we're given an input policy $\\pi$ and we start by initializing a weight to vector $w$\n",
    "\n",
    "Next, we enter a loop that goes for some number of episodes \n",
    "\n",
    "Inside the loop, we reset our environment and obtain the initial state $s$\n",
    "\n",
    "Then we enter a second loop that exits when the episode is complete\n",
    "\n",
    "Inside this loop, we use our policy to get our next action and then we perform this action in the environment\n",
    "\n",
    "This gives us the reward $r$ and the next state $s^\\prime$\n",
    "\n",
    "Next we assign the target value\n",
    "\n",
    "If $s^\\prime$ is a terminal state, then the target value is just the reward $r$ since the value of terminal status is zero\n",
    "\n",
    "Otherwise the target value is $r+\\gamma V(s^\\prime)$\n",
    "\n",
    "Next we update $w$ using gradient ascent\n",
    "\n",
    "Lastly, we assign $s^\\prime$ to be $s$ for the next iteration of the loop\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Interesting Notes</h3>\n",
    "\n",
    "OK, so that's essentially it for prediction with function approximation\n",
    "\n",
    "There are two final notes worth making\n",
    "\n",
    "First, as we recall, with tabular methods when we updated $V$ or $Q$, these were only entries in a table \n",
    "\n",
    "Because of this, when we do an update to $V(s)$ for some state $s$, only the entry for that particular state will change\n",
    "\n",
    "On the other hand, function approximation behaves differently\n",
    "\n",
    "Now, when we update $w$, we can see that changing $w$ affects the value estimate for all states\n",
    "\n",
    "---\n",
    "\n",
    "The second thing to notice is this \n",
    "\n",
    "Suppose that our state space is discrete\n",
    "\n",
    "We can see that tabular methods are really just a special case, a function approximation\n",
    "\n",
    "Imagine that we have $D$ states, simply called $s_1,s_2,\\ldots,s_D$\n",
    "\n",
    "Now, let's suppose that we do a very simple feature transformation called one hot encoding\n",
    "\n",
    "$$\\varphi(s_1) = (1,0,0,\\ldots) \\\\ \\varphi(s_2) = (0,1,0,\\ldots) \\\\ \\ldots \\\\ \\varphi(s_D) = (0,\\ldots,0,1) $$\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Tabular Methods are a Special Case of Linear Approximation</h3>\n",
    "\n",
    "Now, what is our model? \n",
    "\n",
    "We have we have \n",
    "\n",
    "$$\\large \\hat V_\\pi(s) = w^T \\varphi(s)$$\n",
    "\n",
    "But since $\\varphi(s)$ is just a one hot encoding, what does this give us?\n",
    "\n",
    "$\\large \\hat V_\\pi(s_1) = (w_1,w_2,\\cdots,w_D) \\cdot (1,0,0,\\cdots) = w_1$\n",
    "\n",
    "$\\large \\hat V_\\pi(s_2) = (w_1,w_2,\\cdots,w_D) \\cdot (0,1,0,\\cdots) = w_2$\n",
    "\n",
    "So as we can see, in this case, we just have a single parameter for estimating the value for each state, which is exactly the same as the tabular method\n",
    "\n",
    "Updating $w_1$ will update $V(s_1)$, but this will have no effect on any of the other values\n",
    "\n",
    "In fact, $w_1 = V(s_1)$\n",
    "\n",
    "---\n",
    "\n",
    "Furthermore, notice that the update rule reduces to what we have in the tabular case, since the gradient is just $1$ for the state of interest in $0$ for all other states\n",
    "\n",
    "note : gradient is just something like (0,0,1,0,0,...)\n",
    "\n",
    "$\\large \\text{Update Rule : } w_i \\leftarrow w_i + \\alpha(G-w_i) \\cdot 1$\n",
    "\n",
    "To see this, we can first note that the update rule shown here is correct\n",
    "\n",
    "The gradient is one for the particular state of interest\n",
    "\n",
    "But recall that, as we just showed, $w_i$ is the same thing as $V(s_i)$\n",
    "\n",
    "note : $w_i = V(s_i)$\n",
    "\n",
    "In other words, these weights are actually just the value function estimate for each state\n",
    "\n",
    "Therefore, this update rule, which we derive by gradient descent, is actually the same as the update rule we already learned earlier for tabular methods\n",
    "\n",
    "That's why earlier in this series, we mentioned that the update rule for $V(s)$ that looks like gradient descent actually is gradient descent\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Why is is useful?</h3>\n",
    "\n",
    "So this is actually pretty useful\n",
    "\n",
    "Imagine that we're writing code and we can't get it to work\n",
    "\n",
    "One way to debug our code is to use one hot encoding, which is equivalent to the tabular method\n",
    "\n",
    "Then we can check whether our answer is the same as what you get if we implement the tabular method directly\n",
    "\n",
    "If they are the same, then we can be more confident that our code is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>code</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go go lets go !\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.kernel_approximation import RBFSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we will be using the standard Gridworld\n",
    "\n",
    "# first lets implement our Gridworld enviroment\n",
    "# we will be using the same interface as described above\n",
    "\n",
    "class GridWorld:\n",
    "    def __init__(self,rows,cols,start_pos):\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "        self.pos = start_pos\n",
    "        self.start_pos = start_pos\n",
    "    \n",
    "    def current_state(self):\n",
    "        return self.pos\n",
    "    \n",
    "    def set_state(self,state):\n",
    "        self.pos = state\n",
    "        \n",
    "    def set_actions_rewards(self,actions,rewards):\n",
    "        self.actions = actions\n",
    "        self.rewards = rewards\n",
    "        \n",
    "    def all_states(self,):\n",
    "        return [(i,j) for i in range(self.rows) for j in range(self.cols)]\n",
    "    \n",
    "    def is_terminal(self,state):\n",
    "        # we cant perform an action in a terminal state\n",
    "        # so we expect not to find it in the keys\n",
    "        return state not in self.actions.keys()\n",
    "    \n",
    "    def game_over(self):\n",
    "        return self.is_terminal(self.pos)\n",
    "    \n",
    "    def next_state(self,s,a):\n",
    "        # return next state should we take action a\n",
    "        # but do not take that action\n",
    "        i,j = s\n",
    "        # if we are allowed to do this action in our current position\n",
    "        if a in self.actions.get(s,[]): \n",
    "            if a == 'R':\n",
    "                j += 1\n",
    "            if a == 'L':\n",
    "                j -= 1\n",
    "            if a == 'U':\n",
    "                i -= 1\n",
    "            if a == 'D':\n",
    "                i += 1\n",
    "        return (i,j)\n",
    "    \n",
    "    def move(self,a):\n",
    "        # return next state should we take action a\n",
    "        # this time we actually make the move\n",
    "        # and thus return reward\n",
    "        i,j = self.pos\n",
    "        # if we are allowed to do this action in our current position\n",
    "        if a in self.actions.get(self.pos,[]): \n",
    "            if a == 'R':\n",
    "                j += 1\n",
    "            if a == 'L':\n",
    "                j -= 1\n",
    "            if a == 'U':\n",
    "                i -= 1\n",
    "            if a == 'D':\n",
    "                i += 1\n",
    "        self.pos = (i,j)\n",
    "        # if no reward return 0\n",
    "        return self.rewards.get(self.pos,0)\n",
    "    \n",
    "    # lets add methods to print values and actions\n",
    "    def print_values(self,V):\n",
    "        for i in range(self.rows):\n",
    "            print('-'*9*self.rows)\n",
    "            for j in range(self.cols):\n",
    "                v = V[i,j]\n",
    "                if v >= 0:\n",
    "                    # if 0 or +ve, add space so it aligns well when we have -\n",
    "                    print(\" %.2f|\" %v,end=\"\")\n",
    "                else:\n",
    "                    print(\"%.2f|\" %v,end=\"\")\n",
    "            print(\"\")\n",
    "    \n",
    "    def print_policy(self,P):\n",
    "        for i in range(self.rows):\n",
    "            print('-'*6*self.rows)\n",
    "            for j in range(self.cols):\n",
    "                print(\" %s |\" %P.get((i,j),' '),end=\"\")\n",
    "            print(\"\")\n",
    "                \n",
    "    def state_to_loc(self,state): # convert state tupe (0,1) to location 1\n",
    "        return state[0]*self.rows + state[1]\n",
    "    \n",
    "    def reset(self):\n",
    "        self.pos = self.start_pos\n",
    "\n",
    "\n",
    "def standrad_grid():\n",
    "    g = GridWorld(3,4,(2,0))\n",
    "    rewards = {(0,3):1,(1,3):-1}\n",
    "    actions = {\n",
    "        (0,0): ('D','R'),\n",
    "        (0,1): ('L','R'),\n",
    "        (0,2): ('L','D','R'),\n",
    "        (1,0): ('U','D'),\n",
    "        (1,2): ('U','D','R'),\n",
    "        (2,0): ('U','R'),\n",
    "        (2,1): ('L','R'),\n",
    "        (2,2): ('L','R','U'),\n",
    "        (2,3): ('L','U')\n",
    "    }\n",
    "    g.set_actions_rewards(actions,rewards)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = standrad_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy to evaluate\n",
    "policy = {\n",
    "    (2,0) : 'U',\n",
    "    (1,0) : 'U',\n",
    "    (0,0) : 'R',\n",
    "    (0,1) : 'R',\n",
    "    (0,2) : 'R',\n",
    "    (1,2) : 'R',\n",
    "    (2,1) : 'R',\n",
    "    (2,2) : 'R',\n",
    "    (2,3) : 'U',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      " R | R | R |   |\n",
      "------------------\n",
      " U |   | R |   |\n",
      "------------------\n",
      " U | R | R | U |\n"
     ]
    }
   ],
   "source": [
    "g.print_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Approx:\n",
    "    def gather_samples(self,g,num_episodes=10000):\n",
    "        samples = []\n",
    "        all_actions = ['L','R','U','D']\n",
    "        \n",
    "        for epsiodes in range(num_episodes):\n",
    "            g.reset()\n",
    "            s = g.current_state()\n",
    "            samples.append(s)\n",
    "            while not g.game_over():\n",
    "                a = np.random.choice(['L','R','U','D'])\n",
    "                _ = g.move(a)\n",
    "                s = g.current_state()\n",
    "                samples.append(s)\n",
    "        return samples\n",
    "    \n",
    "    def build_phi(self,g,num_episodes=10000,D=100):\n",
    "        # first we gather sum samples\n",
    "        samples = self.gather_samples(g,num_episodes)\n",
    "        # next we can build our RBF Sampler\n",
    "        rbf = RBFSampler(n_components = D)\n",
    "        rbf.fit(samples)\n",
    "        self.rbf = rbf\n",
    "        self.D = D\n",
    "                \n",
    "        # we can also initialise the weights here\n",
    "        # since we know now D\n",
    "        self.W = np.zeros(D)\n",
    "        \n",
    "    def epsilon_greedy(self,best_action,eps=0.1):\n",
    "        if np.random.random() < eps:\n",
    "            return np.random.choice(['L','R','U','D'])\n",
    "        else:\n",
    "            return best_action\n",
    "        \n",
    "    def phi(self,s):\n",
    "        return self.rbf.transform([s]).squeeze()\n",
    "                \n",
    "    def train(self,g,policy,episodes=20000,gamma=0.9,alpha=0.1):\n",
    "        all_states = g.all_states()\n",
    "        all_actions = ['L','R','U','D']\n",
    "        # lets keep track of mse\n",
    "        mse = np.zeros(episodes)\n",
    "        # random policy\n",
    "        if policy is None:\n",
    "            policy = {s:np.random.choice(all_actions) for s in all_states if not g.is_terminal(s)}\n",
    "        \n",
    "        # we already initialised W\n",
    "        # so that if we train more we can begin from where we left off\n",
    "        for episode in range(episodes):\n",
    "            g.reset()\n",
    "            s = g.current_state()\n",
    "            n_steps = 0\n",
    "            while not g.game_over():\n",
    "                a = self.epsilon_greedy(policy[s])\n",
    "                r = g.move(a)\n",
    "                s_prime = g.current_state()\n",
    "                \n",
    "                if g.is_terminal(s_prime):\n",
    "                    y = r\n",
    "                else:\n",
    "                    y = r + gamma * (self.W @ self.phi(s_prime))\n",
    "                self.W = self.W + alpha*(y-self.W@self.phi(s))*self.phi(s) \n",
    "                s = s_prime\n",
    "                # calculate mse\n",
    "                mse[episode] += (y-self.W@self.phi(s))**2\n",
    "                n_steps += 1\n",
    "            mse[episode] /= n_steps\n",
    "        plt.title('mse per epoch')\n",
    "        plt.plot(mse)\n",
    "        plt.show()\n",
    "                \n",
    "    def get_value(self,g):\n",
    "        V = np.zeros((g.rows,g.cols))\n",
    "        for i in range(g.rows):\n",
    "            for j in range(g.cols):\n",
    "                s = (i,j)\n",
    "                if not g.is_terminal(s):\n",
    "                    V[i,j] = self.W @ self.phi((i,j))\n",
    "        return V        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Approx()\n",
    "model.build_phi(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.train(g,policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we might notice something strange, which is that, although we have a general decrease at the start, the error fluctuates instead of converging to zero\n",
    "\n",
    "Of course, this is because we are using Epsilon Greedy, which sometimes brings us to different states which have different values than what is dictated by the greedy policy\n",
    "\n",
    "But if we only acted according to the greedy policy, then we wouldn't be able to learn the values of some of those states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = model.get_value(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      " 0.75| 0.84| 0.95| 0.00|\n",
      "---------------------------\n",
      " 0.67| 0.00|-0.91| 0.00|\n",
      "---------------------------\n",
      " 0.59|-0.71|-0.86|-0.99|\n",
      "------------------\n",
      " R | R | R |   |\n",
      "------------------\n",
      " U |   | R |   |\n",
      "------------------\n",
      " U | R | R | U |\n"
     ]
    }
   ],
   "source": [
    "g.print_values(V)\n",
    "g.print_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the learned value function, we can see that the values are pretty close to what we would expect\n",
    "\n",
    "They are large going into the gold state and they decrease the further away you get\n",
    "\n",
    "They are larger negative going toward the losing state\n",
    "\n",
    "And they also decrease the further away we get\n",
    "\n",
    "So the results make sense, even though the mean squared error does not converge to zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we're going to continue our discussion about how to apply approximation methods in reinforcement learning\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Function Approximation for Control</h3>\n",
    "\n",
    "So we just learned how to use function approximation for approximating the state value $V(s)$ \n",
    "\n",
    "The next task for us is to consider how we will approximate the action value of $Q(s,a)$\n",
    "\n",
    "Previously, our method was to apply some feature expansion $\\varphi$ to the state $s$\n",
    "\n",
    "This would give us a new feature vector $x$\n",
    "\n",
    "$$\\large x = \\varphi(s)$$\n",
    "\n",
    "Then we could take $x$, dot with the weight vector $w$ and get an approximation for $V(s)$\n",
    "\n",
    "$$\\large \\hat V(s) = w^Tx$$\n",
    "\n",
    "But now things are a bit more complicated because of the action \n",
    "\n",
    "In this case, we're going to simply have a new feature expansion $\\varphi$ that transforms both the state and the action\n",
    "\n",
    "$$\\large x = \\varphi(s,a)$$\n",
    "\n",
    "Once we have that, we can again just dot it with the weight vector $W$ to get our approximation of $Q(s,a)$\n",
    "\n",
    "$$\\large \\hat Q(s,a) = w^Tx$$\n",
    "\n",
    "---\n",
    "\n",
    "<h3>How to transform both state and action?</h3>\n",
    "\n",
    "So let's consider how $\\varphi$ can act on both the state and action \n",
    "\n",
    "In Gridworld, our actions are categorical up, down, left and right \n",
    "\n",
    "In machine learning, one simple way to encode categorical variables is to use what is called one hot encoding\n",
    "\n",
    "So since we have four actions, our actions will be encoded as four dimensional vectors \n",
    "\n",
    "So our actions might be:\n",
    "\n",
    "$ \\text{Up} = (1,0,0,0) \\\\  \\text{Down} = (0,1,0,0) \\\\  \\text{Left} = (0,0,1,0) \\\\ \\text{Right} = (0,0,0,1)$\n",
    "\n",
    "OK, so pretty simple.\n",
    "\n",
    "Then we can make a new vector by simply concatenating the state vector and the action's\n",
    "\n",
    "So if our Gridworld position is $(2,3)$ and our action is $\\text{Up}$\n",
    "\n",
    "Then the total concatenated vector would be $(2,3,1,0,0,0)$\n",
    "\n",
    "$s = (2,3), a = \\text{Up} \\\\ (s,a) = (2,3,1,0,0,0)$\n",
    "\n",
    "And now we just have a simple vector so we can apply a feature expansion such as the $\\text{RBF}$ kernel as usual\n",
    "\n",
    "$\\varphi(s,a) = \\varphi((2,3,1,0,0,0))$\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Update Rule</h3>\n",
    "\n",
    "Once we've done that, the process of updating the wait vector $W$ is just as simple as it was for the state value\n",
    "\n",
    "Again, we have some target $G$ and we want to minimize the squared error using stochastic gradient descent\n",
    "\n",
    "So for a single sample, our loss will be \n",
    "\n",
    "$$\\large J = (G-\\hat Q(s,a))^2$$\n",
    "\n",
    "Then our gradient with respect to $W$ is \n",
    "\n",
    "$$\\large \\nabla_w J = -2(G-w^Tx)x$$\n",
    "\n",
    "And at this point our gradient update rule is the same as usual\n",
    "\n",
    "In fact, no different from before\n",
    "\n",
    "$$\\large w \\leftarrow w + \\alpha(G-w^Tx)x$$\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Types of Targetes</h3>\n",
    "\n",
    "Again, function approximation for control applies to all the methods we've learned previously in the series\n",
    "\n",
    "So our target cepends on the method we are doing\n",
    "\n",
    "$$\\large \\begin{array}{c|c} \\text{Method} & \\text{Target} \\\\ \\hline \\text{Monte Carlo Target} & G = r+ \\gamma r^\\prime + \\gamma^2 r'' + \\ldots \\\\ \\text{SARSA Target} & G = r + \\gamma Q(s',a') \\\\ \\text{Q-Learning Target} & G = r + \\gamma \\max\\limits_{a^\\prime} Q(s',a') \\end{array}$$\n",
    "\n",
    "\n",
    "OK, so hopefully we can agree that this is pretty simple\n",
    "\n",
    "In this notebook we'll be focusing on Q-Learning, but as an exercise we'll be assigned to implement the other methods as well :)\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Q-Learning with Function Approximation Pseudocode</h3>\n",
    "\n",
    "So although we can probably do this ourselves by now, let's look at the pseudocode for completeness\n",
    "\n",
    "$\\text{Initialise: w = zeros(D) # or random} \\\\ \\text{Loop until convergance:} \\\\ \\qquad \\text{s = env.reset()} \\\\ \\qquad \\text{while s in not teminal:} \\qquad \\qquad \\text{a ~ epsilon_greedy(Q,s) consider how we'd implement this} \\\\ \\qquad \\qquad s',r = env.move(a) \\\\ \\qquad \\qquad \\text{if s' is terminal:} \\\\ \\qquad \\qquad \\qquad y = r \\\\ \\qquad \\qquad \\text{else} \\\\ \\qquad \\qquad \\qquad y = r + \\gamma \\max\\limits_{a'} \\{w^T \\varphi(s',a')\\}  \\\\ \\qquad \\qquad w = w + \\alpha(y-w^T \\varphi(s,a)) \\varphi(s,a) \\\\ \\qquad \\qquad s = s'$\n",
    "\n",
    "To start, we initialise a random weight vector $w$, which is the same size as the concatenated vector of $s$ and $a$ together\n",
    "\n",
    "This also effectively initialises our policy which is derived from $Q$\n",
    "\n",
    "Next, we do a loop over some number of episodes\n",
    "\n",
    "Inside the loop, we reset the environment and obtain the initial state\n",
    "\n",
    "Next, we enter an inner loop over each step of the episode\n",
    "\n",
    "Inside this loop, we use Epsilon greedy to determine the next action to take\n",
    "\n",
    "Then we perform this action in the environment\n",
    "\n",
    "This gives us back the next state $s'$ and the reward $r$\n",
    "\n",
    "Next, we assign the target value, if $s'$ is a terminal state, then the target is just the reward $r$,  otherwise it's $y = r + \\gamma \\max\\limits_{a'} \\{w^T \\varphi(s',a')\\}$\n",
    "\n",
    "Next, we update $w$ using our gradient ascent formula\n",
    "\n",
    "Finally, we assign $s'$ to be $s$ for the next iteration of the loop\n",
    "\n",
    "OK, so that's it for Q-Learning with function approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>code</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.kernel_approximation import RBFSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld:\n",
    "    def __init__(self,rows,cols,start_pos):\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "        self.pos = start_pos\n",
    "        self.start_pos = start_pos\n",
    "    \n",
    "    def current_state(self):\n",
    "        return self.pos\n",
    "    \n",
    "    def set_state(self,state):\n",
    "        self.pos = state\n",
    "        \n",
    "    def set_actions_rewards(self,actions,rewards):\n",
    "        self.actions = actions\n",
    "        self.rewards = rewards\n",
    "        \n",
    "    def all_states(self,):\n",
    "        return [(i,j) for i in range(self.rows) for j in range(self.cols)]\n",
    "    \n",
    "    def is_terminal(self,state):\n",
    "        # we cant perform an action in a terminal state\n",
    "        # so we expect not to find it in the keys\n",
    "        return state not in self.actions.keys()\n",
    "    \n",
    "    def game_over(self):\n",
    "        return self.is_terminal(self.pos)\n",
    "    \n",
    "    def next_state(self,s,a):\n",
    "        # return next state should we take action a\n",
    "        # but do not take that action\n",
    "        i,j = s\n",
    "        # if we are allowed to do this action in our current position\n",
    "        if a in self.actions.get(s,[]): \n",
    "            if a == 'R':\n",
    "                j += 1\n",
    "            if a == 'L':\n",
    "                j -= 1\n",
    "            if a == 'U':\n",
    "                i -= 1\n",
    "            if a == 'D':\n",
    "                i += 1\n",
    "        return (i,j)\n",
    "    \n",
    "    def move(self,a):\n",
    "        # return next state should we take action a\n",
    "        # this time we actually make the move\n",
    "        # and thus return reward\n",
    "        i,j = self.pos\n",
    "        # if we are allowed to do this action in our current position\n",
    "        if a in self.actions.get(self.pos,[]): \n",
    "            if a == 'R':\n",
    "                j += 1\n",
    "            if a == 'L':\n",
    "                j -= 1\n",
    "            if a == 'U':\n",
    "                i -= 1\n",
    "            if a == 'D':\n",
    "                i += 1\n",
    "        self.pos = (i,j)\n",
    "        # if no reward return 0\n",
    "        return self.rewards.get(self.pos,0)\n",
    "    \n",
    "    # lets add methods to print values and actions\n",
    "    def print_values(self,V):\n",
    "        for i in range(self.rows):\n",
    "            print('-'*9*self.rows)\n",
    "            for j in range(self.cols):\n",
    "                v = V[i,j]\n",
    "                if v >= 0:\n",
    "                    # if 0 or +ve, add space so it aligns well when we have -\n",
    "                    print(\" %.2f|\" %v,end=\"\")\n",
    "                else:\n",
    "                    print(\"%.2f|\" %v,end=\"\")\n",
    "            print(\"\")\n",
    "    \n",
    "    def print_policy(self,P):\n",
    "        for i in range(self.rows):\n",
    "            print('-'*6*self.rows)\n",
    "            for j in range(self.cols):\n",
    "                print(\" %s |\" %P.get((i,j),' '),end=\"\")\n",
    "            print(\"\")\n",
    "                \n",
    "    def state_to_loc(self,state): # convert state tupe (0,1) to location 1\n",
    "        return state[0]*self.rows + state[1]\n",
    "    \n",
    "    def reset(self):\n",
    "        self.pos = self.start_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standrad_grid():\n",
    "    g = GridWorld(3,4,(2,0))\n",
    "    rewards = {(0,3):1,(1,3):-1}\n",
    "    actions = {\n",
    "        (0,0): ('D','R'),\n",
    "        (0,1): ('L','R'),\n",
    "        (0,2): ('L','D','R'),\n",
    "        (1,0): ('U','D'),\n",
    "        (1,2): ('U','D','R'),\n",
    "        (2,0): ('U','R'),\n",
    "        (2,1): ('L','R'),\n",
    "        (2,2): ('L','R','U'),\n",
    "        (2,3): ('L','U')\n",
    "    }\n",
    "    g.set_actions_rewards(actions,rewards)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Approx_control:\n",
    "    def gather_samples(self,g,num_episodes=10000):\n",
    "        samples = []\n",
    "        all_actions = ['L','R','U','D']\n",
    "        a_one_hot = np.zeros(len(all_actions),dtype='int32')\n",
    "        for epsiodes in range(num_episodes):\n",
    "            g.reset()\n",
    "            s = g.current_state()\n",
    "            while not g.game_over():\n",
    "                i = np.random.choice(len(all_actions))\n",
    "                a = all_actions[i]\n",
    "                _ = g.move(a)\n",
    "                # one hot encode a\n",
    "                a_one_hot[:] = 0\n",
    "                a_one_hot[i] = 1\n",
    "                samples.append(s+tuple(a_one_hot))\n",
    "                s = g.current_state()\n",
    "\n",
    "        return samples\n",
    "    \n",
    "    def build_phi(self,g,num_episodes=10000,D=100):\n",
    "        # first we gather sum samples\n",
    "        samples = self.gather_samples(g,num_episodes)\n",
    "        # next we can build our RBF Sampler\n",
    "        rbf = RBFSampler(n_components = D)\n",
    "        rbf.fit(samples)\n",
    "        self.rbf = rbf\n",
    "        self.D = D\n",
    "                \n",
    "        # we can also initialise the weights here\n",
    "        # since we know now D\n",
    "        self.W = np.zeros(D)\n",
    "        \n",
    "    def epsilon_greedy(self,best_action,eps=0.1):\n",
    "        if np.random.random() < eps:\n",
    "            return np.random.choice(['L','R','U','D'])\n",
    "        else:\n",
    "            return best_action\n",
    "        \n",
    "    def phi(self,s):\n",
    "        if type(s) == tuple:\n",
    "            s = [s]\n",
    "        return self.rbf.transform(s).squeeze()\n",
    "    \n",
    "    def max_Q(self,s,get=None):\n",
    "        all_actions = ['L','R','U','D']\n",
    "        # we need to calculate Q(s,a) for each action a and given state s\n",
    "        # the best action is the argmax\n",
    "        actions_one_hot = np.diag(np.ones(len(all_actions)))\n",
    "        s = np.repeat([s],len(all_actions),axis=0)\n",
    "        s_a = np.hstack((s,actions_one_hot))\n",
    "        \n",
    "        Q = self.phi(s_a) @ self.W\n",
    "        \n",
    "        best_action = all_actions[np.argmax(Q)] # the argmax returns the index not the action itself\n",
    "        max_Q = np.max(Q)\n",
    "        \n",
    "        if get == 'value':\n",
    "            return max_Q\n",
    "        if get == 'action':\n",
    "            return best_action\n",
    "        \n",
    "        return max_Q,best_action\n",
    "        \n",
    "                \n",
    "    def train(self,g,episodes=20000,gamma=0.9,alpha=0.1):\n",
    "        all_states = g.all_states()\n",
    "        all_actions = ['L','R','U','D']\n",
    "        # lets keep track of mse\n",
    "        mse = np.zeros(episodes)\n",
    "        # lets also do the same for the rewards\n",
    "        rewards = np.zeros(episodes)\n",
    "        \n",
    "        # create array to store one hot encoded actions\n",
    "        a_one_hot = np.zeros(len(all_actions)).astype('int')\n",
    "        # we already initialised W\n",
    "        # so that if we train more we can begin from where we left off\n",
    "        for episode in range(episodes):\n",
    "            if (episode+1)%1000 == 0:\n",
    "                print('Episode: ',episode+1,'/',episodes)\n",
    "            g.reset()\n",
    "            s = g.current_state()\n",
    "            n_steps = 0\n",
    "            while not g.game_over():\n",
    "                a = self.epsilon_greedy(self.max_Q(s,get='action'))\n",
    "                r = g.move(a)\n",
    "                rewards[episode] += r\n",
    "                s_prime = g.current_state()\n",
    "                \n",
    "                # one hot encode a\n",
    "                a_one_hot[:] = 0\n",
    "                a_one_hot[all_actions.index(a)] = 1\n",
    "                s_a = s + tuple(a_one_hot)\n",
    "                \n",
    "                if g.is_terminal(s_prime):\n",
    "                    y = r\n",
    "                else:\n",
    "                    y = r + gamma * self.max_Q(s_prime,get='value')\n",
    "                delta = y-self.W@self.phi(s_a)     \n",
    "                self.W = self.W + alpha*delta*self.phi(s_a) \n",
    "                s = s_prime\n",
    "                # calculate mse\n",
    "                mse[episode] += delta**2\n",
    "                n_steps += 1\n",
    "            mse[episode] /= n_steps\n",
    "            \n",
    "        plt.title('mse per episode')\n",
    "        plt.plot(mse)\n",
    "        plt.show()\n",
    "\n",
    "        plt.title('total rewards per episode')\n",
    "        plt.plot(rewards)\n",
    "        plt.show()\n",
    "                \n",
    "    def get_value_policy(self,g):\n",
    "        all_actions = ['L','R','U','D']\n",
    "        V = np.zeros((g.rows,g.cols))\n",
    "        pi = {}\n",
    "\n",
    "        for i in range(g.rows):\n",
    "            for j in range(g.cols):\n",
    "                s = (i,j)\n",
    "                # use max_Q to get V(s) and a*\n",
    "                if not g.is_terminal(s):\n",
    "                    v,a = self.max_Q(s)\n",
    "                    V[i,j] = v\n",
    "                    pi[i,j] = a\n",
    "        return V,pi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = standrad_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  1000 / 20000\n",
      "Episode:  2000 / 20000\n",
      "Episode:  3000 / 20000\n",
      "Episode:  4000 / 20000\n",
      "Episode:  5000 / 20000\n",
      "Episode:  6000 / 20000\n",
      "Episode:  7000 / 20000\n",
      "Episode:  8000 / 20000\n",
      "Episode:  9000 / 20000\n",
      "Episode:  10000 / 20000\n",
      "Episode:  11000 / 20000\n",
      "Episode:  12000 / 20000\n",
      "Episode:  13000 / 20000\n",
      "Episode:  14000 / 20000\n",
      "Episode:  15000 / 20000\n",
      "Episode:  16000 / 20000\n",
      "Episode:  17000 / 20000\n",
      "Episode:  18000 / 20000\n",
      "Episode:  19000 / 20000\n",
      "Episode:  20000 / 20000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Approx_control()\n",
    "model.build_phi(g)\n",
    "model.train(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      " 0.81| 0.90| 1.00| 0.00|\n",
      "---------------------------\n",
      " 0.73| 0.00| 0.91| 0.00|\n",
      "---------------------------\n",
      " 0.66| 0.61| 0.69| 0.19|\n",
      "------------------\n",
      " R | R | R |   |\n",
      "------------------\n",
      " U |   | U |   |\n",
      "------------------\n",
      " U | L | U | L |\n"
     ]
    }
   ],
   "source": [
    "V,pi = model.get_value_policy(g)\n",
    "g.print_values(V)\n",
    "g.print_policy(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try again with the negative grid\n",
    "# to see if our model learns to take the shortest path\n",
    "\n",
    "def negative_grid(step_cost=-0.1):\n",
    "    # in this game we want to try to minimize the number of moves\n",
    "    # so we will penalize every move\n",
    "    g = standrad_grid()\n",
    "    g.rewards.update({\n",
    "        (0, 0): step_cost,\n",
    "        (0, 1): step_cost,\n",
    "        (0, 2): step_cost,\n",
    "        (1, 0): step_cost,\n",
    "        (1, 2): step_cost,\n",
    "        (2, 0): step_cost,\n",
    "        (2, 1): step_cost,\n",
    "        (2, 2): step_cost,\n",
    "        (2, 3): step_cost,\n",
    "    })\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = negative_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  1000 / 20000\n",
      "Episode:  2000 / 20000\n",
      "Episode:  3000 / 20000\n",
      "Episode:  4000 / 20000\n",
      "Episode:  5000 / 20000\n",
      "Episode:  6000 / 20000\n",
      "Episode:  7000 / 20000\n",
      "Episode:  8000 / 20000\n",
      "Episode:  9000 / 20000\n",
      "Episode:  10000 / 20000\n",
      "Episode:  11000 / 20000\n",
      "Episode:  12000 / 20000\n",
      "Episode:  13000 / 20000\n",
      "Episode:  14000 / 20000\n",
      "Episode:  15000 / 20000\n",
      "Episode:  16000 / 20000\n",
      "Episode:  17000 / 20000\n",
      "Episode:  18000 / 20000\n",
      "Episode:  19000 / 20000\n",
      "Episode:  20000 / 20000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEICAYAAAC+iFRkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAfhElEQVR4nO3deZhcdZ3v8fcnCQlkARLSQMhiWCIQVJYJy4wjwqhIVMRlRuFxREedXB7lKi53jOMV8TqKXpV5Hh0wRkFc0OBCNFcSEwTZhiXpQEIIJBCykM7aSUg6e3r53j/qdFKpru4+3V1d1anzeT1PP111zvmd861T3Z/61a9OnaOIwMzMqlu/ShdgZma9z2FvZpYBDnszswxw2JuZZYDD3swsAxz2ZmYZ4LA3qxBJ0yR9pcTr/Kikx0q5TqsOAypdgFlWRcT1la7BssM9e7OUJLlzZEcsh72VjaTVkv6XpGcl7ZZ0h6STJM2RtFPSXyQNT5Y9WtIvJW2VtF3SAkknJfOOS9pukLRO0n9I6t/ONm+W9DtJ9yTbeFrSuXnzT5H0e0n1klZJ+nSRtr+U1AB8tMj6B0n6rqRXJG1KhmaOSeZdJqlO0r9L2pI8/g/ltb1L0n8kt0dK+lPyWLdJelRSv2Te2ZIeSuYtlfTuvHWcIGmWpAZJ84HTC+o7S9L9yTqXS/pAN546qwIOeyu39wNvA14LXAXMAf4dGEnu77E1bD8CHAeMBU4Argf2JvN+BjQBZwDnA1cAn+hgm1cDvwVGAL8C/iDpqCRM/x+wGBgNvAW4UdLbC9r+DjgeuLvIur+dPJbzknpGAzflzT85eWyjk8c0XdKZRdbzeaAOqAFOSvZJSDoqqXEecCLwP4G789ZxG7APGAV8LPkBQNIQ4P7kMZ8IXAvcLumcDvaVVSmHvZXbDyJiU0SsAx4FnoqIZyJiPzCTXHgDNJIL+TMiojkiFkZEQ9K7nwzcGBG7I2Iz8J/ANR1sc2FE/C4iGoFbgaOBS4ALgZqI+D8RcSAiVgI/LljXExHxh4hoiYi9+SuVJOBfgc9GxLaI2Al8s0gtX4mI/RHxMHAfUKx33UgusF8TEY0R8WjkTlx1CTAU+FZS44PAn4Brk3cz7wduSvbFc+ReCFu9C1gdET+NiKaIeBr4PfCPHewrq1Ieg7Ry25R3e2+R+0OT278g16ufIel44JfAl4HXAEcBG3JZC+Q6LWs72ObBeRHRIqkOOAUI4BRJ2/OW7U/uRahN2yJqgMHAwrxalKyj1asRsTvv/ppk24W+A9wMzEvWNT0ivpUsuzYiWgrWMTrZ/oCCGtfk3X4NcHHB4xtAbt9axjjsrU9KeuFfA74maTwwG1ie/N4PjIyIppSrG9t6Ixm6GQOsJzcUtCoiJnRUSgfztpB7gToneadSzHBJQ/ICfxzwXJuN5N4VfB74fDLM8ldJC5I6x0rqlxf444AXgfrkMYwFluXNa7UWeDgi3tbBY7CM8DCO9UmSLpf0+mSoooHcMEdzRGwgN379PUnHSuon6XRJb+5gdX8j6X3J0TQ3knuxeBKYDzRI+qKkYyT1l/Q6SRemqTEJ3x8D/ynpxKTu0QVj/pB7wRoo6U3khlZ+W+TxvkvSGcnQUAPQnPw8BewG/i35nOEycp91zIiIZuBe4GZJgyVNJPe5QKs/Aa+V9OGk7VGSLpR0dprHZ9XFYW991cnkPhhtAF4AHiY3lANwHTAQeB54NVluVAfr+iPwwWTZDwPvS8bFm8kF53nAKnI99Z+Q+2A4rS8CK4AnkyN2/gLkfwC7MdnuenIf8F4fEcvarAUmJG13AU8At0fEQxFxAHg3uc8ptgC3A9flreMGckNfG4G7gJ+2rjB5t3AFuc8Q1ifLfBsY1IXHZ1VCvniJVTNJN5P7kPefK7Dty4BfRsSYcm/brJB79mZmGeCwNzPLAA/jmJllgHv2ZmYZ0CePsx85cmSMHz++0mWYmR0xFi5cuCUiatqb3yfDfvz48dTW1la6DDOzI4akNR3N9zCOmVkGOOzNzDLAYW9mlgEOezOzDHDYm5llgMPezCwDHPZmZhngsM+4eUs3snnnvkqXYWa9zGGfYY3NLUz5xUKunf5kpUsxs15WdWG/pG4HDfsaK13GEaElOQne2m17O1nSzI50VRf2V/3XY1x3x/xKl2Fm1qdUXdgDLFq7vdIlmJn1KVUZ9mZmdjiHvZlZBjjszcwywGFvZpYBDnsj8HWIzaqdwz7DhCpdgpmVicPezCwDHPZmZhngsDczywCHvZlZBjjszcwywGFvZpYBDnsjfJi9WdVz2GeYfJi9WWY47M3MMsBhb2aWAQ57M7MMSBX2kq6UtFzSCklTi8z/kKRnk5/HJZ2bN2+1pCWSFkmqLWXxZmaWzoDOFpDUH7gNeBtQByyQNCsins9bbBXw5oh4VdJkYDpwcd78yyNiSwnrNjOzLkjTs78IWBERKyPiADADuDp/gYh4PCJeTe4+CYwpbZlmZtYTacJ+NLA2735dMq09Hwfm5N0PYJ6khZKmtNdI0hRJtZJq6+vrU5RlpeLD7M2qX6fDOFD0pOdF80HS5eTC/u/zJr8xItZLOhG4X9KyiHikzQojppMb/mHSpEnOnzLwYfZm2ZGmZ18HjM27PwZYX7iQpDcAPwGujoitrdMjYn3yezMwk9ywkJmZlVGasF8ATJB0qqSBwDXArPwFJI0D7gU+HBEv5k0fImlY623gCuC5UhVvZmbpdDqMExFNkm4A5gL9gTsjYqmk65P504CbgBOA25X7Dn5TREwCTgJmJtMGAL+KiD/3yiMxM7N2pRmzJyJmA7MLpk3Lu/0J4BNF2q0Ezi2cbmZm5VW136Bds3V3pUswM+szqjbs73hsVaVLMDPrM6o27M3M7BCHvRG+eolZ1XPYm5llgMPezCwDHPZmZhngsDczywCHvZlZBjjszcwyoGrD3qfvNTM7pGrD3tLzUfZm1c9hb2aWAQ57M7MMqNqwb2rx4ISZWauqDfu7n3ql0iWYmfUZVRv2ZmZ2SFWF/azFba6DbmZmVFnY/+KJ1ZUuwcysT6qqsPdp2bvH+82s+lVV2JuZWXEOezOzDHDYm5llgMPezCwDHPZmZhlQVWHvg0rMzIpLFfaSrpS0XNIKSVOLzP+QpGeTn8clnZu2rZmZ9b5Ow15Sf+A2YDIwEbhW0sSCxVYBb46INwBfB6Z3oa2ZmfWyND37i4AVEbEyIg4AM4Cr8xeIiMcj4tXk7pPAmLRtzcys96UJ+9HA2rz7dcm09nwcmNPVtpKmSKqVVFtfX5+iLDMzSytN2Be7nGvRz0IlXU4u7L/Y1bYRMT0iJkXEpJqamhRlpSvUzMxgQIpl6oCxeffHAG1OLynpDcBPgMkRsbUrbc3MrHel6dkvACZIOlXSQOAaYFb+ApLGAfcCH46IF7vS1szMel+nPfuIaJJ0AzAX6A/cGRFLJV2fzJ8G3AScANwuCaApGZIp2raXHouPszcza0eaYRwiYjYwu2DatLzbnwA+kbZtucxbupErzjm5Eps2M+tTquobtIWeXLmt0iWYmfUJVRX2S9btqHQJRxQPe5llR1WF/YGmlkqXYGbWJ1VV2BcK913NzIAqD3szM8tx2JuZZYDD3swsA6o67MND9mZmQJWHvZmZ5TjszcwywGFvZpYBDvtOzJj/CjfP6rVzt5mZlYXDvhNT713CXY+vrnQZZmY94rA3M8sAh72ZWQZUddh7+MXMLKeqw97MzHIc9mZmGeCwNzPLAIe9mVkGOOzNzDLAYW9mlgEOezOzDHDYm5llgMPezCwDHPZmZhmQKuwlXSlpuaQVkqYWmX+WpCck7Zf0hYJ5qyUtkbRIUm2pCjczs/QGdLaApP7AbcDbgDpggaRZEfF83mLbgE8D72lnNZdHxJaeFmtmZt2Tpmd/EbAiIlZGxAFgBnB1/gIRsTkiFgCNvVCjmZn1UJqwHw2szbtfl0xLK4B5khZKmtLeQpKmSKqVVFtfX9+F1ZuZWWfShL2KTIsubOONEXEBMBn4lKRLiy0UEdMjYlJETKqpqenC6ju2esvukq3LzOxIlSbs64CxeffHAOvTbiAi1ie/NwMzyQ0Llc1l332onJszM+uT0oT9AmCCpFMlDQSuAWalWbmkIZKGtd4GrgCe626xZmbWPZ0ejRMRTZJuAOYC/YE7I2KppOuT+dMknQzUAscCLZJuBCYCI4GZklq39auI+HPvPBQzM2tPp2EPEBGzgdkF06bl3d5IbninUANwbk8KNDOznvM3aM3MMsBhb2aWAQ57M7MMcNibmWWAw97MLAMc9mZmGeCwNzPLAIe9mVkGOOzNzDLAYW9mlgGZCPt9jc2VLsHMrKIyEfazFqU+I7OZWVXKRNhv33ug0iWYmVVUJsLezCzrHPZmZhngsDczywCHvZlZBjjszcwyIBNhH1HpCszMKisTYX/LnGUArN6ym9/Wrq1wNWZm5ZfqguPV4qofPMbO/U3806SxlS7FzKysMtGzb7Vzf1OlSzAzq4hMhb2ZWVY57M3MMsBhb2aWAanCXtKVkpZLWiFpapH5Z0l6QtJ+SV/oSlszM+t9nYa9pP7AbcBkYCJwraSJBYttAz4NfLcbbc3MrJel6dlfBKyIiJURcQCYAVydv0BEbI6IBUBjV9uWy+4+ciTOq7sP0NjcUukyzCxj0oT9aCD/m0h1ybQ0UreVNEVSraTa+vr6lKtPb9nGnYfd39fYzMYd+0q+nc6c//X7+cyMZ8q+XTPLtjRhryLT0p6AIHXbiJgeEZMiYlJNTU3K1XdPU3MLH7trAZfc8kCvbqc9s5dsrMh2zSy70nyDtg7I/8rpGCDtdf560rbEDr3GnPHlOZUpwcysQtL07BcAEySdKmkgcA0wK+X6e9LWzMxKpNOefUQ0SboBmAv0B+6MiKWSrk/mT5N0MlALHAu0SLoRmBgRDcXa9taDsa7x2UDNsiPVidAiYjYwu2DatLzbG8kN0aRqWwkONjPLMn+D1swsAxz2ZmYZkJmw39vYXOkSzMwqJjNh/4XfLq50CWZmFZOZsN/UsL/SJZiZVUxmwt7MLMsc9mZmGeCwNzPLAId9N7W0BLv6yGmTzcw647Dvpm/MfoHXfXUuew/4kE4z6/sc9t0085l1AOw54N69mfV9Dnszswxw2JuZZYDD3swsAxz2eTbv3Mf4qfdx//ObUrfxmZPN7EiQ+bBftHb7wdtL1zcA8Msn11SqHDOzXpH5sH/Pbf9d6RLMzHpd5sP+MD0Yk9nf1MwrW/eUrhYzsxJy2Bchdb3N536zmEu/81f2+bz5ZtYHOezzRA+69o8srwfgQHNLqcoxMysZh32J+cLmZtYXOezziPTjN22W7MbQj5lZuTjs8/RkGCdvJWbWgabmFg40ebiz3Bz2RXSnk17qjv2OvY2s3rK7xGs1q7z33v44r/3fcypdRuY47POUYry9JO8OgKt+8BiXffehkqzLrC9Zsm5HpUvIJId9EerGsZfdadORV7b5mH0zK51UYS/pSknLJa2QNLXIfEn6fjL/WUkX5M1bLWmJpEWSaktZfKmVpGdf4jH7Pzyzzsfum1mPdRr2kvoDtwGTgYnAtZImFiw2GZiQ/EwBflgw//KIOC8iJvW85L5h6+4Dh90vccf+oBvvWcS35izrnZWbWWak6dlfBKyIiJURcQCYAVxdsMzVwM8j50ngeEmjSlxrr+tOYBf25HvjYJzNO/f1wlrNLEvShP1oYG3e/bpkWtplApgnaaGkKe1tRNIUSbWSauvr61OUVXp99QtRXTn+38ysmDRhXyxpCmOxo2XeGBEXkBvq+ZSkS4ttJCKmR8SkiJhUU1OToqze42g1s2qTJuzrgLF598cA69MuExGtvzcDM8kNC/VJPenY9+oLhF99zKyH0oT9AmCCpFMlDQSuAWYVLDMLuC45KucSYEdEbJA0RNIwAElDgCuA50pYf6/oyth94XH10VfHgsws0zoN+4hoAm4A5gIvAL+JiKWSrpd0fbLYbGAlsAL4MfDJZPpJwGOSFgPzgfsi4s8lfgwlsWt/E5sach+EdievS32cfb6d+5ranffSpp187jeLaG7xi4yZtW9AmoUiYja5QM+fNi3vdgCfKtJuJXBuD2vsdTv3NfKuHzzGmuTiIwFMe/hlrr1wXOeNy3A0ziMvtv+B9Q2/eoblm3Yy5dLTOOvkY3th62ZWDVKFfbV7/c3zDrv/+MtbeHDZ5oPXpO1Ia7hXeljdo0dm1hGfLqGI1jPy7drX2OW25Q7d1tEjh72ZdcRhX0Tr+Hua/GwN2V4csk+lVCdgM7Pq5LAvojW3u9NbLnfo9uYHw2ZWPRz2RXTv0MvKhq6HccysIw77DnQrP8s9Zl/ezZnZEcphX0Rjc/rErnSP2qM4ZpaGw76HPHpiZkcCh30PbdyR+9ZtpXvYlX6HYWZ9m8O+A2nOc/P+Hz7O1l37D7XpzYKKOHicvd9jmFkHHPYl8Mm7n2bHnq5/AasUWs917569mXXEYd+BRa9sT7XcU6u2caA5963bjkK3FGfEbB02anWoZ29m1j6HfQd27m//bJM9tXbbHsZPvY/Fa9O9oAA88MImLrnlAR5ctungNB+MY2ZpOOxT2tfYzMxn6jq9HmzasfOHkzNZfvSn8xk/9T52pXhhWZS8MCyp6/wEbWZm+XzWy5TO+kruNPxnjzqWOZ95U4/X1zr88moy1r9m627OOeW4Dtu0jgL1K9Kd90VTzKwj7tl30QsbGvi7Wx5od37azO1XcKxmmnYtyUKHNe3CSdvMLLsc9t2wfkfHQzlpFHbO04T9wbPw5KV9660Fq7ax50ATS9fv6HFtZlZ9HPYl1tFVpfK16dmn6JsX7dknbpmzjGumP8k7v/8YO7txHn4zq25VFfbfeO/rKl0CU+9dkm7BgsBONfzTeu78vMaL8o7mebYu16vf19iSrgYzy4yqCvuLTx1R6RIA+IfvPcTF3/wLf1y0rt1l2gzjpFhv6zLFPqDN19jssDezw1VV2A8a0L/SJQCwsn43mxr285kZi9pdpvCiIy2ddO3nr9pGS0tumQeWbWb81PtYu21P0WWnP7KS5pZgX2Nzm3mfmfEMP3r45c4egplVmaoK+zHDj6l0CW1Mf6R4sBb2zjsbxvnAj57gJ4+tAnLBDzDzmeLvHNZv38tn71l08HDRVjv2NPLHReu5Zc6yFJWbWTWpquPs++Il+r45exnvfMMpfG3WUhas3nZwettSu37w5I8fWVl0enNLMGvx+rbT815R/uWn8xkxZFCXt2lmR6aqCvu+6hv3Pc+85zcdNu2z9yw+7H5LNw6Ub+90Ds3tvE3on/cK89flhx819OhL9cx8eh23fvC8rhdiZn1eVQ3j9FVpTqhWyi/ANue9cuR/s/bFzTvbbfPhO+Zz7zPrePqVV0tXiJn1Ge7Zl0GaL2F94EdPAHDtReP49fxXerS9hr2HjrNvCWjYc4DhQwbyT9Oe6LTt+25/nKVfeztDBvlPw6yapOrZS7pS0nJJKyRNLTJfkr6fzH9W0gVp29rhehr0AIvrDn2L9tGX6jn/6/cfdqbMzpzz1bm89daH+fafl/HAC5t4cdNOXtm6h5aWYNnG3jkJ277GZl7/1bnMW7rxsOnrtu/lDTfPZervnz3sHUuh3fub+Nef17Jhx96S1fT1Pz3PrfOWl2x9R5rn1zfwzz95irufWnPYft29v4kGf3GPiKDu1eJHxPVFnXbfJPUHbgPeBtQBCyTNiojn8xabDExIfi4GfghcnLKt9aKP/nQBAB+7q7ZL7VZs3sWKzbu61ObNr63ho383noVrXuVd545izpKNnDf2eIYePYAThgxk+OCB9JNobGmhv0T9rv2MGDKQE4YMZP32vezc38Q3Zr/AFeecfHCdv6uto2FfEzMWrOWS007gPeeP5pWtuX+wcScMPrjcnOc2cv/zmxh29ABu/cChzx1e3X0ACY4fPLBLjwXgjuTop89dcWaHy33unkWcefIw/sebT0+13uaWYMHqbVxy2glF5y9YvY3XnXIcxwzs/qHEEcH2PY0MH1L8ca/ZupsRQwYy7Oijis5/cNmmg38zj63YAsDqb72TiOCcr84F4AfXns9V557S7Rp7S0tL0K+zL6MUaGxu4Zyb5vL195zDBy8c1+nyD7ywiY//7ND/1C3vez1funcJ5409nhc37WTq5LM4b+zxbGrYT82wQRzVX5xzynH86dn1CDF6+DGcN/Z49hxoon8/leWwcXV2tkRJfwvcHBFvT+5/CSAibslb5kfAQxHx6+T+cuAyYHxnbYuZNGlS1NZ2LZxajZ96X7fa2ZFnwolDCWjzonRazRD6Kfc945eSeWecOPTg/GJ/88X+C1bW727TFtp+Ia7YNiD33Yk9+5sZdvSAossXa7N7fxMbkmG/CQXzuqJ1G8MHH8UJQwe1qbt1fnvbeKnIC/0ZJw5tu69HDqFfP3Xpugqt6x43YjCDBpT2Y8PWdY8ZfgzHHJU+QJtbgpVbDn++8/9+CvdTsf3TmYED+nGg6dAXHk8dOYRVyTYnnDiUlzbvYuyIY3j03/6hy+sGkLQwIia1Nz/NwOxoYG3e/TpyvffOlhmdsm1roVOAKQDjxnX+ytqepV97+8Geh1WnYYMGsHN/ExNOyv0Drqzfxek1Qw+Fbs1QBvTPxc+abXtoam7hzJOGtV2ROrzLhu37COKwtsXOYfTS5l2MGDKw6DZWb91NzbBBDM7rpZ9y/DE8/GI9bz37pINhF8TB02Dct2QDE0cdy/iRg9usL60RQwby1Krcu4d+Upu6X9q8i5OPPfrgPiy0fW8j9Tv3HzbtzJOGMW7EYB5ctvngtLNHHdvl6x/vOdDMuu17GTP8GI4fXPydRXcde8xRLFzzKq8ffVzRc0h1ZOWW3Zx18jBOrxl68DHt3NfExoZ9bfbToKP68dy6dEOaAwf0IyK4cPxw/nvF1oPTzx417FDYnzSUddv30rWXza5JE/bFtl747La3TJq2uYkR04HpkOvZp6irqCGDBrD6W+/sbnOzirut0gVYVUoT9nXA2Lz7Y4DCb+y0t8zAFG3NzKyXpRkwWwBMkHSqpIHANcCsgmVmAdclR+VcAuyIiA0p25qZWS/rtGcfEU2SbgDmAv2BOyNiqaTrk/nTgNnAO4AVwB7gXzpq2yuPxMzM2tXp0TiV0JOjcczMsqizo3F8ugQzswxw2JuZZYDD3swsAxz2ZmYZ0Cc/oJVUD6zpZvORwJYSllMqrqtrXFfXuK6uqca6XhMRNe3N7JNh3xOSajv6RLpSXFfXuK6ucV1dk8W6PIxjZpYBDnszswyoxrCfXukC2uG6usZ1dY3r6prM1VV1Y/ZmZtZWNfbszcysgMPezCwDqibsy31hc0ljJf1V0guSlkr6TDL9ZknrJC1Kft6R1+ZLSX3LJb09b/rfSFqSzPu+1NVr7LSpbXWyvkWSapNpIyTdL+ml5PfwctYl6cy8fbJIUoOkGyuxvyTdKWmzpOfyppVs/0gaJOmeZPpTksb3oK7vSFom6VlJMyUdn0wfL2lv3n6bVua6Sva8lbiue/JqWi1pUQX2V3vZUNm/sYg44n/InT75ZeA0chdMWQxM7OVtjgIuSG4PA14EJgI3A18osvzEpK5BwKlJvf2TefOBvyV3Za85wOQe1rYaGFkw7f8CU5PbU4Fvl7uugudrI/CaSuwv4FLgAuC53tg/wCeBacnta4B7elDXFcCA5Pa38+oan79cwXrKUVfJnrdS1lUw/3vATRXYX+1lQ0X/xqqlZ38RsCIiVkbEAWAGcHVvbjAiNkTE08ntncAL5K65256rgRkRsT8iVpE79/9FkkYBx0bEE5F75n4OvKcXSr4a+Fly+2d526hEXW8BXo6Ijr4l3Wt1RcQjwLYi2yvV/slf1++At6R591GsroiYFxFNyd0nyV3trV3lqqsDFd1frZL2HwB+3dE6eqmu9rKhon9j1RL27V3wvCySt1DnA08lk25I3nbfmfdWraOLstcVmd4TAcyTtFC5C7kDnBS5q4eR/D6xAnW1uobD/wkrvb+gtPvnYJskqHcAJ5Sgxo+R6921OlXSM5IelvSmvG2Xq65SPW+9sb/eBGyKiJfyppV9fxVkQ0X/xqol7FNf2LzkG5aGAr8HboyIBuCHwOnAecAGcm8lO6qxN2p/Y0RcAEwGPiXp0g6WLWddKHd5yncDv00m9YX91ZHu1FHyGiV9GWgC7k4mbQDGRcT5wOeAX0k6tox1lfJ5643n9FoO71CUfX8VyYZ2F21nOyWtrVrCPs1F0UtO0lHknsy7I+JegIjYFBHNEdEC/JjcEFNHNdZx+FvzHtceEeuT35uBmUkNm5K3ha1vXTeXu67EZODpiNiU1Fjx/ZUo5f452EbSAOA40g+DtCHpI8C7gA8lb+dJ3vJvTW4vJDfO+9py1VXi563U+2sA8D7gnrx6y7q/imUDFf4bq5awL/uFzZPxsTuAFyLi1rzpo/IWey/QeqTALOCa5FP0U4EJwPzk7dxOSZck67wO+GMP6hoiaVjrbXIf8D2XbP8jyWIfydtGWerKc1iPq9L7K08p90/+uv4ReLA1pLtK0pXAF4F3R8SevOk1kvont09L6lpZxrpK+byVrK7EW4FlEXFwCKSc+6u9bKDSf2OdfYJ7pPyQu+D5i+Resb9chu39Pbm3Tc8Ci5KfdwC/AJYk02cBo/LafDmpbzl5R5AAk8j9s7wM/BfJN5u7Wddp5D7ZXwwsbd0X5MbzHgBeSn6PKGddyfoGA1uB4/KmlX1/kXux2QA0kushfbyU+wc4mtww1QpyR1Oc1oO6VpAbm239G2s9AuP9yfO7GHgauKrMdZXseStlXcn0u4DrC5Yt5/5qLxsq+jfm0yWYmWVAtQzjmJlZBxz2ZmYZ4LA3M8sAh72ZWQY47M3MMsBhb2aWAQ57M7MM+P+HjGk7f8mw4wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Approx_control()\n",
    "model.build_phi(g)\n",
    "model.train(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      " 0.62| 0.80| 1.00| 0.00|\n",
      "---------------------------\n",
      " 0.46| 0.00| 0.80| 0.00|\n",
      "---------------------------\n",
      " 0.31| 0.46| 0.62| 0.44|\n",
      "------------------\n",
      " R | R | R |   |\n",
      "------------------\n",
      " U |   | U |   |\n",
      "------------------\n",
      " R | R | U | L |\n"
     ]
    }
   ],
   "source": [
    "V,pi = model.get_value_policy(g)\n",
    "g.print_values(V)\n",
    "g.print_policy(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we get the expected result\n",
    "# note that the policy for the state at the bottom right might not be sensible in other runs\n",
    "# this is due to the fact that it doesnot get visisted very often during the training process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll be looking at Q-Learning with function approximation again, but for a new environment\n",
    "\n",
    "---\n",
    "\n",
    "<h3>CartPole and OpenAI Gym</h3>\n",
    "\n",
    "This section will look at the CartPole environment, which is part of OpenAI Gym\n",
    "\n",
    "So before we look at the code, we're going to discuss some preliminary basics like what is gym, what is CartPole and so forth\n",
    "\n",
    "So first, if we've never heard of OpenAI Gym before, it's a Python library that contains many reinforcement learning environments from CartPole to Atari games\n",
    "\n",
    "Although if we want Atari games, we'll have to install some extra add ons\n",
    "\n",
    "Getting gym is very easy if we don't have it yet\n",
    "\n",
    "Simply use `pip install gym # like any other package`, as we normally would for any other Python library\n",
    "\n",
    "---\n",
    "\n",
    "<h3>What is CartPole?</h3>\n",
    "\n",
    "OK, so once we have gym, we have access to CartPole, but what is CartPole?\n",
    "\n",
    "CartPole is an environment where our job is to balance a pole that sits on top of a car\n",
    "\n",
    "<img src='extras/58.11.PNG' width='250'></img>\n",
    "\n",
    "We can imagine that this would be challenging for humans since the pole will just fall down\n",
    "\n",
    "Note that the pole rotates around a pivot point where it is attached to the cart\n",
    "\n",
    "Now the cart itself sits on a track, so it's limited to moving only left or right\n",
    "\n",
    "In fact, this setup is a classic problem in control theory and reinforcement learning\n",
    "\n",
    "If we ever have an opportunity to take a course and control theory, we'll get to work with CartPole in the real world\n",
    "\n",
    "That is a physical pool attached to a physical car that sits on a physical track\n",
    "\n",
    "<img src='extras/58.12.PNG' width='250'>\n",
    "\n",
    "Our state vector consists of sensor readings and our actions are real instructions to make a motor\n",
    "spin one way or the other\n",
    "\n",
    "---\n",
    "\n",
    "<h3>OpenAI Gym's CartPole</h3>\n",
    "\n",
    "So in this virtual version of CartPole, what are the state's actions and rewards?\n",
    "\n",
    "Well, we're encouraged to read the documentation for CartPole (see <a href='https://github.com/openai/gym/wiki/CartPole-v0'>here</a>), but here are the basics.\n",
    "\n",
    "The state is a four vector consisting of the carte's position and velocity and the pole's angle and angular velocity\n",
    "\n",
    "<img src='extras/58.13.PNG' width='350'>\n",
    "\n",
    "The actions are to either push the cart left or right\n",
    "\n",
    "<img src='extras/58.14.PNG' width='250'>\n",
    "\n",
    "The reward is $+1$ for every timestep that the pole and cart stay within a certain range\n",
    "\n",
    "<img src='extras/58.15.PNG' width='600'>\n",
    "\n",
    "When our pole falls down past a certain angle or the cart goes past a certain position, the episode will terminate and we'll stop receiving rewards\n",
    "\n",
    "<img src='extras/58.16.PNG' width='600'>\n",
    "\n",
    "Note that in previous iterations of gym, it was possible for this environment to go on indefinitely\n",
    "\n",
    "However, for newer versions, the episode automatically ends after we reach $200$ steps\n",
    "\n",
    "Therefore, the maximum reward we can achieve for episode is $200$\n",
    "\n",
    "There are ways to hack around the code to make it last forever, but we won't consider how to do that\n",
    "\n",
    "So essentially the thing we should notice about CartPole is that the state variables are now continuous values\n",
    "\n",
    "This makes it the perfect candidate for function approximation\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Using Gym in Python</h3>\n",
    "\n",
    "The next thing we're going to do is look at how to use Gym in Python code\n",
    "\n",
    "```python\n",
    "# instantiate enviroment\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "\n",
    "s = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    a = env.action_space.sample() # np.random.choice(2)\n",
    "    s_next, r, done, info = env.step(a)\n",
    "    env.render() # optional: displays enviroment\n",
    "```\n",
    "\n",
    "We'll see that it's very similar to what we've done in this series, so the changes we need to make are minimal\n",
    "\n",
    "And this example will assume that our policy is just to perform actions according to a uniform, random distribution\n",
    "\n",
    "So to start, we instantiate a new environment by calling `gym.make` passing in the name of the environment\n",
    "\n",
    "Again, note that we can get these names from the documentation\n",
    "\n",
    "Next, we call `env.reset()`, which puts our agent back into the initial state, and this function\n",
    "also returns that state\n",
    "\n",
    "So this is the same as the code in this series\n",
    "\n",
    "Next, we set a boolean variable called `done` to `False`, we'll be updating this variable as we go along and this will become `True` when we reach a terminal state\n",
    "\n",
    "Next, we enter a loop that exits when `done` becomes `True` \n",
    "\n",
    "Inside the loop, we call in `env.action_space.sample()` in order to select a random action\n",
    "\n",
    "Note that this is just one way of selecting an action \n",
    "\n",
    "In gym, discrete actions are encoded as integers\n",
    "\n",
    "So an alternative would have been to use `numpy` to select a random number from a set containing $0$ and $1$, `np.random.choice(2)`\n",
    "\n",
    "Next, we call the function in `env.step()` passing in the action `a` \n",
    "\n",
    "Note that this is similar to our `grid.move()` function\n",
    "\n",
    "The `step` function returns for items, the next state, the reward, the done flag and an info dictionary\n",
    "\n",
    "Typically, this info dictionary is empty so it can be ignored\n",
    "\n",
    "One optional step is to call the `env.render` function\n",
    "\n",
    "This will open a new window and show us visually the CartPole environment \n",
    "\n",
    "So we can actually see the CartPole system move around on the track and how well our agent controls it\n",
    "\n",
    "This also applies to video games\n",
    "\n",
    "So if we have a video game environment, we can call `env.render()` and it will show us the frames of a video game\n",
    "\n",
    "However, keep in mind that rendering video on our screen is slow, so we may not want to do this all the time, especially when our agent is training\n",
    "\n",
    "Note that at this point, the `done` flag is updated, so when this becomes `true`, our episode is terminated\n",
    "\n",
    "OK, so that's the interface for OpenAI Gym environments\n",
    "\n",
    "Hopefully we agree that it's nothing too unexpected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now again for cartpole\n",
    "# basically the same code but few modifications for the cartpole enviroment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "# now we import gym\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Approx_control:\n",
    "    def gather_samples(self,env,num_episodes=10000):\n",
    "        samples = []\n",
    "        action_space = env.action_space.n # number of possible acions\n",
    "        a_one_hot = np.zeros(action_space,dtype='int32')\n",
    "        for epsiodes in range(num_episodes):\n",
    "            s = env.reset()\n",
    "            done = False\n",
    "            while not done:\n",
    "                a = env.action_space.sample() # returns action, an integer\n",
    "                s_prime,r,done,info = env.step(a)\n",
    "                # one hot encode a\n",
    "                a_one_hot[:] = 0\n",
    "                a_one_hot[a] = 1\n",
    "                samples.append(np.concatenate((s,a_one_hot)))\n",
    "                s = s_prime\n",
    "\n",
    "        return samples\n",
    "    \n",
    "    def build_phi(self,g,num_episodes=10000,D=100):\n",
    "        # first we gather sum samples\n",
    "        samples = self.gather_samples(g,num_episodes)\n",
    "        # next we can build our RBF Sampler\n",
    "        rbf = RBFSampler(n_components = D)\n",
    "        rbf.fit(samples)\n",
    "        self.rbf = rbf\n",
    "        self.D = D\n",
    "                \n",
    "        # we can also initialise the weights here\n",
    "        # since we know now D\n",
    "        self.W = np.zeros(D)\n",
    "        \n",
    "    def epsilon_greedy(self,env,best_action,eps=0.1):\n",
    "        if np.random.random() < eps:\n",
    "            return env.action_space.sample()\n",
    "        else:\n",
    "            return best_action\n",
    "        \n",
    "    def phi(self,s):\n",
    "        if len(s.shape) == 1:\n",
    "            s = [s]\n",
    "        return self.rbf.transform(s).squeeze()\n",
    "    \n",
    "    def max_Q(self,s,get=None):\n",
    "        # we need to calculate Q(s,a) for each action a and given state s\n",
    "        # the best action is the argmax\n",
    "        action_space = env.action_space.n # number of possible acions\n",
    "        actions_one_hot = np.diag(np.ones(action_space))\n",
    "        s = np.repeat([s],action_space,axis=0)\n",
    "        s_a = np.hstack((s,actions_one_hot))\n",
    "        \n",
    "        Q = self.phi(s_a) @ self.W\n",
    "        \n",
    "        best_action = np.argmax(Q) # actions are already integers, so argmax returns action itself\n",
    "        max_Q = np.max(Q)\n",
    "        \n",
    "        if get == 'value':\n",
    "            return max_Q\n",
    "        if get == 'action':\n",
    "            return best_action\n",
    "        \n",
    "        return max_Q,best_action\n",
    "        \n",
    "                \n",
    "    def train(self,env,episodes=2000,gamma=0.9,alpha=0.1):\n",
    "        action_space = env.action_space.n\n",
    "        # lets keep track of mse\n",
    "        mse = np.zeros(episodes)\n",
    "        # lets also do the same for the rewards\n",
    "        rewards = np.zeros(episodes)\n",
    "        \n",
    "        # create array to store one hot encoded actions\n",
    "        a_one_hot = np.zeros(action_space).astype('int')\n",
    "        # we already initialised W\n",
    "        # so that if we train more we can begin from where we left off\n",
    "        done = False\n",
    "        for episode in range(episodes):\n",
    "            if (episode+1)%50 == 0:\n",
    "                print('Episode: ',episode+1,'/',episodes)\n",
    "            s = env.reset()\n",
    "            done = False\n",
    "            n_steps = 0\n",
    "            while not done:\n",
    "                a = self.epsilon_greedy(env,self.max_Q(s,get='action'))\n",
    "                s_prime,r,done,info = env.step(a)\n",
    "                rewards[episode] += r\n",
    "                \n",
    "                # one hot encode a\n",
    "                a_one_hot[:] = 0\n",
    "                a_one_hot[a] = 1\n",
    "                s_a = np.concatenate((s,a_one_hot))\n",
    "                \n",
    "                if done: # so s_prime is a terminal state\n",
    "                    y = r\n",
    "                else:\n",
    "                    y = r + gamma * self.max_Q(s_prime,get='value')\n",
    "                delta = y-self.W@self.phi(s_a)     \n",
    "                self.W = self.W + alpha*delta*self.phi(s_a) \n",
    "                s = s_prime\n",
    "                # calculate mse\n",
    "                mse[episode] += delta**2\n",
    "                n_steps += 1\n",
    "            mse[episode] /= n_steps\n",
    "\n",
    "            \n",
    "        plt.title('mse per episode')\n",
    "        plt.plot(mse)\n",
    "        plt.show()\n",
    "\n",
    "        plt.title('total rewards per episode')\n",
    "        plt.plot(rewards)\n",
    "        plt.show()\n",
    "        \n",
    "    def play_game(self,env,eps=0,episodes=1,render=True):\n",
    "        # during training we use epsilon greedy\n",
    "        # when we play the game we want to select the best action\n",
    "        # also we can use the render function to see the model playing\n",
    "        # recall we dont use this in  training since thats slow\n",
    "        # so basically this is the same code while setting epsilon to 0\n",
    "        # so lets add eps as an argument should we want to try testing using different values of epsilon\n",
    "        \n",
    "        action_space = env.action_space.n\n",
    "        # lets also do the same for the rewards\n",
    "        rewards = np.zeros(episodes)\n",
    "        # create array to store one hot encoded actions\n",
    "        a_one_hot = np.zeros(action_space).astype('int')\n",
    "        done = False\n",
    "        for episode in range(episodes):\n",
    "            s = env.reset()\n",
    "            done = False\n",
    "            while not done:\n",
    "                a = self.epsilon_greedy(env,self.max_Q(s,get='action'),eps=eps)\n",
    "                s_prime,r,done,info = env.step(a)\n",
    "                if render:\n",
    "                    env.render()\n",
    "                rewards[episode] += r\n",
    "                s = s_prime\n",
    "            print('episode: ',episode+1,' reward: ',rewards[episode])\n",
    "        env.close()\n",
    "        print('Average test reward: ',rewards.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  50 / 2000\n",
      "Episode:  100 / 2000\n",
      "Episode:  150 / 2000\n",
      "Episode:  200 / 2000\n",
      "Episode:  250 / 2000\n",
      "Episode:  300 / 2000\n",
      "Episode:  350 / 2000\n",
      "Episode:  400 / 2000\n",
      "Episode:  450 / 2000\n",
      "Episode:  500 / 2000\n",
      "Episode:  550 / 2000\n",
      "Episode:  600 / 2000\n",
      "Episode:  650 / 2000\n",
      "Episode:  700 / 2000\n",
      "Episode:  750 / 2000\n",
      "Episode:  800 / 2000\n",
      "Episode:  850 / 2000\n",
      "Episode:  900 / 2000\n",
      "Episode:  950 / 2000\n",
      "Episode:  1000 / 2000\n",
      "Episode:  1050 / 2000\n",
      "Episode:  1100 / 2000\n",
      "Episode:  1150 / 2000\n",
      "Episode:  1200 / 2000\n",
      "Episode:  1250 / 2000\n",
      "Episode:  1300 / 2000\n",
      "Episode:  1350 / 2000\n",
      "Episode:  1400 / 2000\n",
      "Episode:  1450 / 2000\n",
      "Episode:  1500 / 2000\n",
      "Episode:  1550 / 2000\n",
      "Episode:  1600 / 2000\n",
      "Episode:  1650 / 2000\n",
      "Episode:  1700 / 2000\n",
      "Episode:  1750 / 2000\n",
      "Episode:  1800 / 2000\n",
      "Episode:  1850 / 2000\n",
      "Episode:  1900 / 2000\n",
      "Episode:  1950 / 2000\n",
      "Episode:  2000 / 2000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Approx_control()\n",
    "model.build_phi(env)\n",
    "model.train(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  1  reward:  200.0\n",
      "episode:  2  reward:  200.0\n",
      "episode:  3  reward:  200.0\n",
      "episode:  4  reward:  200.0\n",
      "episode:  5  reward:  200.0\n",
      "Average test reward:  200.0\n"
     ]
    }
   ],
   "source": [
    "model.play_game(env,episodes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll be assigned some exercises to practice what we've learned in this notebook\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Excercises for Function Approximation</h3>\n",
    "\n",
    "Clearly, the concept of function approximation is very general\n",
    "\n",
    "There are tons of combinations we could have tried\n",
    "\n",
    "So in this section, we're going to enumerate some of these things and hopefully by doing these exercises, we will reinforce what we've learned in this course\n",
    "\n",
    "OK, so the first thing we can try is other feature expansions\n",
    "\n",
    "Try polynomials of different degrees, have a look at scikit-learn and see what other feature expansions are available\n",
    "\n",
    "Number two, we discussed that there are many ways to form the target value\n",
    "\n",
    "For example, Monte Carlo and SARSA \n",
    "\n",
    "Implement these :)\n",
    "\n",
    "Number three, in this course, we used to cast gradient descent, updating the weights for each separate target value\n",
    "\n",
    "But how about batch gradient descent? \n",
    "\n",
    "For example, with Monte Carlo this is natural because we effectively have all the returns at the same time after the episode is complete\n",
    "\n",
    "Number four, if we know how to implement a neural network with Tensorflow or PyTorch or Keras or any other deep learning library, try using that instead of a static feature expansion\n",
    "\n",
    "In this case, our gradient descent update looks more generic \n",
    "\n",
    "Rather than using the gradient of a linear model, which is just the input feature $x$, we have the gradient of the model output with respect to the model parameters, which differs depending on which model we chose\n",
    "\n",
    "$$\\large \\theta \\leftarrow \\theta - \\alpha \\frac{\\partial \\left(G-\\hat Q(s,a)\\right)^2}{\\partial \\theta}$$\n",
    "\n",
    "Now, of course, we don't have to worry about what form this gradient takes since modern deep learning libraries take care of that for us\n",
    "\n",
    "We also have access to other more advanced optimization techniques such as momentum, Adam and rms-prop\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Different Ways to Encode Action</h3>\n",
    "\n",
    "Number five, recall that in this notebook, we formed the feature expansion of the state action pair by one hot encoding the action and then concatenating that with the state \n",
    "\n",
    "$$\\large \\varphi(s,a) = \\text{ concat(state,one-hot encoded action)}$$\n",
    "\n",
    "In practice, we actually have several options\n",
    "\n",
    "Another option is this\n",
    "\n",
    "Suppose that we have $N$ continuous variables and $K$ possible discrete actions \n",
    "\n",
    "Then to represent our state action pair as a vector, we could create a big vector of size $N \\times K$ (thats a long vector not a matrix)\n",
    "\n",
    "If action one is chosen, then the first and elements would hold the state measurements and the rest would be zero\n",
    "\n",
    "If action number two is chosen, then the next $N$ elements would hold the state measurements and the rest would be zero\n",
    "\n",
    "$$\\large{x = f(s) \\in \\Large{\\mathfrak{R}}^N} \\text{(some feature expansion of s)} \\\\ \\large \\varphi(s,a_1) = (x_1,\\ldots,x_N,0,0,\\ldots \\ldots \\ldots \\ldots,0) \\\\ \\large \\varphi(s,a_2) = (0,\\ldots,0,x_1,\\ldots,x_N,0,0,\\ldots,0) \\\\ \\large{...} \\\\ \\large{\\varphi(s,a_K) = (0,0,\\ldots \\ldots \\ldots \\ldots,0,x_1,\\ldots,x_N)}$$\n",
    "\n",
    "OK, so hopefully we get the idea the state gets put into different positions based on which action was chosen\n",
    "\n",
    "So that's how we're able to differentiate between different actions\n",
    "\n",
    "---\n",
    "\n",
    "Yet another option is this, instead of trying to combine the state inaction action into a single vector, just transform the state by itself, as we did for prediction \n",
    "\n",
    "For the actions, simply create multiple outputs\n",
    "\n",
    "For example, if we have $K$ actions, then our model becomes \n",
    "\n",
    "$$\\large \\hat y = W^T \\varphi(s), \\text{where } \\hat y \\in \\Large{\\mathfrak{R}}^K, W \\in \\Large{\\mathfrak{R}}^{N \\times K}, \\varphi(s) \\in \\mathfrak{R}^N$$\n",
    "\n",
    "In this case, $\\hat y$ is no longer a scalar, but rather a vector of size $K$\n",
    "\n",
    "<img src='extras/58.17.PNG' width='500'>\n",
    "\n",
    "The wait is now a matrix instead of just a vector of size and by K\n",
    "\n",
    "So in this case each output prediction $\\hat y$ represents $Q(s,a)$ for each possible action $a$\n",
    "\n",
    "---\n",
    "\n",
    "As part of this exercise, consider the pros and cons of each approach, which ones have more parameters and which ones have less, and if we're familiar with neural networks, consider this question both for linear models and neural networks\n",
    "\n",
    "Which ones require more computation?\n",
    "\n",
    "Which ones can handle continuous actions?\n",
    "\n",
    "And if we do have continuous actions, what challenges would do we have to overcome?\n",
    "\n",
    "note : all seem pretty basic, so we are skipping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will summarize everything we learned in this notebook\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Function Approximation notebook Summary</h3>\n",
    "\n",
    "This notebook was all about function approximation for reinforcement learning\n",
    "\n",
    "The motivation behind the notebook is clear \n",
    "\n",
    "For modern problems like playing chess, go, video games and autonomous vehicles, the state spaces are too large or infinite in size\n",
    "\n",
    "In these cases, tabular methods are limited\n",
    "\n",
    "Now it's possible to take a continuous or infinite state space and simply discretise it into buckets\n",
    "\n",
    "But even that will fail at some point\n",
    "\n",
    "In practice, function approximation offers a reliable solution\n",
    "\n",
    "It essentially allows us to compress the value function parameter space \n",
    "\n",
    "Instead of having to enumerate all possible states, we only need to find a small number of parameters\n",
    "\n",
    "This can help us predict the value even for states we have never seen before, as long as they are sufficiently similar to states that we have seen before\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, we first reviewed linear models and how they learn via stochastic gradient descent\n",
    "\n",
    "We then learn that linear models are actually not limited to modeling linear functions since we can\n",
    "use feature engineering\n",
    "\n",
    "We considered polynomial feature expansions in the RBF Kernel\n",
    "\n",
    "Next, we returned to reinforcement learning and applied function approximation to prediction\n",
    "\n",
    "This allowed us to find the value function of a given policy using a linear model\n",
    "\n",
    "Next, we turned our attention to control and looked at Q-learning with function approximation\n",
    "\n",
    "Finally, we looked at a new environment called CartPole\n",
    "\n",
    "Since this environment has a continuous state space, it allowed us to see the real power of approximation methods \n",
    "\n",
    "Gridworld is still a critical part of this series, because it allows us to compare and contrast each method we learned while keeping the\n",
    "environment constant\n",
    "\n",
    "---\n",
    "\n",
    "<h3>\"All data is the same\"</h3>\n",
    "\n",
    "But CartPole allowed us to extend what we've learned with essentially zero effort\n",
    "\n",
    "It lets us see what we're really capable of, despite the fact that GridWorld might seem overly simplistic\n",
    "\n",
    "This is encapsulated in the rule, $\\text{All data is the same}$\n",
    "\n",
    "Using the exact same code, we were able to solve a much more complex environment with essentially zero effort\n",
    "\n",
    "This is because, like all other machine learning algorithms, the same code works no matter the data\n",
    "\n",
    "When we consider things from the perspective of the computer, we know that the computer doesn't know anything about CartPole or Newtonian physics or video games\n",
    "\n",
    "All the computer can see is numbers\n",
    "\n",
    "So for us, while it may seem like there's a big difference between dataset one and dataset two or environment one and environment two, the computer says, well, to me it all just looks like numbers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
