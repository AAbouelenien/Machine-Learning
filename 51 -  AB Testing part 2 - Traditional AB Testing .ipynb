{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we are going to start talking about confidence intervals\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Confidence Intervals</h3>\n",
    "\n",
    "\n",
    "<img src='extras/51.1.PNG' width='300'></img>\n",
    "\n",
    "Now, we may have probably heard about confidence intervals before, but even if we have, we are still going to start from scratch\n",
    "\n",
    "\n",
    "We're going to build everything up from a very intuitive place, which follows from the review notebook (50) that we just completed\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Maximum Likelihood Estimation</h3>\n",
    "\n",
    "OK, so as we recall, we previously learned how to do maximum likelihood estimation\n",
    "\n",
    "One of the parameters we learned how to calculate was the maximum likelihood estimate of the mean\n",
    "\n",
    "Recall that in both the Bernoulli and the Gaussian case, this reduced to the sample mean\n",
    "\n",
    "$$\\large \\hat \\mu = \\bar x = \\frac{1}{N} \\sum^N_{i=1}x_i$$\n",
    "\n",
    "OK, so let's suppose we've collected a small data set containing the numbers $1$, $3$ and $5$\n",
    "\n",
    "$$X = (1,3,5)$$\n",
    "\n",
    "Now, let's suppose we want the sample mean of this data set\n",
    "\n",
    "Pretty clearly the answer is $3$\n",
    "\n",
    "This makes sense because three is in the middle.\n",
    "\n",
    "---\n",
    "\n",
    "OK, but now let's consider a different data set, let's say this time our data set contains the numbers $2.9$,$3.0$,$3.1$\n",
    "\n",
    "$$X = (2.9,3.0,3.1)$$\n",
    "\n",
    "In this case, when we calculate the mean again, we still get $3$\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Which estimate are we more confident about?</h4>\n",
    "\n",
    "So now let's consider the question, which answer are we more confident about?\n",
    "\n",
    "Are we more confident that the true mean is $3$ in\n",
    "\n",
    "$$\\text{Dataset 1}: X=(1,3,5) \\\\ \\text{ or } \\\\ \\text{Dataset 2}: X=(2.9,3.0,3.1)$$\n",
    "\n",
    "---\n",
    "\n",
    "OK, so we probably agree that we are more confident in the $X=(2.9,3.0,3.1)$ case\n",
    "\n",
    "In the $X=(1,3,5)$, it is plausible that the true mean might be something like,say, $3.5$ or even $4$\n",
    "\n",
    "But in the $X=(2.9,3.0,3.1)$ case, it's pretty clear that the true mean is probably not $4$\n",
    "\n",
    "Now, just intuitively think about why this is true\n",
    "\n",
    "Why are we more confident when the numbers are closer together?\n",
    "\n",
    "As an extreme example of this, consider if our samples are just $0$ and $10 \\text{ million}$\n",
    "\n",
    "Sure, the mean is $5 \\text{ million}$, but we're probably not very confident in that estimate compared to the mean being $3$ when our samples are just $2.9,3.0,3.1$\n",
    "\n",
    "In this case, the mean might be five million and one or five million and two, we don't think we have enough evidence to say one or the other (in other words, being $1$ or $2$ off is plausible when the range is large, but not when its small)\n",
    "\n",
    "But for the $2.9,3.0,3.1$ case, we're pretty sure the is not $4$ or $5$\n",
    "\n",
    "---\n",
    "\n",
    "<h3>A new scenario</h3>\n",
    "\n",
    "Now, let's consider another scenario\n",
    "\n",
    "Suppose we've collected two data sets\n",
    "\n",
    "Suppose it's a coin toss, so the result is the probability of heads when we calculate the mean \n",
    "\n",
    "In our first data set, we have 10 samples\n",
    "\n",
    "That means we flipped the coin 10 times\n",
    "\n",
    "We calculate the mean and the mean is $0.6$\n",
    "\n",
    "In our second data set, we have 1000 samples\n",
    "\n",
    "Again, we calculate the mean and the mean is also $0.6$\n",
    "\n",
    "$$\\text{Dataset 1: 10 flips }\\rightarrow \\text{ mean = 0.6}$$\n",
    "\n",
    "$$\\text{Dataset 2: 1000 flips }\\rightarrow \\text{ mean = 0.6}$$\n",
    "\n",
    "So again, we want  to answer the question, which of these estimates are we more confident about?\n",
    "\n",
    "Are we more confident when we've collected only $10$ samples, or are you more confident when we've collected $1000$ samples?\n",
    "\n",
    "---\n",
    "\n",
    "OK, so hopefully we all came to the same answer, which is that we are more confident when we've collected more samples \n",
    "\n",
    "Intuitively we know this is true, when we do a medical experiment, for example, to test the drug, we need to have a certain threshold of participants before we can be sure that it works\n",
    "\n",
    "We can't just test our weight loss drug on one person and say, aha, this person lost weight, therefore out drug works well\n",
    "\n",
    "Maybe that person just didn't eat that much since they were busy with work and they lost weight due to eating less\n",
    "\n",
    "It may be that the drug is actually useless\n",
    "\n",
    "Of course, we hope that these random effects will average out when we test the drug on more people\n",
    "\n",
    "So that's why we have to collect more samples\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Summary</h3>\n",
    "\n",
    "OK, so let's summarize what we've come up with so far, we know that there are two things which affect our confidence in an estimate\n",
    "\n",
    "<ul>\n",
    "    <li>How spread out the samples are seems to matter</li>\n",
    "    <ul>\n",
    "        <li>If they are more spread out, we are less confident \n",
    "</li>\n",
    "    </ul>\n",
    "    <li>How many samples we've collected also seems to matter</li>\n",
    "    <ul>\n",
    "        <li>When we collect more samples, we become more confident</li>\n",
    "    </ul>\n",
    "</ul>\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture, we are going to continue our discussion of confidence intervals\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Confidence Intervals: The \"API Approach\"</h3>\n",
    "\n",
    "<img src='extras/51.2.PNG' width='350'></img>\n",
    "\n",
    "This section will be a beginner summary, that is to say, this section won't discuss the detailed derivation or the whys and hows\n",
    "\n",
    "Instead, this section will focus on a more API like approach\n",
    "\n",
    "In other words, if someone asks us to calculate the confidence interval for some estimate, we will be able to do so using the formulas we will see in this section\n",
    "\n",
    "So this is like a plug and chug kind of section where we are going to see how to compute some quantity\n",
    "\n",
    "In the following sections will step back and see where this formula actually comes from, so we can get a deeper understanding\n",
    "\n",
    "---\n",
    "\n",
    "<h3>z-Confidence Interval</h3>\n",
    "\n",
    "OK, so in this lecture, we are going to learn about the  z-confidence interval pecifically \n",
    "\n",
    "The formula is this \n",
    "\n",
    "Suppose that we've collected some samples of a quantity we're interested in\n",
    "\n",
    "Let's call that $X$, so we have $x_1$ all the way up to $x_N$\n",
    "\n",
    "$$\\large \\text{Data : } \\{x_1.\\ldots,x_N\\}$$\n",
    "\n",
    "This means we have $N$ samples\n",
    "\n",
    "Let's call the average of those $\\bar x$\n",
    "\n",
    "Sometimes we'll refer to this as $\\hat \\mu$, other times we might refer to this as $\\bar x$\n",
    "\n",
    "Either way they mean the same thing\n",
    "\n",
    "\n",
    "$$\\large \\text{Sample Mean : }\\hat \\mu = \\bar x = \\frac{1}{N} \\sum^N_{i=1} x_i$$\n",
    "\n",
    "Now suppose we calculate the sample variance of the $x$s\n",
    "\n",
    "Let's call that $\\hat \\sigma^2$\n",
    "\n",
    "$$\\large \\text{Sample Variance : } \\hat \\sigma^2 = \\frac{1}{N-1} \\sum^N_{i=1} (x_i - \\bar x)^2$$\n",
    "\n",
    "Then, the sample standard deviation is just the square root of that which we'll call $\\hat \\sigma$\n",
    "\n",
    "---\n",
    "\n",
    "Finally, the confidence interval can be defined like this \n",
    "\n",
    "Specifically, this will be for the $95 \\%$  confidence interval \n",
    "\n",
    "Since it's an interval, it has a lower end point and an upper end point \n",
    "\n",
    "The lower end point is equal to $\\hat \\mu - 1.96 \\frac{\\hat \\sigma}{\\sqrt{N}}$ \n",
    "\n",
    "The upper end point is equal to  $\\hat \\mu + 1.96 \\frac{\\hat \\sigma}{\\sqrt{N}}$\n",
    "\n",
    "OK, so you can think of this like the master formula for the $95 \\%$ confidence interval\n",
    "\n",
    "$$\\large 95 \\% \\text{ Confidence Interval } = \\left[ \\hat \\mu - 1.96 \\frac{\\hat \\sigma}{\\sqrt{N}},\\hat \\mu + 1.96 \\frac{\\hat \\sigma}{\\sqrt{N}}\\right]$$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<h3>$\\gamma$ Confidence Interval</h3>\n",
    "\n",
    "Note that we can calculate confidence intervals for percentages other than $95 \\%$ \n",
    "\n",
    "In general, we will say that the $\\gamma$ confidence interval is the confidence interval with the portion $\\gamma$ confidence\n",
    "\n",
    "This means that the portion $\\gamma$ of all confidence intervals will contain the true parameter we are trying to estimate \n",
    "\n",
    "For example, $95 \\%$ of the time, the $95 \\%$ confidence interval will contain the true parameter $\\mu$\n",
    "\n",
    "So generally we say, $\\gamma$ fo the time, the $\\gamma$ confidence interval withh contain the true parameter $\\mu$\n",
    "\n",
    "In later sections we'll learn how to calculate confidence intervals for any value of $\\gamma$\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Why does it make sense?</h3>\n",
    "\n",
    "The last thing we want to do in this section is to talk about why this even makes sense\n",
    "\n",
    "Recall that from our first section on confidence intervals, we learn that intuitively there were two things that seemed to affect our confidence in an estimate\n",
    "\n",
    "Let's recall what those two things are\n",
    "\n",
    "First, we have the variance in the data\n",
    "\n",
    "If the data is more spread out or in other words, has higher variance, then our confidence is less\n",
    "\n",
    "Second, we have the number of samples we've collected, when we collect more samples than our confidence is greater\n",
    "\n",
    "We can see that both of these intuitions are reflected in the confidence interval\n",
    "\n",
    "We can see that the width of the interval is proportional to $\\sigma$\n",
    "\n",
    "$$95 \\% \\text{ Confidence Interval } = \\left[ \\hat \\mu - 1.96 \\frac{\\boxed{\\hat \\sigma}}{\\sqrt{N}},\\hat \\mu + 1.96 \\frac{\\boxed{\\hat \\sigma}}{\\sqrt{N}}\\right]$$\n",
    "\n",
    "That is when the variance increases, so does the width of the confidence interval \n",
    "\n",
    "Because the interval is wider, we are actually less confident about our estimate\n",
    "\n",
    "Secondly, we can see that the width of the interval is inversely proportional to the square root of the number of samples $N$ \n",
    "\n",
    "$$95 \\% \\text{ Confidence Interval } = \\left[ \\hat \\mu - 1.96 \\frac{\\hat \\sigma}{\\boxed{\\sqrt{N}}},\\hat \\mu + 1.96 \\frac{\\hat \\sigma}{\\boxed{\\sqrt{N}}}\\right]$$\n",
    "\n",
    "\n",
    "That is, when the number of samples increases, the width of the confidence interval becomes smaller\n",
    "\n",
    "Because the width of the interval becomes  smaller, we become more confident in our estimate\n",
    "\n",
    "Sohopefully is clear how this simple formula encapsulates the intuitions we learned about earlier\n",
    "\n",
    "Higher variance leads to less confidence, while more samples leads to more confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so now we're going to switch to a more mathematical perspective on this topic\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Sum of Normals</h3>\n",
    "\n",
    "Let's pretend that we know our data comes from a normal distribution\n",
    "\n",
    "Let's say that each data point we've collected is IID, that means independent and identically distributed\n",
    "\n",
    "OK, so each sample we've collected comes from the same distribution and they are independent from one another\n",
    "\n",
    "For example, if we're measuring heights, we know that John's Height is independent of Mary's height\n",
    "\n",
    "Well, this may not be the case if they have the same parents, but let's assume that this is not the case\n",
    "\n",
    "---\n",
    "\n",
    "We know that the sample mean is the sum of all our samples divided by N and is just a number, it's not random\n",
    "\n",
    "$$\\large \\hat \\mu = \\bar x = \\frac{1}{N} \\sum^N_{i=1} x_i$$\n",
    "\n",
    "But the $x_i$s are random\n",
    "\n",
    "As we recall, functions of random variables are also random variables\n",
    "\n",
    "In this case, the sum of random variables is also a random variable \n",
    "\n",
    "Intuitively, this should make sense\n",
    "\n",
    "For example, consider $X_1$ and $X_2$, which are the result of two coin tosses\n",
    "\n",
    "Now let $Y = X_1 + X_2$ \n",
    "\n",
    "Since  $X_1$ can be $0$ or $1$ and $X_2$ can be $0$ or $1$, then $Y$ can be either $\\{0,1,2\\}$\n",
    "\n",
    "And of course because $X_1$ and $X_2$ are both random, so is $Y$\n",
    "\n",
    "That means we can calculate the $p(Y=0),p(Y=1),p(Y=2)$\n",
    "\n",
    "That is to say $Y$ has a distribution\n",
    "\n",
    "Saying it has a distribution is the same thing as saying it's random\n",
    "\n",
    "OK, so hopefully we are convinced that sums of random variables are random and in general functions of random variables are random\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Sums of Normals</h3>\n",
    "\n",
    "Now, what do we know about sums of normally distributed random variables?\n",
    "\n",
    "Well, it turns out that they are also normally distributed\n",
    "\n",
    "If we have two normally distributed at random variables, \n",
    "\n",
    "$$\\large X_1 \\sim N(\\mu_1,\\sigma_1^2)$$\n",
    "\n",
    "$$\\large X_2 \\sim N(\\mu_2,\\sigma_2^2)$$\n",
    "\n",
    "\n",
    "Then what is the distribution of their sum?\n",
    "\n",
    "For the purpose of this section, let's say that $X_1$ and $X_2$ are independent, then the answer is that $Y$, which is $X_1 + X_2$ is also normal\n",
    "\n",
    "$$\\large Y = X_1 + X_2 \\sim N(\\mu_1+\\mu_2,\\sigma_1^2+\\sigma_2^2)$$\n",
    "\n",
    "Now if we want to prove this, we can use a technique called characteristic functions which we would have encountered in our undergraduate probability course (never heard about it tho :) )\n",
    "\n",
    "These will be outside the scope of these notebooks for the time being\n",
    "\n",
    "So its left for us to look it up if we are intrested\n",
    "\n",
    "---\n",
    "\n",
    "The next thing we can do is extend this idea to the sum of $N$ IID normal random variables \n",
    "\n",
    "Since they are IID, the mean of each sample is $\\mu$ and the mean of their sum is $N \\times \\mu$\n",
    "\n",
    "In addition, the variance of each sample is $\\sigma^2$ and the variance of their sum is $N \\times \\sigma^2$\n",
    "\n",
    "$$\\large X \\sim N(\\mu,\\sigma^2)$$\n",
    "\n",
    "$$\\large X_1 + \\ldots + X_N \\sim N(N\\mu,N\\sigma^2)$$\n",
    "\n",
    "Again, we should be able to verify this using what we just learned, or we can try to prove it oursleves using characteristic functions :(\n",
    "\n",
    "---\n",
    "\n",
    "<h3>What are we trying to find?</h3>\n",
    "\n",
    "So let's remember what we are trying to find\n",
    "\n",
    "We know that $\\hat \\mu$, the sample mean of our data, is a function of random variables\n",
    "\n",
    "$$\\large \\hat \\mu = \\frac{x_1+x_2+\\ldots+x_N}{N}$$\n",
    "\n",
    "Right now we are currently asking what is the distribution of $\\hat \\mu$?\n",
    "\n",
    "Well, since $\\hat \\mu$ is just the sum of $N$ normals divided by $N$, we just have to divide what we found previously by $N$\n",
    "\n",
    "\n",
    "That is $\\hat \\mu$ is also a normal random variable\n",
    "\n",
    "The mean of $\\hat \\mu$ is $\\mu$, and the variance of $\\hat \\mu$ is $\\frac{\\sigma^2}{N}$\n",
    "\n",
    "$$\\large \\hat \\mu \\sim N\\left(\\mu,\\frac{\\sigma^2}{N}\\right)$$\n",
    "\n",
    "Now you might wonder\n",
    "\n",
    "Previously, we $N \\sigma^2$, why are we dividing by $N$ twice to get $\\frac{\\sigma}{N}$\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Mean of Estimate</h3>\n",
    "\n",
    "Again, we have to use our probability skills\n",
    "\n",
    "First, let's double check that the mean of $\\hat \\mu$ is actually $\\mu$\n",
    "\n",
    "We can start by the definition of the mean, which is the expected value $E(\\hat \\mu)$\n",
    "\n",
    "The next step is to replace $\\hat \\mu$  with its expression in terms of the samples $X_1$ up to $X_N$, $\\frac{1}{N} \\sum\\limits^N_{i=1} X_i $\n",
    "\n",
    "$$\\large E(\\hat \\mu) = E \\left(\\frac{1}{N} \\sum^N_{i=1} X_i \\right)$$\n",
    "\n",
    "Next, we can split up the summation to write $X_1$ up to $X_N$ explicitly\n",
    "\n",
    "$$\\large E(\\hat \\mu) = E \\left(\\frac{1}{N} \\left( X_1 + X_2 + \\ldots + X_N \\right)\\right)$$\n",
    "\n",
    "Next, since we know that the expected value is a linear operator, we can split the expected value over the sum and we can factor out the $\\frac{1}{N}$\n",
    "\n",
    "$$\\large E(\\hat \\mu) = \\frac{1}{N}E(X_1) + \\frac{1}{N}E(X_2) + \\ldots + \\frac{1}{N}E(X_N)$$\n",
    "\n",
    "\n",
    "Next, we can see that all we have left are just the expected values of each of the $X$s\n",
    "\n",
    "We know that these are $\\mu$, so we can write \n",
    "\n",
    "$$\\large E(\\hat \\mu) =  \\large \\frac{1}{N}\\mu + \\frac{1}{N}\\mu + \\ldots + \\frac{1}{N}\\mu, \\text{ N times}$$\n",
    "\n",
    "$$\\large E(\\hat \\mu) = \\mu$$\n",
    "\n",
    "Now, lets think about why this makes sense\n",
    "\n",
    "The expected value of $\\hat \\mu$ is $\\mu$ itself\n",
    "\n",
    "That's a good thing because $\\hat \\mu$ is supposed to estimate $\\mu$\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Variance of the Estimate</h3>\n",
    "\n",
    "Next, let's look at the variance, which is a little more tricky\n",
    "\n",
    "\n",
    "Again, we can start by using the definition of variance\n",
    "\n",
    "It's the expected value of a random variable minus its mean all squared\n",
    "\n",
    "We can replace $\\hat \\mu$  with the $\\frac{1}{N} \\sum^N_{i=1} X_i$\n",
    "\n",
    "$$\\large var(\\boxed{\\hat \\mu}) = var \\left(\\boxed{\\frac{1}{N} \\sum^N_{i=1} X_i} \\right)$$\n",
    "\n",
    "We  can also replace the mean with $\\mu$ because we know that the mean of $\\hat \\mu$ hat is $\\mu$\n",
    "\n",
    "$$\\large var(\\hat \\mu) = E \\left[ {\\left(\\frac{1}{N} \\sum^N_{i=1} X_i -\\boxed{\\mu}\\right)}^2\\right]$$\n",
    "\n",
    "That's what we found in the previous subsection\n",
    "\n",
    "Next we can factor out the $\\frac{1}{N}$ \n",
    "\n",
    "Now we have to do this carefully because of the square\n",
    "\n",
    "When we factor something out from a square we have to square it\n",
    "\n",
    "Therefore we have $\\frac{1}{N^2}$\n",
    "\n",
    "Furthermore, we can bring this outside the expected value because it's constant\n",
    "\n",
    "$$\\large var(\\hat \\mu) = \\frac{1}{N^2} E \\left[ {\\left(\\sum^N_{i=1} X_i - N\\mu\\right)}^2\\right]$$\n",
    "\n",
    "Note also that the mean has become and $N \\mu$ \n",
    "\n",
    "When we factor out $\\frac{1}{N}$, we have to factor it out of both terms\n",
    "\n",
    "Of course this makes sense\n",
    "\n",
    "Our random variable is now the sum over all the $X$s  $\\sum\\limits^N_{i=1} X_i$ and as we established previously, the mean of that sum is $N \\mu$ ( so it follows the definition of the variance : the expected value of a random variable minus its mean all squared)\n",
    "\n",
    "So we are now taking the variance of the sum of the $X$s rather than the sample mean of the $X$s\n",
    "\n",
    "$$\\large var(\\hat \\mu) = \\frac{1}{N^2} var \\left(\\sum^N_{i=1} X_i\\right)$$\n",
    "\n",
    "Now, of course, we already know what the variance of the sum is, because we talked about that earlier\n",
    "\n",
    "As we recall, if the variance of each $X$ is $\\sigma^2$, then the variance of the sum is $N \\times \\sigma^2$\n",
    "\n",
    "$$\\large var(\\hat \\mu) = \\frac{1}{N^2} N \\sigma^2$$\n",
    "\n",
    "$$\\large var(\\hat \\mu) = \\frac{\\sigma^2}{N}$$\n",
    "\n",
    "So the reason why we divide by $N$ twice, as we saw earlier, is because the $\\frac{1}{N}$ over is being factored out of a square\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Putting it all together</h3>\n",
    "\n",
    "OK, so let's put this all together\n",
    "\n",
    "We've just found the distribution of $\\hat \\mu$, our estimate of the mean of $X$\n",
    "\n",
    "We found that it is a normal distribution with mean $\\mu$ and variance $\\frac{\\sigma^2}{N}$\n",
    "\n",
    "$$\\large \\hat \\mu \\sim N \\left(\\mu,\\frac{\\sigma^2}{N}\\right)$$\n",
    "\n",
    "Let's now consider why this makes sense\n",
    "\n",
    "We've already looked at the mean, which should be pretty intuitive\n",
    "\n",
    "The mean of $\\hat \\mu$ is the mean of $X$\n",
    "\n",
    "This makes sense because that's the thing we're trying to estimate\n",
    "\n",
    "Its expected value should be $\\mu$\n",
    "\n",
    "But what about the variance\n",
    "\n",
    "As we can see, it depends on two things\n",
    "\n",
    "First, it depends on $\\sigma$, which is the variance of $X$, which is the variance of our original data\n",
    "\n",
    "Second, it depends on $N$, the number of samples we've collected\n",
    "\n",
    "So why does that make sense?\n",
    "\n",
    "Well, as we can see, one of these things makes the ratio larger while the other makes it smaller\n",
    "\n",
    "When $\\sigma^2$ is larger, the variance of $\\hat \\mu$ becomes larger\n",
    "\n",
    "That makes sense\n",
    "\n",
    "If $X$ is more spread out then the variance of $\\hat \\mu$ is also more spread out\n",
    "\n",
    "That is to say, $\\mu$ is harder to estimate if the samples of $X$ vary by a lot\n",
    "\n",
    "We can also see that as we collect more and more samples, that is as $N$ gets larger and larger, the variance of $\\hat \\mu$ gets smaller\n",
    "\n",
    "That also makes sense, as we collect more and more data, the variance of our estimate decreases\n",
    "\n",
    "Now, surely we've all seen this effect for ourselves\n",
    "\n",
    "For example, suppose we're flipping a coin to try and measure the probability of heads \n",
    "\n",
    "In the early stages of our experiment, our estimate might vary by a lot because we don't have that many samples\n",
    "\n",
    "But once we've collected one hundred or one thousand samples, our estimate is going to be very close to zero point five, and the new coin flips will not affect our estimate that much.\n",
    "\n",
    "OK, so more samples means the variance of our estimate decreases\n",
    "\n",
    "---\n",
    "\n",
    "<h3>More Intuition</h3>\n",
    "\n",
    "OK, so this is a very intuitive idea behind the confidence interval\n",
    "\n",
    "<img src='extras/51.3.PNG' width='350'></img>\n",
    "\n",
    "What  we're trying to do is we're trying to create a distribution of the sample mean or any other quantity we are trying to estimate\n",
    "\n",
    "The confidence interval is just an interval over this distribution.\n",
    "\n",
    "For example, we can choose the middle $95 \\%$\n",
    "\n",
    "This is called the $95 \\%$ confidence interval\n",
    "\n",
    "And from this intuitive example, we see that when the variance of our original data is larger, this makes our confidence interval larger\n",
    "\n",
    "However, we can shrink our confidence interval by collecting more data\n",
    "\n",
    "That is, we can become more confident in our estimate by collecting more samples\n",
    "\n",
    "OK, so more variance means larger and more samples mean smaller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we are going to continue our discussion of confidence intervals\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Confidence Intervals Continued</h3>\n",
    "\n",
    "Previously, we learned when our mean estimate $\\hat \\mu$ is modeled as a distribution, which is a normal with mean $\\mu$ and variance $\\frac{\\sigma^2}{N}$, then the confidence interval can be defined as follows\n",
    "\n",
    "For the $95 \\%$ confidence interval, it is simply the interval which covers the middle $95 \\%$  of the area of this distribution\n",
    "\n",
    "<img src='extras/51.3.PNG' width='300'></img>\n",
    "\n",
    "In this section, we'll do some more work in order to figure out how we can determine the actual numerical values for this interval\n",
    "\n",
    "That is to say, what calculations do we have to do in order to figure out the lower end point and the upper end point of this interval?\n",
    "\n",
    "In general, it's not required to use $95 \\%$\n",
    "\n",
    "Sometimes we might see people use the $90 \\%$ interval or the $99 \\%$ percent interval\n",
    "\n",
    "In general, the $\\gamma$ confidence interval is the interval that covers the portion $\\gamma$ of the area under the PDF\n",
    "\n",
    "---\n",
    "\n",
    "<h3>We've Reduced the Problem to Math</h3>\n",
    "\n",
    "So the question we have to answer now is purely mathematical\n",
    "\n",
    "We have some distribution which is normal, and we want to find the lower end point and the upper end point so that the area in the middle is $95 \\%$\n",
    "\n",
    "In fact, we may recall that this can be done using the CDF, the cumulative distribution function\n",
    "\n",
    "Suppose that we have some random variable which has a standard normal distribution that is to say mean zero and variance one, $z \\sim N(0,1)$\n",
    " \n",
    "Then because this distribution is symmetric, if we want to cover $95 \\%$ in the middle, we'll have $2.5 \\%$ left on the right side and $2.5 \\%$ percent left on the left side\n",
    "\n",
    "<img src='extras/51.4.PNG' width='400'></img>\n",
    "\n",
    "Let's consider the left side\n",
    "\n",
    "What value of $Z$ do we need so that the area to the left of $Z$ is $2.5 \\%$\n",
    "\n",
    "We'll call this Value $Z_{\\text{left}}$\n",
    "\n",
    "<img src='extras/51.5.PNG' width='400'></img>\n",
    "\n",
    "\n",
    "This is just the inverse CDF of $Z_{\\text{left}}$ \n",
    "\n",
    "To see why, recall that the CDF of the $Z_{\\text{left}}$ is the area from $-\\infty$ up to $Z_{\\text{left}}$\n",
    "\n",
    "We want this to be $0.025$\n",
    "\n",
    "$$\\large 0.025 = \\int^{Z_{left}}_{-\\infty} \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{1}{2}z^2}dz = \\Phi(Z_{\\text{left}})$$\n",
    "\n",
    "Therefore we can take the inverse of the $\\Phi$ to solve for $Z_{left}$\n",
    "\n",
    "$$\\large Z_{\\text{left}} = \\Phi^{-1}(0.025) = -1.96$$\n",
    "\n",
    "Remember that there is no equation for this function, but we can calculate the values either using a table or with software library such as ```scipy```\n",
    "\n",
    "After doing so, we should obtain the answer $-1.96$\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Right Side</h3>\n",
    "\n",
    "Now, due to symmetry, we can conclude that the answer for $Z_{\\text{right}}$ is $+1.96$\n",
    "\n",
    "<img src='extras/51.6.PNG' width='400'></img>\n",
    "\n",
    "Alternatively, we could also calculate this area directly\n",
    "\n",
    "We know that $Z_{\\text{right}}$ is the point at which $97.5 \\%$ of the area under the PDF should be to the left\n",
    "\n",
    "That's because $2.5 \\%$ is on the right\n",
    "\n",
    "Therefore, the CDF of  $Z_{\\text{right}}$ should be equal to $0.975$\n",
    "\n",
    "$$\\large 0.975 = \\int^{Z_{\\text{right}}}_{\\infty} \\frac{1}{2 \\pi} e^{-\\frac{1}{2}z^2} dz = \\Phi(z_\\text{right})$$\n",
    "\n",
    "Again, taking the inverse of the CDF, we should arrive at $+1.96$\n",
    "\n",
    "---\n",
    "\n",
    "<h3>General Calculation</h3>\n",
    "\n",
    "OK, so what should we do when our data is not from the standard normal? \n",
    "\n",
    "Recall that if we have a random variable and we subtract its mean and divide by its standard deviation, this is called standardisation\n",
    "\n",
    "That is to say, if we have some normal random variable with mean $\\mu$ and variance $\\sigma_0^2$, we can transform it into a standardised random variable by subtracting $\\mu$ and dividing by $\\sigma_0$\n",
    "\n",
    "$$\\large x \\sim N(\\mu,\\sigma_0^2) \\rightarrow z = \\frac{x - \\mu}{\\sigma_0} \\sim N(0,1)$$\n",
    "\n",
    "We often use the letter $z$ to denote this standardized random variable\n",
    "\n",
    "OK, and so what do we know about $z$?\n",
    "\n",
    "Well, we know that if we want the lower and upper end points of the $95 \\%$ confidence interval, these are what we just calculated, $(-1.96,+1.96)$\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Reversing the Transformation</h3>\n",
    "\n",
    "So now we have our confidence interval for $z$\n",
    "\n",
    "We can express it as follows where we say that \n",
    "\n",
    "$$\\large -1.96 \\le z \\le 1.96$$\n",
    "\n",
    "Of course, we don't want to know about $z$, we want to know about our original parameter $\\mu$\n",
    "\n",
    "We know that \n",
    "\n",
    "$$\\large z = \\frac{\\hat \\mu - \\mu}{\\sigma_0}$$\n",
    "\n",
    "So we can simply plug that back in\n",
    "\n",
    "$$\\large -1.96 \\le \\frac{\\hat \\mu - \\mu}{\\sigma_0} \\le 1.96$$\n",
    "\n",
    "\n",
    "Our goal now is to isolate the parameter of interest $\\mu$\n",
    "\n",
    "We can start by first multiplying everything $\\sigma_0$ \n",
    "\n",
    "$$\\large -1.96 \\sigma_0 \\le \\hat \\mu - \\mu \\le 1.96 \\sigma_0$$\n",
    "\n",
    "The next step is to subtract $\\hat \\mu$ from each term\n",
    "\n",
    "$$\\large -1.96 \\sigma_0 - \\hat \\mu \\le - \\mu \\le 1.96 \\sigma_0 - \\hat \\mu$$\n",
    "\n",
    "and then negate each of the terms, which also reverses the direction of the inequalities\n",
    "\n",
    "$$\\large \\hat \\mu - 1.96 \\sigma_0  \\le \\mu \\le \\hat \\mu + 1.96 \\sigma_0 $$\n",
    "\n",
    "\n",
    "At this point, we have what we want\n",
    "\n",
    "We have $\\mu$ the parameter of interest in the middle and we have the lower end point and the upper end point of the confidence interval\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Lets return to the sample mean</h3>\n",
    "\n",
    "So how does this look for the situation where our data is normally distributed in general?\n",
    "\n",
    "Recall that in this case, if $X$ is normally distributed with mean $\\mu$ and variance $\\sigma^2$, then $\\hat \\mu$ is also normally distributed with mean $\\mu$ and variance $\\frac{\\sigma^2}{N}$\n",
    "\n",
    "$$\\large \\text{If } X \\sim N(\\mu,\\sigma^2), \\text{ then } \\hat \\mu \\sim N\\left(\\mu,\\frac{\\sigma^2}{N}\\right)$$\n",
    "\n",
    "Therefore, the $95 \\%$ confidence interval for $\\mu$ is \n",
    "\n",
    "$$\\large 95\\% - \\text{CI} = \\left[ \\hat \\mu - 1.96 \\frac{\\sigma}{\\sqrt{N}}, \\hat \\mu + 1.96 \\frac{\\sigma}{\\sqrt{N}}\\right]$$\n",
    "\n",
    "More generally, if we wanted the $\\gamma$ confidence interval it would be the formula that we see here :)\n",
    "\n",
    "$$\\large \\gamma - \\text{CI} = \\left[ \\hat \\mu + \\Phi^{-1} \\left(\\frac{1-\\gamma}{2}\\right) \\frac{\\sigma}{\\sqrt{N}}, \\hat \\mu + \\Phi^{-1} \\left(1-\\frac{1-\\gamma}{2}\\right)\\frac{\\sigma}{\\sqrt{N}}\\right]$$\n",
    "\n",
    "OK, so we can think of this like the master formula for calculating the confidence interval\n",
    "\n",
    "We'll call this the $z$ confidence interval since it's based on the standard normal\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Some Different Notation</h3>\n",
    "\n",
    "Note that sometimes we'll see the confidence interval written in a different way\n",
    "\n",
    "First note that since $z$ comes from the standard normal distribution, we can represent the middle $95 \\%$ as a probability\n",
    "\n",
    "$$\\large 0.95 = P(-1.96 \\le z \\le 1.96)$$\n",
    "\n",
    "Note that we're using $95 \\%$ here for convenience instead of just a generic $\\gamma$, but the same logic applies in either case\n",
    "\n",
    "And note that this is always a true statement, assuming that $-1.96$ and $1.96$ are not approximations \n",
    "\n",
    "It is always true that the area under the standard normal from $-1.96$ to $1.96$ covers $95 \\%$ of the area\n",
    "\n",
    "Next, let's do the same steps to replace $z$ with $\\hat \\mu$, $\\mu$, $\\sigma$, and $N$ \n",
    "\n",
    "$$\\large 0.95 = P(-1.96 \\le \\frac{\\hat \\mu - mu}{\\sigma / \\sqrt{N}} \\le 1.96)$$\n",
    "\n",
    "\n",
    "The important thing to note about this formula is that it is not interpreted as the probability that $\\mu$ is between these values\n",
    "\n",
    "Instead, recall that we are using a frequentist interpretation of statistics\n",
    "\n",
    "What this means is that this is not a probability, but rather a relative frequency\n",
    "\n",
    "In other words, it means that if we do some experiment many times, then $95 \\%$ of those times the true $\\mu$ will be contained in the confidence interval\n",
    "\n",
    "$$\\large 0.95 \\approx \\frac{\\text{# of experiments where } \\mu \\text{ is contained in the 95% CI}}{\\text{# of total experiments}}$$\n",
    "\n",
    "At first this might sound strange, but in fact we can show in code that this is true\n",
    "\n",
    "---\n",
    "\n",
    "<h3>One small Wrinkle</h3>\n",
    "\n",
    "Now, there's one small problem with the preceding derivation\n",
    "\n",
    "If we look at a confidence interval carefully, we should recognize that there is one value which we do not know\n",
    "\n",
    "This value is $\\sigma$\n",
    "\n",
    "$$95\\% - CI = \\left[\\hat\\mu - 1.96 \\frac{\\boxed{\\sigma}}{\\sqrt{N}},\\hat \\mu + 1.96 \\frac{\\boxed{\\sigma}}{\\sqrt{N}}\\right]$$\n",
    "\n",
    "Remember that we only have the data\n",
    "\n",
    "$$\\text{Data : } \\{x_1,\\ldots,x_N\\}$$\n",
    "\n",
    "We don't know it's mean and typically we don't know its variance\n",
    "\n",
    "Luckily, this can be simply approximated by using the sample variance\n",
    "\n",
    "$$\\large \\hat \\sigma = \\sqrt{\\frac{1}{N-1} \\sum^N_{i=1}\\left(x_i - \\bar x \\right)^2}$$\n",
    "\n",
    "This is not precise, but it's a very common approximation to use in the real world\n",
    "\n",
    "Furthermore, if we have lots of samples or in other words $N$ is large, then this becomes more accurate\n",
    "\n",
    "Typically, statisticians use the <strong>unbiased</strong> estimate of the variance, which is one $\\frac{1}{N-1} \\sum\\limits^N_{i=1}\\left(x_i - \\bar x \\right)^2$\n",
    "\n",
    "Then the estimate of $\\sigma$ is simply the square root of the estimate of the variance\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Central Limit Theorem</h3>\n",
    "\n",
    "The last thing we want to mention in this section,  is that it's very common to employ the central limit theorem to confidence intervals\n",
    "\n",
    "Recall that in our derivation, our only requirement was that our estimate $\\hat \\mu$ was normally distributed\n",
    "\n",
    "In the previous section, and this section, we assume that the data itself was normally distributed \n",
    "\n",
    "And then by the rules of probability, $\\hat \\mu$, must be normally distributed as well\n",
    "\n",
    "However, note that because $\\hat \\mu$ is essentially the sum of many random variables, it converges to a normal distribution no matter what the distribution of the data is\n",
    "\n",
    "Therefore, it's often the case that people use the $z$ confidence interval even when the data is not normally distributed\n",
    "\n",
    "$$\\large \\text{Exact : } X \\sim N(\\mu,\\sigma^2) \\rightarrow \\hat \\mu \\sim N\\left(\\mu,\\frac{\\sigma^2}{N}\\right)$$\n",
    "\n",
    "$$\\large \\text{Approximation : } E(X) = \\mu, var(X) = \\sigma^2 \\rightarrow \\hat \\mu \\sim N\\left(\\mu,\\frac{\\sigma^2}{N}\\right)$$\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Example: Bernoulli</h3>\n",
    "\n",
    "To give an example of this, let's consider how we would do this for the Bernoulli random variable\n",
    "\n",
    "As we recall, these are coin flips, so the only possible values are zero and one\n",
    "\n",
    "$$\\large \\text{Coin flip : } X \\in \\{0,1\\}$$\n",
    "\n",
    "It might surprise us to see that such a distribution might lead to a normal approximation\n",
    "\n",
    "But if you plot a histogram of the sample mean, we will find this to be true\n",
    "\n",
    "Let's suppose that the $X$s are drawn from a Bernoulli distribution with parameter $p$\n",
    "\n",
    "$$X \\sim \\text{Bernoulli(p) iid} $$\n",
    "\n",
    "OK, so as before, we know that $\\hat p$ is simply the sample mean of the $X$s\n",
    "\n",
    "$$\\large \\hat p \\ \\bar X$$\n",
    "\n",
    "Again, we assume that the $X$s are IID samples\n",
    "\n",
    "The only difference now, which is not visible from this expression, is that all the $X$s only take on the values zero or one\n",
    "\n",
    "We know that the true meaning of $\\hat p$ is $p$, \n",
    "\n",
    "$$\\large E(\\hat p ) = E(X) = p$$\n",
    "\n",
    "but what is its variance?\n",
    "\n",
    "As before, its variance is equal to the variance of $X$ divided by $N$, but what is the variance of $X$?\n",
    "\n",
    "Well, we could check this on Wikipedia or you could calculate this by definition, but either way we would get that the variance of $X$ is equal to \n",
    "\n",
    "$$\\large var(X) = p(1-p)$$\n",
    "\n",
    "tTherefore the distribution of $\\hat p$ is approximately normal with mean $p$ and variance $\\frac{p(1-p)}{N}$ \n",
    "\n",
    "$$\\large \\hat p \\rightarrow N \\left( p, \\frac{p(1-p)}{N}\\right)$$\n",
    "\n",
    "---\n",
    "\n",
    "As before, we can apply our master formula to arrive at the lower and upper end points for the $95 \\%$ confidence interval for $p$ \n",
    "\n",
    "In particular \n",
    "\n",
    "$$\\large \\left[ \\hat p - 1.96 \\sqrt{\\frac{\\hat p (1-\\hat p)}{N}},\\hat p + 1.96 \\sqrt{\\frac{\\hat p (1- \\hat p)}{N}}\\right]$$\n",
    "\n",
    "So this is an example of where the data is not normal, but since the sample mean is approximately normal, we can still use the $z$ confidence interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we are going to expand our understanding of confidence intervals even further \n",
    "\n",
    "---\n",
    "\n",
    "<h3>Confidence Intervals Continued</h3>\n",
    "\n",
    "Previously, in our master formula for the confidence interval, we noted that there is one value which we do not actually know\n",
    "\n",
    "This is the variance of the data called $\\sigma$ in this equation\n",
    "\n",
    "$$\\large \\text{CI} = \\left[ \\hat \\mu + z_\\text{left} \\frac{\\sigma}{\\sqrt{N}},\\hat \\mu + z_\\text{right} \\frac{\\sigma}{\\sqrt{N}}\\right]$$\n",
    "\n",
    "Instead, we replaced it with $\\hat \\sigma$, had our estimate of $\\sigma$\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Moving Back a Few Steps</h3>\n",
    "\n",
    "In order to make our answer more accurate, we have to move back a few steps\n",
    "\n",
    "In particular, let's consider the standardised variable, which we'll now call $t$ \n",
    "\n",
    "$$\\large t = \\frac{\\hat \\mu - \\mu}{\\hat \\sigma / \\sqrt{N}}$$\n",
    "\n",
    "Recall that $\\hat \\sigma / \\sqrt{N}$ is the standard deviation estimate of $\\hat \\mu$, so above, we are just subtracting the mean and dividing by standard deviation of $\\hat \\mu$, nothing new \n",
    "\n",
    "What is important to recognize about this quantity is that it is not normally distributed\n",
    "\n",
    "If we go back to first principles, we can see that if we only had to consider the numerator, which is what we were doing before, then all we would have is the sum of the $X$s, which would be normal if the $X$s were also normal\n",
    "\n",
    "But recognize that now not only is the numerator a function of random variables, the denominator is also a function of random variables\n",
    "\n",
    "As we recall, $\\hat \\sigma$ is the sample standard deviation, it depends on the data\n",
    "\n",
    "---\n",
    "\n",
    "<h3>A Trick</h3>\n",
    "\n",
    "So before we move on, let's consider a little trick\n",
    "\n",
    "Suppose that we do know the true value of $\\sigma$\n",
    "\n",
    "If we divide both the top and bottom by the true $\\sigma$, what do we get?\n",
    "\n",
    "$$\\large t = \\frac{\\hat \\mu - \\mu}{\\hat \\sigma / \\sqrt{N}} \\times \\frac{1 / \\sigma}{1 / \\sigma} = \\left( \\frac{\\hat \\mu - \\mu}{\\sigma / \\sqrt{N}} \\right) \\Big/ \\left(\\frac{\\hat \\sigma}{\\sigma}\\right)$$\n",
    "\n",
    "Well, now we can see that the numerator is something we recognize \n",
    "\n",
    "Since the numerator has $\\hat \\mu$ standardised\n",
    "\n",
    "using the ture $\\mu$ and the true $\\sigma$, the numerator is a standard normal random variable\n",
    "\n",
    "And note that we don't actually need to know the true value of $\\sigma$ in order to do this operation\n",
    "\n",
    "We'll see why in a moment\n",
    "\n",
    "But what about the denominator?\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Denominator Only</h3>\n",
    "\n",
    "Let's consider only the denominator\n",
    "\n",
    "As we recall, the unbiased estimator for the variance is given by the equation\n",
    "\n",
    "$$\\large \\hat \\sigma^2 = \\frac{1}{N-1} \\sum^N_{i=1}\\left(x_i - \\bar x \\right)^2$$\n",
    "\n",
    "So we can write the denominator $\\large \\left( \\frac{\\hat \\sigma}{\\sigma} \\right)^2$ as \n",
    "\n",
    "$$\\large \\left( \\frac{\\hat \\sigma}{\\sigma} \\right)^2 = \\frac{1}{N-1} \\sum^N_{i=1} \\left(\\frac{x_i - \\bar x}{\\sigma}\\right)^2$$\n",
    "\n",
    "The question is, if we declare this to be a new random variable, what would be the distribution of this random variable?\n",
    "\n",
    "The derivation behind this is outside the scope of these notebooks, but the result is this\n",
    "\n",
    "In particular\n",
    "\n",
    "$$\\large (N-1) \\left(\\frac{\\hat \\sigma}{\\sigma}\\right)^2 \\sim \\chi^2_{N-1}$$\n",
    "\n",
    "Recall, $\\chi^2_{N-1}$ denotes a chi-squared distribution, with $N-1$ degrees of freedom\n",
    "\n",
    "If we're interested in why this is, we can look into the fact that if we have $z_1,\\ldots,z_N$, which comes from the standard normal, then\n",
    "\n",
    "$$\\large z \\sim N(0,1) \\rightarrow \\sum^N_{i=1}(z_i - \\bar z)^2 \\sim \\chi^2_{N-1}$$\n",
    "\n",
    "---\n",
    "\n",
    "<h3>The Definition of t-Distribution</h3>\n",
    "\n",
    "Finally, it turns out that if we have a standard normal random variable divided by the square root of a chi square random variable which is divided by the degrees of freedom , the result is a new random variable which is  $t$-distributed :o \n",
    "\n",
    "\n",
    "$$\\large t = \\frac{z}{\\sqrt{V/\\nu}} \\sim t_\\nu$$\n",
    "\n",
    "This $t$-distribution has $N-1$ degrees of freedom\n",
    "\n",
    "So this may sound confusing, but basically the facts we have to keep in mind are as follows\n",
    "\n",
    "First, because we have a function of random variables, this just gives us another random variable\n",
    "\n",
    "Therefore it must have some distribution\n",
    "\n",
    "And our goal is to answer the question, what is this distribution?\n",
    "\n",
    "It turns out that if the numerator is a standard normal and the denominator is the square root of a chi square which is divided by the degrees of freedom, then the ratio of the two gives us a $t$-distributed random variable\n",
    "\n",
    "\n",
    "$$\\large \\frac{\\text{standard normal}}{\\sqrt{\\text{chi-square/ deg of freedom}}} \\sim t_{\\text{deg of freedom}}$$\n",
    "\n",
    "\n",
    "If we want to keep it simple, then simply remember that when you standardize $\\bar x$ or $\\hat \\mu$ with the sample standard deviation, it's going to be $t$-distributed with $N-1$ degrees of freedom\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Intuition</h3>\n",
    "\n",
    "So what's the intuition behind this?\n",
    "\n",
    "<img src='extras/51.7.PNG' width='500'></img>\n",
    "\n",
    "Well, the $t$ distribution, if you look at it visually, looks a lot like the normal distribution\n",
    "\n",
    "It's shaped like a bell curve\n",
    "\n",
    "This should give us some confidence that what we were doing previously made sense\n",
    "\n",
    "And if that made sense, then what we are doing now also makes sense\n",
    "\n",
    "Basically, it's the same thing, just slightly modified.\n",
    "\n",
    "It turns out that the $t$ distribution differs from the normal distribution in one major way \n",
    "\n",
    "This is, that the tails of the $t$ distribution are fatter\n",
    "\n",
    "In other words, they have more weight \n",
    "\n",
    "In other words, more probability is assigned to more extreme values\n",
    "\n",
    "And this should be very intuitive because previously we assumed that we knew $\\sigma$ \n",
    "\n",
    "Since now we have to account for the fact that we don't know $\\sigma$ our confidence should be more spread out\n",
    "\n",
    "---\n",
    "\n",
    "<h3>t-Confidence Interval</h3>\n",
    "\n",
    "OK, so knowing this, how can we construct our $t$-confidence interval?\n",
    "\n",
    "Well again, it's the same story\n",
    "\n",
    "Since we know that our $t$ statistic has a $t$ distribution with $N-1$ degrees of freedom, we just have to find the points at which we cover $2.5 \\%$ and $97.5 \\%$ of the area of this distribution, assuming we're interested in the $95 \\%$ confidence interval\n",
    "\n",
    "<img src='extras/51.8.PNG' width='400'></img>\n",
    "\n",
    "Now, unlike the standard normal distribution, this has one parameter, which is the degrees of freedom currently assigned the value $N-1$\n",
    "\n",
    "Therefore, this is not going to be fixed as it was in the previous sections\n",
    "\n",
    "It actually depends on how many samples we've collected\n",
    "\n",
    "In other words, we can't just plug in $1.96$\n",
    "\n",
    "It's going to depend on the value of $N-1$\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Caclulating the endpoints</h3>\n",
    "\n",
    "So practically speaking, how can we compute these values?\n",
    "\n",
    "Let's assume that we're using ```scipy``` so that we have access to the $t$ distribution and all the usual functions like the PDF, CDV, inverse CDF and so forth\n",
    "\n",
    "In this case, it's just like before\n",
    "\n",
    "Suppose that we're interested in $t_\\text{left}$\n",
    "\n",
    "We know that this should cover $2.5 \\%$ under the CDF\n",
    "\n",
    "Therefore we have the CDF of $t_\\text{left}$ given some degrees of freedom, $\\nu$, equal to $0.025$\n",
    "\n",
    "$$\\large t_\\text{left} = F^{-1}(0.025,\\nu=N-1)$$\n",
    "\n",
    "Note that when we talk about the $t$ distribution, we commonly use the symbol $\\nu$ to denote the degrees of freedom\n",
    "\n",
    "So $\\nu$ in this case is equal to $N-1$\n",
    "\n",
    "Therefore $t_\\text{left}$ is equal to the inverse CDF of $0.025$ with $\\nu$ equal to $N-1$\n",
    "\n",
    "In ```scipy```, this can be done using the ```ppf``` function\n",
    "\n",
    "```python\n",
    "t_left = scipy.stats.t.ppf(0.025,df=N-1)\n",
    "```\n",
    "Furthermore, we can calculate $t_\\text{right}$ by using ```ppf``` and passing in $0.975$\n",
    "\n",
    "```python\n",
    "t_right = scipy.stats.t.ppf(0.975,df=N-1)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "OK, so now that we have a $t_\\text{left}$ and $t_\\text{right}$, what do we do?\n",
    "\n",
    "Well, we do the same thing as before\n",
    "\n",
    "We know our $t$-statistic has lower end point equal to $t_\\text{left}$ and upper end point equal to $t_\\text{right}$\n",
    "\n",
    "$$\\large t_\\text{left} \\le t \\le t_\\text{right}$$\n",
    "\n",
    "Therefore, we simply have to rearrange everything to isolate $\\mu$ the parameter of interest\n",
    "\n",
    "$$\\large t_\\text{left} \\le \\frac{\\hat \\mu - mu}{\\hat \\sigma / \\sqrt{N}} \\le t_\\text{right}$$\n",
    "\n",
    "What we should end up with is the exact same formula we had before with the $z$ confidence interval, except now $-1.96$ is replaced with $t_\\text{left}$ and $+1.86$ is replaced with $t_\\text{right}$\n",
    "\n",
    "$$\\large \\hat \\mu + t_\\text{left} \\frac{\\hat \\sigma}{\\sqrt{N}} \\le \\mu \\le \\hat \\mu + t_\\text{right} \\frac{\\hat \\sigma}{\\sqrt{N}}$$\n",
    "\n",
    "And just to be sure, there actually is a $+$ sign in front of $t_\\text{left}$ because $t_\\text{left}$ will actually end up being a negative value since it's on the left side of the $t$ distribution, which is centered around zero\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Summary</h3>\n",
    "\n",
    "OK, so to summarize this section, what did we do?\n",
    "\n",
    "We learned that there is a more accurate way to characterise the confidence interval for a normally distributed estimate $\\hat \\mu$\n",
    "\n",
    "We learned that instead of assuming we know the true variance of the samples, we can assume that it's unknown \n",
    "\n",
    "When we do this, it's still just as easy to find the confidence interval\n",
    "\n",
    "All we have to do is replace the $z_\\text{left}$ and $z_\\text{right}$, which are based on the standard normal, with $t_\\text{left}$ and $t_\\text{right}$, which are based on the $t$-distribution\n",
    "\n",
    "It's worth noting that, for large values of $N$ the $t$ values are pretty close to the $z$ values, so it's very common to see people simply plug in $1.96$, as we did previously\n",
    "\n",
    "Here are some values of $t_\\text{right}$, given varying values of $N$\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>N</td>\n",
    "        <td>50</td>\n",
    "        <td>100</td>\n",
    "        <td>500</td>\n",
    "        <td>1000</td>\n",
    "        <td>10000</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>$t_\\text{right}$</td>\n",
    "        <td>2.010</td>\n",
    "        <td>1.984</td>\n",
    "        <td>1.965</td>\n",
    "        <td>1.962</td>\n",
    "        <td>1.960</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "So we can see that even for values of $N$ even on the small side, the $t_\\text{right}$ values are reasonably close to $1.960$ \n",
    "\n",
    "At the same time, if we're writing code, then it shouldn't be any more effort to use the $t$ compared to the $z$, we're just calling some function in ```scipy```\n",
    "\n",
    "Finally, it's also worth noting that for both the $z$ confidence interval and the $t$ confidence interval, the distribution of $\\hat \\mu$ is assumed to be normal\n",
    "\n",
    "This is not always the case, but it can be justified with the central limit theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>code</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm,t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000 # number of samples\n",
    "mu = 5 # true mean\n",
    "sigma = 2 # true standard deviation\n",
    "# reverse of standardisation\n",
    "# data has mean mu and sd sigma\n",
    "X = np.random.randn(N)*sigma + mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.077624952319204 4.955959806754385 5.199290097884023\n"
     ]
    }
   ],
   "source": [
    "# implement Z-confidence interval\n",
    "# gamma = 95%\n",
    "\n",
    "mu_hat = np.mean(X)\n",
    "sigma_hat = np.std(X,ddof=1)\n",
    "\n",
    "z_left = norm.ppf(0.025)\n",
    "z_right = norm.ppf(0.975)\n",
    "\n",
    "lower = mu_hat + z_left*sigma_hat / np.sqrt(N)\n",
    "upper = mu_hat + z_right*sigma_hat / np.sqrt(N)\n",
    "\n",
    "print(mu_hat,lower,upper)\n",
    "\n",
    "# we see that our mean is equal to about 5, which is expected\n",
    "# also, we see that the interval between the lower and upper endpoints contains the true mean, 5\n",
    "# we expected this to be the case about 95% of the time\n",
    "# or in other times every 19/20 times we run this block of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.077624952319204 4.9558122244324165 5.199437680205992\n"
     ]
    }
   ],
   "source": [
    "# t-confidence interval\n",
    "\n",
    "# same as before\n",
    "mu_hat = np.mean(X)\n",
    "sigma_hat = np.std(X,ddof=1)\n",
    "\n",
    "# again we use ppf, which refers to the inverse CDF\n",
    "# unlike the standard normal, the t-distribution requires the degrees of freedom parameter\n",
    "# as we mentioned, thats equal to N-1\n",
    "t_left = t.ppf(0.025,df=N-1)\n",
    "t_right = t.ppf(0.975,df=N-1)\n",
    "\n",
    "# same as before\n",
    "# with t_left, t_right instead of z_left, z_right\n",
    "lower = mu_hat + t_left*sigma_hat / np.sqrt(N)\n",
    "upper = mu_hat + t_right*sigma_hat / np.sqrt(N)\n",
    "\n",
    "print(mu_hat,lower,upper)\n",
    "\n",
    "# the estimated mean is the same, not changed from before\n",
    "# also the lower and upper endpoints are extemely close to the z-interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we want to do an experiment to test hte interpretation of confidence interval\n",
    "# according to the frequentist interpretation of CI, 95% of the time the interval will contain the true mean\n",
    "# this means that 5% of the time, the interval will no contain the true mean\n",
    "\n",
    "def experiment():\n",
    "    X = np.random.randn(N)*sigma + mu\n",
    "    mu_hat = np.mean(X)\n",
    "    sigma_hat = np.std(X,ddof=1)\n",
    "    t_left = t.ppf(0.025,df=N-1)\n",
    "    t_right = t.ppf(0.975,df=N-1)\n",
    "    lower = mu_hat + t_left *sigma_hat / np.sqrt(N)\n",
    "    upper = mu_hat + t_right *sigma_hat / np.sqrt(N)\n",
    "    return mu > lower and mu < upper # check if mu in range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_experiment(M):\n",
    "    return np.mean([experiment() for _ in range(M)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9506"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_experiment(10000)\n",
    "# so we see that, our of 10,000 trials\n",
    "# the CI contain the true mean about 95% of the time as we expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we are going to begin discussing another essential concept in frequentist statistics which is hypothesis testing\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Hypothesis Testing Examples</h3>\n",
    "\n",
    "Hypothesis testing is easiest to understand when we consider real world practical examples.\n",
    "\n",
    "So let's think of some\n",
    "\n",
    "The first example is the classic scenario where we are drug makers who want to test the effectiveness of a drug\n",
    "\n",
    "We want to know, does this drug have some improvement over the standard treatment for some condition?\n",
    "\n",
    "Let's suppose we are making a drug in order to eliminate some bad stuff from the patient's body, whatever that may be\n",
    "\n",
    "The standard treatment takes some number of days in order to eliminate all this bad stuff (on average)\n",
    "\n",
    "The new drug we are developing also takes some number of days in order to eliminate all this bad stuff (also on average)\n",
    "\n",
    "In such an experiment, we would split our study participants into two groups, the control group and the treatment group\n",
    "\n",
    "The control group is the group that receives the current standard treatment or a placebo or no treatment at all\n",
    "\n",
    "The treatment group is the group that receives our new drug or whatever treatment we are trying to develop\n",
    "\n",
    "The question we might want to consider is, does the new drug work faster?\n",
    "\n",
    "That is, does the new drug on average take less time to work?\n",
    "\n",
    "And is the difference statistically significant?\n",
    "\n",
    "We'll discuss what we mean by statistically significant later in this section and we'll revisit this concept over the next few sections\n",
    "\n",
    "---\n",
    "\n",
    "Here's another example, suppose that we have two Web page designs \n",
    "\n",
    "We want to measure which Web page leads to the longest time spent on that page?\n",
    "\n",
    "Generally speaking, we want users to spend more time on our page, meaning that it's more engaging\n",
    "\n",
    "Practically, what we are going to do is serve each Web page to a bunch of different users and then use that data to determine if the time spent on either page is different or not\n",
    "\n",
    "Thus, again, we have the same scenario where we would like to take measurements from two different groups and we want to know whether the difference is statistically significant\n",
    "\n",
    "---\n",
    "\n",
    "Here's another example, suppose that we've been watching some stock and we want to calculate the daily returns for that stock\n",
    "\n",
    "For many stocks, if we plot their distribution, they look like bell curves centred around zero\n",
    "\n",
    "<img src='extras/51.9.PNG' width='500'></img>\n",
    "\n",
    "Of course, stock returns will not be exactly centered at zero, and in fact, we hope that they will be greater than zero so that we can make money \n",
    "\n",
    "For reasons we'll understand later, it is not enough to simply calculate the average daily return and check whether or not it is greater than zero\n",
    "\n",
    "Sometimes the individual daily return will be greater than zero, but sometimes the individual daily return may be negative and in fact very negative\n",
    "\n",
    "Overall, perhaps the average daily return is greater than zero, but it being greater than zero is not enough\n",
    "\n",
    "We want to know if the effect is statistically significant\n",
    "\n",
    "---\n",
    "\n",
    "OK, so hopefully the previous examples give us some intuition on what hypothesis testing is all about and how it can be used in the real world \n",
    "\n",
    "At this point, we are going to generalize these concepts \n",
    "\n",
    "First we'll recognize that the previous examples we just saw are not all the same\n",
    "\n",
    "When we're comparing a new drug and the standard treatment or we're comparing two different Web pages, we will have two groups of data.\n",
    "\n",
    "We have one group corresponding to the drug and one group corresponding to the standard treatment\n",
    "\n",
    "In general, these are called two sample tests\n",
    "\n",
    "<img src='extras/51.10.PNG' width='600'></img>\n",
    "\n",
    "On the other hand, when we're comparing the daily return of some stock against some fixed value like zero, then we only have one group of data which all come from the same stock\n",
    "\n",
    "In this case, we call that a one sample test\n",
    "\n",
    "<img src='extras/51.11.PNG' width='600'></img>\n",
    "\n",
    "There's only one group to compare against a fixed number\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Notation and Terminology</h3>\n",
    "\n",
    "There's another distinction we can make \n",
    "\n",
    "In order to discuss this, we need to introduce the concept of the null hypothesis and the alternative hypothesis\n",
    "\n",
    "So here's some notation\n",
    "\n",
    "Suppose that in order to test our new drug, our null hypothesis is that the effect of the new drug is the same as the effect of the standard treatment\n",
    "\n",
    "The alternative hypothesis is that they are not the same\n",
    "\n",
    "Our notation for the null hypothesis is $H_0$\n",
    "\n",
    "We then write a colon $:$ followed by $\\mu_1 = \\mu_2$, indicating that the null hypothesis is that the mean value of group one is equal to the mean value of Group two\n",
    "\n",
    "$\\text{Null Hypothesis : }$\n",
    "\n",
    "$$\\large H_0 = \\mu_1 = \\mu_2$$\n",
    "\n",
    "We use the mean because of course every measurement is going to be different\n",
    "\n",
    "What we are concerned with is the overall average effect of our drug\n",
    "\n",
    "The alternative hypothesis is denoted $H_1$\n",
    "\n",
    "Again, this is followed by a colon $:$ and then we have $\\mu_1 \\neq \\mu_2$\n",
    "\n",
    "This indicates that under the alternative hypothesis, the mean value of group one is not equal to the mean value of group\n",
    "\n",
    "$\\text{Alternative Hypothesis : }$\n",
    "\n",
    "$$\\large H_1 = \\mu_1 = \\mu_2$$\n",
    "\n",
    "Our goal when we are doing hypothesis testing is to detect whether or not $H_1$ could be true, thus rejecting the null hypothesis\n",
    "\n",
    "OK, so why are we talking about this and what's the purpose of this notation?\n",
    "\n",
    "---\n",
    "\n",
    "<h3>1- Sided Test vs. 2-Sided Test</h3>\n",
    "\n",
    "In this case, what we just described is called a two sided test, because there are two ways in which the drug can be different from the control\n",
    "\n",
    "The effect of the drug can be less or the effect of the drug can be greater\n",
    "\n",
    "Those are two different scenarios under the same hypothesis\n",
    "\n",
    "On the other hand, the alternative hypothesis may simply be that the effect of a drug is greater than the effect of the standard treatment\n",
    "\n",
    "In this case, we call it a one sided test\n",
    "\n",
    "So the notation for this is slightly different \n",
    "\n",
    "Since the alternative now is that $\\mu_2$ is greater than $\\mu_1$ we use a greater than sign $>$ instead of a not equal sign $\\neq$\n",
    "\n",
    "Another way to think of this is that the distribution of Group two could be to the left or to the right of Group one\n",
    "\n",
    "<img src='extras/51.12.PNG'></img>\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Example with Stock Returns</h3>\n",
    "\n",
    "Note that the same concepts can apply to our stock return example, which is a one sample test \n",
    "\n",
    "We can check if the mean daily stock return is not equal to zero, or we can check if the mean daily stock return is greater than zero specifically, since it being less than zero is not necessarily something we care about\n",
    "\n",
    "Again, these are two sided and a one sided test respectively\n",
    "\n",
    "OK, so these are just two ways we can categorize different kinds of tests\n",
    "\n",
    "We can have one sample test or two sample tests\n",
    "\n",
    "We can also have one sided tests or two sided tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So why do we care about this idea of statistical significance?\n",
    "\n",
    "Why can't we just pick the one with the best average value and then claim that one to be the best?\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Statistical Significance</h3>\n",
    "\n",
    "Well, let's think about this idea that we're comparing two groups of patients, the treatment group and the control group\n",
    "\n",
    "We take some measurements for both groups and then we take the average\n",
    "\n",
    "It should be obvious that when we take the average of the treatment group and the control group, one of those averages will be bigger than the other one\n",
    "\n",
    "This is just a simple fact of numbers\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Examples to Consider</h3>\n",
    "\n",
    "Imagine this, suppose we take a coin and we flip it 100 times and we calculate the empirical win rate\n",
    "\n",
    "Then we take another coin, flip it 100 times and calculate the empirical win rate\n",
    "\n",
    "Clearly, one of these will have a higher empirical probability of heads\n",
    "\n",
    "Let's say coin number one got heads 52 out of 100 times, but coin number two got heads 49 out of 100 times\n",
    "\n",
    "Does this mean that coin number one truly has a higher probability of heads compared to coin number two?\n",
    "\n",
    "Clearly, the answer is no\n",
    "\n",
    "And clearly, we would have expected to see a result like this, even though the true probability of heads for both coins is probably 50 percent\n",
    "\n",
    "Knowing this, we surely would not want to declare that one of these coins has a higher probability of heads than the other based on such a flimsy experiment\n",
    "\n",
    "So what's the solution?\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Examples to Consider</h3>\n",
    "\n",
    "Perhaps this may be surprising, but this idea of hypothesis testing is closely tied to confidence intervals\n",
    "\n",
    "To give ourselves some intuition for this, consider our coin toss example once again \n",
    "\n",
    "Let's take an extreme example \n",
    "\n",
    "For both coins, we flip them just once\n",
    "\n",
    "For coin number one, we get heads, but for coin number two, we get tails\n",
    "\n",
    "Clearly, this is not a good experiment\n",
    "\n",
    "we don't want to claim coin number one has a higher probability of heads simply because we got heads once\n",
    "\n",
    "Now consider the case where we flip each coin 10 times\n",
    "\n",
    "This is an improvement, but intuitively it's still not trustworthy\n",
    "\n",
    "How about one hundred times this seems better\n",
    "\n",
    "How about 1000 times?\n",
    "\n",
    "This seems even better\n",
    "\n",
    "It's clear that for the perfect experiment, although it would be impractical, an infinite number of samples would give us a definitive answer\n",
    "\n",
    "---\n",
    "\n",
    "Now, let's consider another scenario, suppose that we're comparing to stocks and we're measuring the returns for each stock \n",
    "\n",
    "<img src='extras/51.13.PNG' width='350'></img>\n",
    "\n",
    "With stock number one, the average daily return is $10$ basis points and the standard deviation is $5$ basis points \n",
    "\n",
    "With stock number two, the average daily return is $15$ basis points and the standard deviation is $6$ basis points\n",
    "\n",
    "In this case, would we be confident in saying that stock number two is better than stock number one\n",
    "\n",
    "Based on this picture, probably the answer would be no\n",
    "\n",
    "There is so much overlap in their distributions that it's not clear which one truly is better\n",
    "\n",
    "---\n",
    "\n",
    "Now, consider a different result\n",
    "\n",
    "Suppose that the average daily return for stock number one is still $10$ basis points, but the standard deviation is now $1$\n",
    "\n",
    "Suppose that the average daily return for stock number two is still $15$ basis points, but the standard deviation is also now $1$\n",
    "\n",
    "<img src='extras/51.14.PNG' width='350'></img>\n",
    "\n",
    "Based on this picture, would we be more confident in saying that stock number two is better than stock number one?\n",
    "\n",
    "Intuitively, this picture should make us more confident in making such a declaration because there is less overlap between the two distributions\n",
    "\n",
    "---\n",
    "\n",
    "<h3>What Have We learned?</h3>\n",
    "\n",
    "So what have we learned?\n",
    "\n",
    "We've learned that comparing two groups is not simply just a matter of comparing their averages, their averages will always be different in every experiment\n",
    "\n",
    "One must have a higher average than the other , so this is not a useful thing to compare\n",
    "\n",
    "Furthermore, we have uncovered two crucial new variables that do seem to be useful\n",
    "\n",
    "They are\n",
    "\n",
    "<ul>\n",
    "    <li>the number of samples collected</li>\n",
    "    <li>the variance in the samples</li>\n",
    "</ul>\n",
    "\n",
    "This should remind us exactly of confidence intervals, since these two items are also what affects the width of the confidence interval\n",
    "\n",
    "Generally speaking, all of these variables are highly relevant when we assess whether or not the results of our hypothesis test is statistically significant\n",
    "\n",
    "If the difference between the average of the two groups is not large enough, then the result is not statistically significant\n",
    "\n",
    "If there are not enough samples, then the result is not statistically significant\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td></td>\n",
    "        <td style=\"text-align:left\"><strong>Factors affecting statistical significance</strong></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">#1</td>\n",
    "        <td style=\"text-align:left\">Effect size (difference in the means)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">#2</td>\n",
    "        <td style=\"text-align:left\">Variance</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">#3</td>\n",
    "        <td style=\"text-align:left\">Sample size</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "If the variance in the data is too large, then again, the result is not statistically significant\n",
    "\n",
    "In later sections, we will learn how to quantify statistical significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will learn the API approach to hypothesis testing and we will learn how statistical significance is encapsulated in a value called the $p$ value\n",
    "\n",
    "---\n",
    "\n",
    "<h3>The \"API Approach\" to Hypothesis Testing</h3>\n",
    "\n",
    "Now, it's important to note that although this is a beginner focused section on how to use hypothesis tests without understanding the underlying math, this is your intuition only\n",
    "\n",
    "It is still strongly recommended that you we beyond just the beginner basics to understand how hypothesis testing really works\n",
    "\n",
    "Probably most statisticians would agree that it's probably not a good idea to just plug and chug our data into a hypothesis test without thinking of the real world meaning behind the process\n",
    "\n",
    "That being said, we think this is still a very helpful view because it allows you to view this process in terms of inputs and outputs\n",
    "\n",
    "What inputs do we pass into a test and what outputs do we get back?\n",
    "\n",
    "How do we interpret those outputs?\n",
    "\n",
    "We can think of this like kind of a ```Scikit-Learn``` for statistical inference\n",
    "\n",
    "---\n",
    "\n",
    "OK, so what is the API approach for hypothesis testing?\n",
    "\n",
    "Firstly, it should be noted that we are going to stick to the kinds of tests that were described in the previous section\n",
    "\n",
    "As we recall, we discussed one sided and two sided tests, as well as one sample and two sample tests\n",
    "\n",
    "So examples would be like, testing the difference between two means, is the average effect of the drug better than the standard treatment?\n",
    "\n",
    "That would be a one sided two sample test\n",
    "\n",
    "Another example would be, is the daily stock return for some stock equal to zero or not equal to zero?\n",
    "\n",
    "That would be a two sided one sample test\n",
    "\n",
    "So this defines the input into a hypothesis test\n",
    "\n",
    "Clearly, for the one sample test, our data would be a one-dimensional array of numbers, those numbers being the samples from our dataset \n",
    "\n",
    "For the two sample test, our data would be two one-dimensional arrays of numbers\n",
    "\n",
    "OK, so hopefully that's pretty simple.\n",
    "\n",
    "---\n",
    "\n",
    "<h3>The Hypothesis Testing Function</h3>\n",
    "\n",
    "Next, we're going to pass these arrays into a hypothesis testing function\n",
    "\n",
    "Our data:\n",
    "\n",
    "<ul>\n",
    "    <li>1-sample test : $x$</li>\n",
    "    <li>2-sample test : $x1,x_2$</li>\n",
    "</ul>\n",
    "\n",
    "Obviously, we have to choose the correct function depending on what kind of test you want to do\n",
    "\n",
    "Basically, for the examples we looked at previously, usually the $z$-test or the $t$-test is a fine choice\n",
    "\n",
    "As we'll learn later, both the $z$-test and the $t$-test work for both one sample and two sample tests\n",
    "\n",
    "In stats models, the $z$-test function works for both the one sample tests and the two sample tests, so we can use the same function in both cases\n",
    "\n",
    "Note that the $z$-test currently does not appear in ```scipy``` \n",
    "\n",
    "For the $t$-test, we find the ```scipy``` interface to be simpler \n",
    "\n",
    "In ```scipy```, we would be interested in the functions at ```ttest_ind``` in the case where we are doing a two sample test and ```ttest_1samp``` in the case where we are doing a one sample test\n",
    "\n",
    "As we can see, all that's needed is to pass our data, which we described previously into one of these functions\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>Library</td>\n",
    "        <td>1-sample test</td>\n",
    "        <td>2-sample test</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Statsmodels</td>\n",
    "        <td><strong>ztest(x)</strong></td>\n",
    "        <td><strong>ztest(x1,x2)</strong></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Scipy</td>\n",
    "        <td><strong>ttest_1samp(x)</strong></td>\n",
    "        <td><strong>ttest_ind(x1,x2)</strong></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "---\n",
    "\n",
    "<h3>What is the Output</h3>\n",
    "\n",
    "After we call these functions, we're going to get some output\n",
    "\n",
    "<img src='extras/51.15.PNG' width='600'></img>\n",
    "\n",
    "Essentially, this will usually consist of two items, a test statistic and a $p$-value\n",
    "\n",
    "We are more interested in the $p$-value.\n",
    "\n",
    "So what do these outputs mean?\n",
    "\n",
    "In later sections, we will learn what these values mean mathematically, but in this section we will learn what they mean from an API perspective\n",
    "\n",
    "Essentially, the $p$-value is telling us whether or not the difference you observed is statistically significant\n",
    "\n",
    "Of course, the $p$-value is just a number\n",
    "\n",
    "So how can you interpret this number?\n",
    "\n",
    "---\n",
    "\n",
    "<h3>P-value Interpretation</h3>\n",
    "\n",
    "So basically, the super dumb, no math approach of looking at the $p$-value is this \n",
    "\n",
    "First know that the, $p$-value is a probability\n",
    "\n",
    "The technical definition is that it's the probability we will observe something as extreme or more extreme when the null hypothesis is true\n",
    "\n",
    "For example, if the null hypothesis is that the daily stock return is zero, but we find that the average daily stock return is actually $100$ basis points with a variance of $10$, then we would expect that the $p$ value will be very small, since if the daily stock return actually were zero, then this observation would be very unlikely\n",
    "\n",
    "OK, so the $p$-value doesn't usually come by itself, but it is presented relative to some threshold\n",
    "\n",
    "We call this the <strong>significance threshold</strong> or the significance level\n",
    "\n",
    "---\n",
    "\n",
    "In other fields, people call this the maximum allowed a probability of false alarm\n",
    "\n",
    "A false alarm being that, we claim to detect a significant difference when there wasn't really one\n",
    "\n",
    "We may also hear the significance threshold referred to as the maximum allowed probability of type one error\n",
    "\n",
    "Personally, we don't like the terms type one error and type two error because they are not descriptive\n",
    "\n",
    "Which one is type one in which one is type two?\n",
    "\n",
    "Unfortunately, statisticians prefer this terminology\n",
    "\n",
    "Either way, we'll try my best not to use it\n",
    "\n",
    "We think overall the concept of a false alarm is easier to understand\n",
    "\n",
    "In any case, a typical significance threshold would be $5\\%$\n",
    "\n",
    "Therefore, if we find a $p$-value less than $5 \\%$, then we would declare that the result of our hypothesis test was statistically significant\n",
    "\n",
    "OK, so basically from this perspective, the output of our API is a simple binary decision\n",
    "\n",
    "Either the test produced a statistically significant result or it did not\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Comparison to Confidence Intervals</h3>\n",
    "\n",
    "Note again, the similarities to confidence intervals \n",
    "\n",
    "With confidence intervals, it was common to use that $95\\%$ \n",
    "\n",
    "With hypothesis testing, it's common to use $5 \\%$ to declare that an observation was so unlikely it would be considered statistically significant\n",
    "\n",
    "So these are the same, but also kind of the opposite\n",
    "\n",
    "With confidence intervals, we are usually looking inside at the $95 \\%$\n",
    "\n",
    "But with hypothesis testing, we are usually looking outside\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Examples</h3>\n",
    "\n",
    "So let's think of some examples, suppose that we are testing a drug \n",
    "\n",
    "Group A is the control group and Group B is the treatment group \n",
    "\n",
    "We select a significance threshold of $5 \\%$ \n",
    "\n",
    "After calling the $z$-test or the $t$-test function, we find that the $p$-value is $0.01$ \n",
    "\n",
    "since $0.01$ is smaller than $5\\%$\n",
    "\n",
    "We declare that the effect of the treatment is statistically significant\n",
    "\n",
    "---\n",
    "\n",
    "Here's another example \n",
    "\n",
    "Suppose that we are checking whether or not the daily stock return of some stock is greater than zero\n",
    "\n",
    "We select a significance threshold of $1 \\%$ \n",
    "\n",
    "After calling the $z$-test or the $t$-test function\n",
    "\n",
    "We find that the $p$-value is $0.1$\n",
    "\n",
    "In this case, since $0.1$ is greater than $1 \\%$, we declare that although the average daily return may be greater than zero, this result is not statistically significant\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Choosing a Significance Threshold</h3>\n",
    "\n",
    "Now, we might wonder, how does one go about choosing a significant threshold\n",
    "\n",
    "Typically $5 \\%$ is a very common default choice\n",
    "\n",
    "WE may want to consult other papers in our field, to determine what is conventional and what is acceptable\n",
    "\n",
    "Thus, there is no rule of thumb per say, but rather it's probably better to fall in line with our peers\n",
    "\n",
    "We also have to apply common sense\n",
    "\n",
    "If the cost of a false alarm is very high, such as producing a drug that cost billions of dollars but doesn't actually work, then we might want to have a more strict, significant threshold\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Statistical vs. Practical Significance</h3>\n",
    "\n",
    "Finally, it's important to distinguish between statistical significance and practical significance\n",
    "\n",
    "In some cases, a statistically significant difference may not matter in the practical sense\n",
    "\n",
    "For example, if we find that some drug can increase lifespan on average by one second, but this drug costs billions of dollars to make, then is this a practical investment?\n",
    "\n",
    "Probably the answer would be no\n",
    "\n",
    "On the other hand, suppose that we find the clickthrough rate of some advertisement is one percent, but the clickthrough rate for some other advertisement is one point one percent, and this result is statistically significant\n",
    "\n",
    "In this case, this small increase in click through rate may lead to an appreciable difference in revenue for our company\n",
    "\n",
    "So, again, using common sense and applying our domain knowledge is required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, one thing that's worth mentioning is that statisticians are conventionally very strict about terminology\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Terminology</h3>\n",
    "\n",
    "So far we've learned about terms such as the null hypothesis, the alternative hypothesis, the $p$-value and the significance threshold\n",
    "\n",
    "We know that if we find the $p$-value to be very small, below our significant threshold, then we can reject the null hypothesis\n",
    "\n",
    "In this case, we say that the result is statistically significant\n",
    "\n",
    "But what if the $p$-value is not below our significant threshold?\n",
    "\n",
    "We might think that hypothesis testing is like making a binary decision, either we pick one or the other, but in fact, this is not true\n",
    "\n",
    "We cannot pick $H_0$ or pick $H_1$\n",
    "\n",
    "The difference is subtle, but it's important\n",
    "\n",
    "---\n",
    "\n",
    "<h3>What Can we Say?</h3>\n",
    "\n",
    "Our only two options are to reject the null hypothesis or fail to reject the null hypothesis\n",
    "\n",
    "If you get a $p$-value above the significant threshold, we would not say that you accept the null hypothesis\n",
    "\n",
    "Here's an intuitive reason \n",
    "\n",
    "Suppose that we only test your drug on five people\n",
    "\n",
    "The drug actually works, but because we have too few samples, the $p$-value is large\n",
    "\n",
    "We don't simply accepts the null hypothesis, we've just failed to collect enough data to reject it\n",
    "\n",
    "Therefore, we fail to reject the null hypothesis\n",
    "\n",
    "Just because we haven't found enough evidence to reject the null hypothesis, does not imply that the null hypothesis is true.\n",
    "\n",
    "In fact, it's also rare to say that we accept the alternative hypothesis\n",
    "\n",
    "This is even though we might be rejecting the null hypothesis \n",
    "\n",
    "In this case, the difference is even more subtle\n",
    "\n",
    "Generally speaking, if we want to be very, very careful, we'll never accept anything\n",
    "\n",
    "We will only reject the null hypothesis or fail to reject the null hypothesis\n",
    "\n",
    "Now, we realize that at this point, this might seem very philosophical\n",
    "\n",
    "However, we think once you learn more about the math behind hypothesis testing, this concept will become more intuitive and more visual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the last thing we want to mention regarding the API approach is that this API approach can be applied to many different kinds of tests, not just the kind we've been discussing so far\n",
    "\n",
    "---\n",
    "\n",
    "<h3>The \"API Approach\" - More Examples</h3>\n",
    "\n",
    "In these notebooks, we are mainly interested in comparing the average reward out of a set of items\n",
    "\n",
    "For example, which treatment had the largest effect?\n",
    "\n",
    "Which webpage had the strongest engagement?\n",
    "\n",
    "Which advertisement has the highest click rate?\n",
    "\n",
    "However, there are actually many different kinds of tests not related to these notebooks, but they still work the same way \n",
    "\n",
    "In this section, we want to get introduced to some of these tests so we can see that this API approach is uniform, even outside these notebooks\n",
    "\n",
    "Suppose that we have some data that we want to model as normally distributed\n",
    "\n",
    "One common question to ask is, is the data actually normal?\n",
    "\n",
    "An example of this is stock returns\n",
    "\n",
    "When we plot a histogram of stock returns, often they look like a bell curve, and many people would assume that this is a normal distribution\n",
    "\n",
    "<img src='extras/51.16.PNG' width='500'></img>\n",
    "\n",
    "But in fact, there are a few ways to show that this is false\n",
    "\n",
    "One way is to use a hypothesis test \n",
    "\n",
    "Without understanding how the test actually works, we can still understand the API as input we pass in your samples, which are the samples we think might come from a normal distribution \n",
    "\n",
    "As output, we get a $p$-value\n",
    "\n",
    "This $p$-value will tell us whether or not the data is normal\n",
    "\n",
    "The null hypothesis is that the data is normal\n",
    "\n",
    "The alternative hypothesis is that the data is not normal\n",
    "\n",
    "That is, if the data is so much unlike a normal distribution that we must reject its normality, then the $p$-value will be very small\n",
    "\n",
    "But note that interpreting the $p$-value does require us to know what the null and alternative hypotheses actually are\n",
    "\n",
    "But once we know what they are, we don't have to actually know how the test works\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Is My Time Series Stationary?</h3>\n",
    "\n",
    "Here's another example \n",
    "\n",
    "When we're working with Time series data, one common requirement before applying time series methods is that the data is stationary\n",
    "\n",
    "Briefly speaking, this means that the distribution of the data does not change over time\n",
    "\n",
    "Basically, if we plot stationary data over each time step, then it should look the same at all time steps\n",
    "\n",
    "<img src='extras/51.17.PNG' width='400'></img>\n",
    "\n",
    "This is easiest to understand in pictures\n",
    "\n",
    "In the first picture we can see that the data is trending upwards\n",
    "\n",
    "<img src='extras/51.18.PNG' width='400'></img>\n",
    "\n",
    "\n",
    "This indicates that the mean of the data is increasing over time\n",
    "\n",
    "By definition, this must be non -tationary because if the mean is increasing, then the distribution is changing\n",
    "\n",
    "Here's another example, in the second picture, we can see that the variance is increasing over time\n",
    "\n",
    "<img src='extras/51.19.PNG' width='400'></img>\n",
    "\n",
    "\n",
    "The signal is getting more and more spread out as time goes on\n",
    "\n",
    "This is also non-stationary because if the variance is increasing, then the distribution must be changing\n",
    "\n",
    "---\n",
    "\n",
    "Although the actual test is quite complicated, the API approach is simple\n",
    "\n",
    "Again, it's just a matter of simply plugging in our data and checking the $p$-value\n",
    "\n",
    "In this case, the null hypothesis is that the time series is non stationary and the alternative is that it is stationary\n",
    "\n",
    "Therefore, when we plug in our data, if we find that the $p$-value is less than our significance threshold, we will declare that our time series is stationary.\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Summary</h3>\n",
    "\n",
    "OK, so to summarize this lecture, we looked at a few more examples of the API approach to hypothesis testing\n",
    "\n",
    "In these notebooks, we are specifically interested in testing the means of two groups or just one group\n",
    "\n",
    "However, there are many different kinds of tests that do not involve such comparisons\n",
    "\n",
    "Comparing means just happens to be very practical in the real world\n",
    "\n",
    "We learned that even though the test can get quite complicated, the inputs and outputs are the same\n",
    "\n",
    "The input is always our data and the output is always the $p$-value \n",
    "\n",
    "From the $p$-value, we reject or fail to reject the null hypothesis\n",
    "\n",
    "And we can do this even if we don't know how the test works\n",
    "\n",
    "This is called the API approach because it's just like using an API when we are programming\n",
    "\n",
    "We can use the API without knowing how the person who made the API implemented their code\n",
    "\n",
    "For example, you we't need to know how numpy works in order to use numpy, you don't need to know how Sci-kit learn works in order to use Sci-kit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we are going to look at our first statistical test from the ground up known as the $z$-test\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Z-test</h3>\n",
    "\n",
    "Similar to our discussion on confidence intervals, we are going to first assume that everything is normally distributed\n",
    "\n",
    "In fact, our discussion can begin right where we left off with confidence intervals\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Recall: Confidence Intervals</h3>\n",
    "\n",
    "As we recall, in order to construct our confidence interval, we begin with the sample mean \n",
    "\n",
    "We call that either $\\bar x$ or $\\hat \\mu$, either way is fine\n",
    "\n",
    "Next, we find the width of the confidence interval, which is symmetric about the sample mean\n",
    "\n",
    "It's the sample mean, plus some quantity and the sample mean minus that same quantity\n",
    "\n",
    "These define at the upper and lower end points of the confidence interval.\n",
    "\n",
    "Another way of stating this is that we just found the middle $95 \\%$ area of the distribution of the sample mean \n",
    "\n",
    "<img src='extras/51.3.PNG' width='400'></img>\n",
    "\n",
    "This has mean equal to the true mean and variance equal to $\\frac{\\sigma^2}{N}$\n",
    "\n",
    "$$\\large \\hat \\mu \\sim N\\left(\\mu,\\frac{\\sigma^2}{N}\\right)$$\n",
    "\n",
    "So as usual here, we're using $\\sigma$ to mean the standard deviation of the data and not the standard deviation of $\\hat \\mu$\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Consider the 1-Sample Test</h3>\n",
    "\n",
    "Now, the idea behind hypothesis testing is very similar\n",
    "\n",
    "We'll start by considering the one sample test \n",
    "\n",
    "In this case, the null hypothesis is that the sample mean is equal to some fixed value $\\mu_0$\n",
    "\n",
    "$$\\large H_0 : \\mu = \\mu_0$$\n",
    "\n",
    "$$\\large H_1 : \\mu \\neq \\mu_0$$\n",
    "\n",
    "The alternative hypothesis is that the sample mean is not equal to that value \n",
    "\n",
    "In both cases, we'll assume that the variance is known and that it's equal to $\\frac{\\sigma^2}{N}$\n",
    "\n",
    "$$\\large \\text{variance} = \\frac{\\sigma^2}{N}$$\n",
    "\n",
    "Now remember that hypothesis testing is actually centered around rejecting the null hypothesis\n",
    "\n",
    "Therefore, in order to do this test, we only need to consider one question \n",
    "\n",
    "How far away do we have to be so that it makes the data look very unlikely to have come from the null hypothesis distribution?\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Another Perspective on the 1-Sample Test</h3>\n",
    "\n",
    "Well, let's consider writing our null hypothesis in a different way\n",
    "\n",
    "What we are really saying is that, does $\\hat \\mu$ actually come from a normal distribution with mean $\\mu$ and variance $\\frac{\\sigma^2}{N}$\n",
    "\n",
    "$$\\large H_0 : \\hat \\mu \\sim N\\left(\\mu_0,\\frac{\\sigma^2}{N}\\right)$$\n",
    "\n",
    "Now that we've written things in this way, our question becomes a lot easier to answer\n",
    "\n",
    "Firstly, note that we can standardise the random variable $\\hat \\mu$ \n",
    "\n",
    "By subtracting $\\mu_0$ and dividing by $\\sigma/\\sqrt{N}$ we get $z$, which comes from a normal distribution with mean zero and variance one\n",
    "\n",
    "$$\\large H_0 = z = \\frac{\\hat \\mu - \\mu_0}{\\sigma / \\sqrt{N}} \\sim N(0,1)$$\n",
    "\n",
    "We'll call this ($z$) the $z$-statistic\n",
    "\n",
    "Now remember that $z$ is actually a number, this is because $\\mu_0$ and $\\sigma$ are fixed values and they're assumed to be known \n",
    "\n",
    "$N$ is also known since it's the number of samples\n",
    "\n",
    "$\\hat \\mu$ is also known since that'sthe sample mean of our data\n",
    "\n",
    "Therefore, $z$ is just a number after doing this calculation\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Now it Looks Like a Confidence Interval Problem</h3>\n",
    "\n",
    "OK, so now we can see more clearly how this is going to work\n",
    "\n",
    "Our null hypothesis is that $z$ is a number that comes from the standard normal\n",
    "\n",
    "How can we check if this is likely or not?\n",
    "\n",
    "Well, looking at a picture really helps\n",
    "\n",
    "If we draw the standard normal distribution, we can see that in areas with high probability, that's where we would expect $z$ to be if $H_0$ was actually true\n",
    "\n",
    "<img src='extras/51.1.PNG' width='300'></img>\n",
    "\n",
    "Imagine, for example, that we find $z$ equal to one hundred\n",
    "\n",
    "Then clearly this would be a very unlikely scenario\n",
    "\n",
    "Remember that our goal is to reject the null hypothesis\n",
    "\n",
    "Now, suppose that, as usual, we've selected a significant threshold of $5 \\%$\n",
    "\n",
    "Rejecting the null hypothesis means that the value of $z$ that we got is very unlikely, such that it falls outside of the middle $95 \\%$ of the area\n",
    "\n",
    "Thus, we want to know, does $z$ fall into the right $2.5 \\%$ area or the left two $2.5 \\%$ area?\n",
    "\n",
    "This should remind us exactly of the concept of confidence intervals\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Now it Looks Like a Confidence Interval Problem</h3>\n",
    "\n",
    "Now, of course, we already know these thresholds because we've calculated them previously \n",
    "\n",
    "As we recall, they can be calculated from the CDF of the standard normal\n",
    "\n",
    "We get $(-1.96,+1.96)$\n",
    "\n",
    "<img src='extras/51.20.PNG' width='300'></img>\n",
    "\n",
    "Therefore, our hypothesis test gives us the following answer\n",
    "\n",
    "If $z$ is greater then $+1.96$ or less than $-1.96$, then it falls beyond our significance threshold and thus we reject the null hypothesis\n",
    "\n",
    "This means that we found the value of $z$ to be so unlikely that we're confident we've collected enough evidence to show that the null hypothesis is probably not true\n",
    "\n",
    "---\n",
    "\n",
    "<h3>How do we calculate the p-value</h3>\n",
    "\n",
    "The next question we want to consider is how do we calculate the $p$-value?\n",
    "\n",
    "As we recall, the $p$-value is the probability of seeing a result as extreme or more extreme than the result we got\n",
    "\n",
    "So if we found that $z$ equals two, then we're considering the probability that $z$ could be $2$ or more like $2.1$, $3$ or $1000$ or $1000000$ (so any value >= 2 would be \"as extreme or more\")\n",
    "\n",
    "Note that negative values can also be \"as extreme or more\"\n",
    "\n",
    "Therefore, we would also consider the values of $-2$ and less\n",
    "\n",
    "note that $-2$ is considered to be as extreme as $+2$\n",
    "\n",
    "This is because the normal distribution is symmetric\n",
    "\n",
    "<img src='extras/51.21.PNG'></img>\n",
    "\n",
    "---\n",
    "\n",
    "As we recall, we can use the CDF to calculate these values\n",
    "\n",
    "In this case, the $p$-value is equal to the area on the right plus the area on the left\n",
    "\n",
    "Since they're symmetric, we can technically just find one of the areas and multiply it by two\n",
    "\n",
    "But to be thorough, we are going to calculate each of them separately\n",
    "\n",
    "Now, recognize that this will depend on whether or not $z$ is positive or negative\n",
    "\n",
    "Let's suppose that we take the absolute value of $Z$ so that $z$ is always positive\n",
    "\n",
    "Then the area on the right side \n",
    "\n",
    "$$\\large p_\\text{right} = 1 - \\Phi \\left(\\vert z\\vert\\right)$$\n",
    "\n",
    "The area on the left side \n",
    "\n",
    "$$\\large p_\\text{left} = \\Phi(-\\vert z\\vert)$$\n",
    "\n",
    "Finally, we add these two values together, and this is our $p$-value\n",
    "\n",
    "$$\\large p = p_\\text{left} + p_\\text{right}$$\n",
    "\n",
    "So now it's clear why we say that the $p$-value is the probability of obtaining a result as extreme or more extreme than what we observed\n",
    "\n",
    "It should also be clear from this method why we say that we reject the null hypothesis but cannot accept it\n",
    "\n",
    "Failing to reject the null hypothesis simply means that the $z$ we found wasn't extreme enough to reject\n",
    "\n",
    "---\n",
    "\n",
    "<h3>One-Sided Test</h3>\n",
    "\n",
    "So that was the one sample, two sided $z$-test, how about the one sided $z$-test? \n",
    "\n",
    "In this case, everything is the same, except that now we only care about the area on the right side, assuming that the alternative is that $\\mu > \\mu_0$\n",
    "\n",
    "$$\\large H_0 : \\mu \\le \\mu_0$$\n",
    "\n",
    "$$\\large H_1 : \\mu > \\mu_0$$\n",
    "\n",
    "<img src='extras/51.22.PNG' width='300'></img>\n",
    "\n",
    "Note that the test statistic itself, $z$ will be the same\n",
    "\n",
    "So this time, the $p$-value\n",
    "\n",
    "$$\\large p = 1 - \\Phi(z)$$\n",
    "\n",
    "note : we use $z$ without taking the absolute value\n",
    "\n",
    "So why does this make sense?\n",
    "\n",
    "In order to convince ourselves that this works, consider what happens if the alternative hypothesis is true.\n",
    "\n",
    "In this case, $\\hat \\mu - \\mu_0$ will be positive\n",
    "\n",
    "In addition, as we collect more and more data, $N$ will get bigger and therefore $z$ will also get bigger (recall $z = \\frac{\\hat \\mu - \\mu_0}{\\sigma / \\sqrt{N}}$ )\n",
    "\n",
    "Therefore, if the alternative is true, $z$ will become a larger and larger positive number \n",
    "\n",
    "So when the alternative is true, we are looking for $z$ to be very large and positive  \n",
    "\n",
    "And in this case the $p$-value will be very small, and so we should reject the null hypothesis\n",
    "\n",
    "That is to say, $z$ is moving to the right and the area to the right becomes smaller\n",
    "\n",
    "As an exercise, we might want to consider how to do the one sided test if the alternative is that $\\hat \\mu < \\mu_0$ (of course thats just $\\Phi(z)$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we learned how to perform the one sample $z$-test\n",
    "\n",
    "This is when we want to compare the mean of our sample against some fixed value\n",
    "\n",
    "The null hypothesis is that they are equal and the alternative is that they are not, which can be either one sided or two sided\n",
    "\n",
    "We learned that it's essentially the same as computing a confidence interval\n",
    "\n",
    "To recap, this involves calculating the $z$-statistic\n",
    "\n",
    "Then we calculate the lower and upper endpoints that cover $95 \\%$ of the area under the null hypothesis\n",
    "\n",
    "Then we check whether our $z$-statistic falls inside or outside of this area\n",
    "\n",
    "If it falls outside, then we reject the null hypothesis\n",
    "\n",
    "Additionally, we calculate a $p$-value, which tells us the probability of seeing a result as extreme or more extreme than what we observed\n",
    "\n",
    "---\n",
    "\n",
    "<h3>2-sample Z-test</h3>\n",
    "\n",
    "OK, now let's consider the two sample test, in fact, this is very similar\n",
    "\n",
    "<img src='extras/51.23.PNG' width='300'></img>\n",
    "\n",
    "The steps are still the same\n",
    "\n",
    "Step one is to calculate our $Z$-statistic, something that will be a sample from the standard normal under the null hypothesis\n",
    "\n",
    "Step two is to calculate the $p$-value of the $z$-statistic\n",
    "\n",
    "Same as before\n",
    "\n",
    "So the real challenge here is to calculate this $z-$ statistic \n",
    "\n",
    "First, let's write down the null hypothesis and the alternative hypothesis \n",
    "\n",
    "Again, we'll start by assuming that this is a two sided test\n",
    "\n",
    "In this case, the null hypothesis is that $\\mu_1$ is equal to $\\mu_2$\n",
    "\n",
    "$$\\large H_0 : \\mu_1 = \\mu_2$$\n",
    "\n",
    "This would be like saying the new drug has the same effect as the standard treatment\n",
    "\n",
    "The alternative hypothesis is that $\\mu_1$ is not equal to $\\mu_2$ \n",
    "\n",
    "$$\\large H_1 : \\mu_1 \\neq \\mu_2$$\n",
    "\n",
    "We will assume a two sided test for now\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Trick: convert it into a 1-sample test</h3>\n",
    "\n",
    "The trick is to transform this into something that looks like a one sample test \n",
    "\n",
    "In order to do this, let's consider the following\n",
    "\n",
    "First, suppose that all the samples from group one are called $X_1,\\ldots,X_{N_1}$\n",
    "\n",
    "$$\\large \\text{Group 1}: \\{X_1,\\ldots,X_{N_1}\\} \\text{ with mean }\\mu_1$$\n",
    "\n",
    "Therefore, there are $N_1$ samples in the first group.\n",
    "\n",
    "Next, suppose that all the samples from Group two are called $X_1^\\prime,\\ldots,X^\\prime_{N_2}$\n",
    "\n",
    "$$\\large \\text{Group 2}: \\{X^\\prime_1,\\ldots,X^\\prime_{N_2}\\} \\text{ with mean }\\mu_2$$\n",
    "\n",
    "Therefore there are $N_2$ samples in the second group\n",
    "\n",
    "Now let $\\mu_1$ be the mean of the group one samples and let $\\mu_2$ be the mean of the group two samples\n",
    "\n",
    "Recall that the null hypothesis is that $mu_1 = mu_2$\n",
    "\n",
    "$$\\large H_0 : \\mu_1 = \\mu_2$$\n",
    "\n",
    "Clearly this is the same as saying\n",
    "\n",
    "$$\\large H_0 : \\mu_1 = \\mu_2 \\leftrightarrow H_0 : \\mu_1 - \\mu_2 = 0$$\n",
    "\n",
    "---\n",
    "\n",
    "So let's create a new variable called a $y$, which is equal to $\\mu_1 - \\mu_2$\n",
    "\n",
    "$$\\large \\text{Let }y = \\mu_1-\\mu_2$$\n",
    "\n",
    "Now it's easy to see how we can transform this into a one sample test\n",
    "\n",
    "The null hypothesis is that $y$ is equal to zero\n",
    "\n",
    "$$\\large H_0 : y=0$$\n",
    "\n",
    "The alternative hypothesis is that $y$ is not equal to zero\n",
    "\n",
    "$$\\large H_1 : y \\neq 0$$\n",
    "\n",
    "---\n",
    "\n",
    "As we recall, an alternative way of writing the null hypothesis, which will help us derive the test statistic and the $p$-value, is this \n",
    "\n",
    "Under the null hypothesis, $\\hat y$ comes from a normal distribution with mean zero and variance $\\sigma_y^2$\n",
    "\n",
    "$$\\large H_0 : \\hat y \\sim N(0,\\sigma^2_{\\hat y})$$\n",
    "\n",
    "or\n",
    "\n",
    "$$\\large H_0 : \\hat y \\sim N(\\mu_0,\\sigma^2_{\\hat y})$$\n",
    "\n",
    "Now, there are two points of interest here.\n",
    "\n",
    "Firstly, we can see how this can easily be generalized\n",
    "\n",
    "As we recall, in the one sample case, we can compare $y$ to any fixed mean which we were calling $\\mu_0$\n",
    "\n",
    "Therefore we can do the same thing here\n",
    "\n",
    "Usually we would like to simply test whether or not $\\mu_1$ is not the same as $\\mu_2$\n",
    "\n",
    "However, it could also be the case that we are looking for an effect beyond some non-zero magnitude\n",
    "\n",
    "For example, we want $\\mu_1$ to be at least two units greater than $\\mu_2$, so that would be an easy modification to this test\n",
    "\n",
    "Next, recognize that we don't yet know the variance of $\\hat y$\n",
    "\n",
    "We're simply calling it $\\sigma^2_{\\hat y}$ had squared, but as we recall, under the assumptions of the Z test, this should be a fixed known value\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Variance</h3>\n",
    "\n",
    "So here's how we can determine the variance of $\\hat y$ \n",
    "\n",
    "We can do so by first principles\n",
    "\n",
    "Recall that $\\hat y$ is simply $\\hat \\mu_1 - \\hat \\mu_2$\n",
    "\n",
    "$$\\large \\hat y = \\hat \\mu_1 - \\hat \\mu_2$$\n",
    "\n",
    "However, $\\hat \\mu_1$ and $\\hat \\mu_2$ can be expanded in terms of the $X$s and the $X^\\prime$s\n",
    "\n",
    "$$\\large \\hat y = \\frac{x_1+x_2+\\ldots+x_{N_1}}{N_1} - \\frac{x_1^\\prime + x_2^\\prime+\\ldots+x_{N_2}^\\prime}{N_2}$$\n",
    "\n",
    "As usual, we assume all the samples are iide, independent and identically distributed\n",
    "\n",
    "Let's also recall a few basic rules of probability that we should derive on our own in case we've forgotten\n",
    "\n",
    "Firstly, suppose that the variance of $X$ is $\\sigma^2$, then for some constant $c$,\n",
    "\n",
    "$$\\large var(X) = \\sigma^2 \\rightarrow var(cX) = c^2 \\sigma^2$$\n",
    "\n",
    "Next, suppose again that the variance of $X$ is equal to $\\sigma^2$, then \n",
    "\n",
    "$$\\large var(X) = \\sigma^2 \\rightarrow var(-X) = \\sigma^2$$\n",
    "\n",
    "Now we may have thought that it would be $-\\sigma^2$, but of course, that's impossible since variance cannot be negative\n",
    "\n",
    "In fact, the second rule is simply a specific instance of the first rule since we can just plug in a $c = -1$\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Variance Calculation</h3>\n",
    "\n",
    "OK, so using these two facts, what can we do?\n",
    "\n",
    "First, we can calculate the variance of each of the terms on the right side\n",
    "\n",
    "$$ \\large var(\\hat y) = var\\left(\\frac{x_1}{N}\\right) + \\ldots + var\\left(\\frac{x_{N_1}}{N_1}\\right) + var\\left(\\frac{x_1^\\prime}{N_2}\\right) + \\ldots + var\\left(\\frac{x_{N_2}^\\prime}{N_2}\\right)$$\n",
    "\n",
    "Notice how we do not subtract any of the variances, as we may have assumed, due to rule number two on the previous subsection\n",
    "\n",
    "Of course, now we just have to apply rule number one\n",
    "\n",
    "Assuming that the variance of group one is $\\sigma_1^2$ and the variance of Group two is $\\sigma_2^2$, the variance of each term is $\\frac{\\sigma_1^2}{N_1^2}$ or $\\frac{\\sigma_2^2}{N_2^2}$\n",
    "\n",
    "$$\\large var(\\hat y) = \\frac{\\sigma_1^2}{N_1^2} + \\ldots + \\frac{\\sigma_1^2}{N_1^2} + \\frac{\\sigma_2^2}{N_2^2} + \\ldots + \\frac{\\sigma^2_2}{N_2^2}$$\n",
    "\n",
    "Notice that we have and $N_1$ items from the first group and $N_2$ items from the second group \n",
    "\n",
    "Therefore in total we just have the variance of group one divided by $N_1$ plus the variance of group two divided $N_2$\n",
    "\n",
    "$$\\large var(\\hat y) = \\frac{\\sigma_1^2}{N_1} + \\frac{\\sigma^2_2}{N_2}$$\n",
    "\n",
    "And of course, we can just take the square root to get the standard deviation\n",
    "\n",
    "$$\\large \\sigma_{\\hat y} = \\sqrt{\\frac{\\sigma_1^2}{N_1} + \\frac{\\sigma^2_2}{N_2}}$$\n",
    "\n",
    "---\n",
    "\n",
    "<h3>The z-statistic</h3>\n",
    "\n",
    "OK, so after all that hard work, the next few steps should be relatively simple\n",
    "\n",
    "As we recall, we are trying to calculate the $z$-statistic, which is the standard normal under the null hypothesis \n",
    "\n",
    "That is,\n",
    "\n",
    "$$\\large z = \\frac{\\hat y - \\mu_0}{\\sigma_{\\hat y}} = \\frac{\\hat y - \\mu_0}{\\sqrt{\\frac{\\sigma_1^2}{N_1} + \\frac{\\sigma^2_2}{N_2}}}$$\n",
    "\n",
    "OK, so this is our $z$-statistic\n",
    "\n",
    "---\n",
    "\n",
    "<h3>The p-value</h3>\n",
    "\n",
    "As before, we can calculate our $p$-value as follows\n",
    "\n",
    "2-sided test\n",
    "\n",
    "$$\\large p_\\text{right} = 1 - \\Phi(\\vert z\\vert)$$\n",
    "\n",
    "$$\\large p_\\text{left} = \\Phi(-\\vert z\\vert)$$\n",
    "\n",
    "$$\\large p = p_\\text{left} + p_\\text{right}$$\n",
    "\n",
    "1-sided test (>)\n",
    "\n",
    "$$\\large p = 1 - \\Phi(z)$$\n",
    "\n",
    "Again, as an exercise, we might want to consider the expression for the one sided less than test on our own (agian thats just $\\Phi(z)$)\n",
    "\n",
    "However, note that we could also simply use the greater then test and switch the data sets :)\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Summary</h3>\n",
    "\n",
    "So to summarize this section, we learned how to do the two sample Z-test\n",
    "\n",
    "We discovered that the process is mostly similar to the one sample Z-test.\n",
    "\n",
    "The trick was figuring out how to calculate the Z-statistic.\n",
    "\n",
    "And the trick behind that was to treat the two sample test like a one sample test\n",
    "\n",
    "In particular, we created a new variable, which was the difference between the two means \n",
    "\n",
    "And then our test becomes like a one sample test on this new variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Code</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from statsmodels.stats.weightstats import ztest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we are going to implement the z-test ourselves\n",
    "# then cross-reference it with what stats models give us\n",
    "# to make sure that we get the same asnwer\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "mu = 0.2\n",
    "sigma = 1\n",
    "x = np.random.randn(N)*sigma + mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.7981205884493316, 0.07215790025630599)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# two sided test \n",
    "# if we check the documentation, we will see that the reference value (what we are comparing to) = 0\n",
    "# so if we want to compare to any other, we can pass this to value\n",
    "ztest(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.7981205884493316, 0.07215790025630597)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now for our implementation\n",
    "# so this is just applying the equations\n",
    "mu_hat = np.mean(x)\n",
    "sigma_hat = x.std(ddof=1)\n",
    "z = mu_hat/(sigma_hat/np.sqrt(N))\n",
    "# this can be norm.sf(np.abs(z))\n",
    "# also may give more accurate results\n",
    "p_right = 1 - norm.cdf(np.abs(z))\n",
    "p_left = norm.cdf(-np.abs(z))\n",
    "p = p_right + p_left\n",
    "z,p\n",
    "# slight difference is due to numerical precision in floating point numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.7981205884493316, 0.036078950128152994)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one sided test\n",
    "# since this is one-sided\n",
    "# we need to check whether this is the greater than case or less than case\n",
    "# since we know that mu is actually greater than 0 (mu=0.2)\n",
    "# it should make more sense to check the greater than case\n",
    "ztest(x,alternative='larger')\n",
    "# note how we get the same value of z\n",
    "# but half the value of p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.7981205884493316, 0.03607895012815299)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# again, here is our implementation\n",
    "mu_hat = x.mean()\n",
    "sigma_hat = x.std(ddof=1)\n",
    "z = mu_hat / (sigma_hat/np.sqrt(N)) # mu0 = 0, no need to subtract\n",
    "p = 1 - norm.cdf(z)\n",
    "z,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.12053181455609435, 0.9040618789770263)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what happens if we pass in a different reference value mu0\n",
    "mu0 = 0.2 # same as mu\n",
    "# this means that the null hypotheses is actually true\n",
    "ztest(x,value=mu0)\n",
    "# remember\n",
    "# even though we know that the null hypothesis is true (since we created the data)\n",
    "# we can not accept the null hypothesis\n",
    "# we can only fain to reject the null hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.12053181455609435, 0.9040618789770263)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same as the above 2-sided test\n",
    "# but this time we subtract mu\n",
    "mu_hat = np.mean(x)\n",
    "sigma_hat = x.std(ddof=1)\n",
    "z = (mu_hat-mu0)/(sigma_hat/np.sqrt(N))\n",
    "p_right = 1 - norm.cdf(np.abs(z))\n",
    "p_left = norm.cdf(-np.abs(z))\n",
    "p = p_right + p_left\n",
    "z,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we may recall that the purpose of the significance level\n",
    "# is to control the rate of false alarms\n",
    "# that means that we reject the null hypothesis\n",
    "# even though the null hypothesis is true\n",
    "# or in less technical terms, we detect some significant effect\n",
    "# even though when there is no such effect\n",
    "# so one thing we can try to do is play around with script or run this multiple times\n",
    "# in order to generate a false positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, we are doing a two sample test\n",
    "# we will starrt by creating our data and our variables\n",
    "\n",
    "N0 = 100\n",
    "mu0 = 0.2\n",
    "sigma0 = 1\n",
    "x0 = np.random.randn(N0)*sigma0 + mu0\n",
    "\n",
    "N1 = 100\n",
    "mu1 = 0.5\n",
    "sigma1 = 1\n",
    "x1 = np.random.randn(N1)*sigma1 + mu1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.972669008209414, 0.002952226258536032)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ztest(x0,x1)\n",
    "# this is one example of failing to reject the null hypothesis\n",
    "# with a significance threshold of 5%\n",
    "# even though we know that the alternative is true\n",
    "\n",
    "# all three variables (mu,sigma,N) above contribute to this\n",
    "# we may not have enough data\n",
    "# or the means may not far enough apart\n",
    "# or the variances migh be too large\n",
    "# all of these things contribute to the z statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.972669008209414, 0.002952226258536002)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here comes our implementation\n",
    "# we transform our two-sample test into a one-sample test\n",
    "mu_hat0 = x0.mean()\n",
    "mu_hat1 = x1.mean()\n",
    "y_mu_hat = mu_hat0 - mu_hat1\n",
    "var_hat0 = x0.var(ddof=1)\n",
    "var_hat1 = x1.var(ddof=1)\n",
    "s_hat = np.sqrt(var_hat0/N0 + var_hat1/N1)\n",
    "z = y_mu_hat/s_hat # reference value is 0\n",
    "p_right = 1-norm.cdf(np.abs(z))\n",
    "p_left = norm.cdf(-np.abs(z))\n",
    "p = p_left + p_right\n",
    "z,p\n",
    "# note that if we had done mu_hat1 - mu_hat0\n",
    "# we would have gotten the same z value but with the opposite sign\n",
    "# this is fine, since it depends on which group do we consider 1 and which do we consider 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, we want to provide more intuition behind the idea of frequentist statistics\n",
    "# lets recall the meaning of the significance threshold\n",
    "# by using a mean of 5%, it means that 5% of the time we will reject the null hypothesis\n",
    "# even when the null hypothesis is really true\n",
    "# we call such an event a false alarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0491\n"
     ]
    }
   ],
   "source": [
    "num_tests = 10000 # number of runs\n",
    "results = np.zeros(num_tests)\n",
    "\n",
    "for i in range(num_tests):\n",
    "    # both x1 and x2 are 100 samples from the standard normal\n",
    "    x1 = np.random.randn(100)\n",
    "    x2 = np.random.randn(100)\n",
    "    z,p = ztest(x1,x2)\n",
    "    results[i] = (p<0.05) # 1 if we reject the null hypothesis\n",
    "print(results.mean())\n",
    "\n",
    "# its also worth mentioning that\n",
    "# we cant simply change the false alarm rate\n",
    "# without affecting our ability to detect a significant effect\n",
    "# suppose that we want our false alarm rate to be 1% instead of 5%\n",
    "# then we require a p value of less than 1% in order to detect a significant effect\n",
    "# however as we have learned, in order to obtain a smaller p value\n",
    "# this might require more data, a stronger effect or a smaller variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>code</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will apply our z-test to real data\n",
    "# we will be looking at the famous titanic dataset \n",
    "# (first time to hear about it though, tho :)\n",
    "# (the dataset not the titanic ;)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# seaborn will help us draw density plots\n",
    "# which are useful for visualising the distribution of our data\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can find the data on kaggle\n",
    "data = pd.read_csv('datasets/titanic/titanic_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n",
    "# we will be interested in the groups of passengers who survived and who did not survive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok, our goal in this test is to check \n",
    "# whether or not there is a difference in the fare each passenger paid between the two groups\n",
    "# that is to say, is the fare different among those who survived and those who did not survive\n",
    "\n",
    "# get the fare passengers who survived\n",
    "x1 = data[data['Survived']==1]['Fare'].dropna().to_numpy()\n",
    "\n",
    "# same for those who did not surviv\n",
    "x2 = data[data['Survived']==0]['Fare'].dropna().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# next we do a density plot for the two groups\n",
    "# basically this is like a histogram\n",
    "# but it yeilds a smoother curve\n",
    "sns.kdeplot(x1,label='Survived')\n",
    "sns.kdeplot(x2,label='Did Not Survive')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we see that, based on visual inspection only\n",
    "# there doesnot seem to be that much of a difference between the two groups\n",
    "# there does seem to be a highe peek for the 'Did Not Survive' group\n",
    "# but this does not imply that the means are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48.39540760233918, 22.117886885245902)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check the means\n",
    "x1.mean(),x2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so there does seem to be a big difference in the means of the two groups\n",
    "# which was not visible from the plot\n",
    "# since the range of values was so large\n",
    "# however, this doesnot imply the the difference is significant\n",
    "# since it still depends on the variance and the number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.939191660871055, 2.035031103573989e-15)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ztest(x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as we can see, we get a p value on the order e-15\n",
    "# this means that the result we observed is very significant\n",
    "# and we would reject the Null hypothesis\n",
    "# that the average fair of the two groups is the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is another example on click through rates\n",
    "# we compare between two ads A and B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so our rule \"All data is the same\"\n",
    "# allows us to use exactly the above code\n",
    "data = pd.read_csv('datasets/advertisement_clicks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>advertisement_id</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  advertisement_id  action\n",
       "0                B       1\n",
       "1                B       1\n",
       "2                A       0\n",
       "3                B       0\n",
       "4                A       1"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# action = 1, means use saw ad and clicked\n",
    "# action = 0, means user saw ad and did not click\n",
    "\n",
    "# ok, our goal in this test is to check \n",
    "# whether or not there is a statistical difference\n",
    "# between the click through rates (CTR) of ads A and B\n",
    "\n",
    "# get data for ad A\n",
    "x1 = data[data['advertisement_id']=='A']['action'].to_numpy()\n",
    "\n",
    "# same for add B\n",
    "x2 = data[data['advertisement_id']=='B']['action'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(x1,label='A')\n",
    "sns.kdeplot(x2,label='B')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.304, 0.372)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.mean(),x2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.2211732138019786, 0.0012766696301529544)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ztest(x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since p< 5%\n",
    "# we can reject the null hypothesis\n",
    "# that states that both means are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.2211732138019786, 0.0006383348150764772)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ztest(x1,x2,alternative='smaller')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# again, since p< 5%\n",
    "# we accept the null statement\n",
    "# that muA < muB\n",
    "# which we know is true\n",
    "# muA = 0.304 , muB = 0.372"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise brings up an important point, which comes up time and time again in machine learning courses\n",
    "\n",
    "<h3>All data is the same</h3>\n",
    "\n",
    "This is the idea that all data is the same \n",
    "\n",
    "In this exercise, we've expressed  that we are comparing the click events of two advertisements\n",
    "\n",
    "But we ask ourselves this important question\n",
    "\n",
    "Would this data change if this data were about something else?\n",
    "\n",
    "For example, what if we were comparing the page loading time of two Web pages?\n",
    "\n",
    "Or what if we were comparing the lifetime of two different kinds of CPU's in our data center?\n",
    "\n",
    "Or what if we were comparing the success rate of two sales scripts that the sales team at our company is using?\n",
    "\n",
    "Hopefully we can see that in all of these cases, our CSV file would be structured in the exact same way\n",
    "\n",
    "Furthermore, the code that we write to load in the data and run the test would also be exactly the same\n",
    "\n",
    "This is why we say that all data is the same\n",
    "\n",
    "We can use the same code and the same concepts on many different kinds of data\n",
    "\n",
    "Whether that data is from biology, finance or our business\n",
    "\n",
    "We don't have to worry about thinking \"this is too abstract because we're talking about the Bernoulli distribution\" or \"this won't work in the real world because these are only coin flips\"\n",
    "\n",
    "In fact, this is a very common beginner mistake\n",
    "\n",
    "Instead, it's more powerful when we realize that all data is the same\n",
    "\n",
    "It doesn't matter if we're presented with coin flips or advertisement clicks\n",
    "\n",
    "The same code would run on both of those data files in either case\n",
    "\n",
    "In fact, the data files themselves would look the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we are going to conclude and summarize what we learn in this notebook\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Notebook Summary</h3>\n",
    "\n",
    "This notebook was all about frequentist or classical A/B Testing and inference\n",
    "\n",
    "Now, the purpose of this notebook was not particularly to learn about classical statistics per say \n",
    "\n",
    "The actual purpose of this section is to help us contrast with the Bayesian method\n",
    "\n",
    "This is an approach we took in other notebooks as well\n",
    "\n",
    "We hope that by going through this notebook, we will understand the similarities and differences\n",
    "between the frequencies and Bayesian approaches\n",
    "\n",
    "However, there is good reason to go through this section, even if we don't particularly care about the frequentist method\n",
    "\n",
    "And this is that, these two approaches are not mutually exclusive\n",
    "\n",
    "For example, we may have a live system that uses the Bayesian approach, which we will soon learn about, but we can still do some offline analysis after collecting live data, using the frequentist approach\n",
    "\n",
    "In other words, overall, we can still end up using both approaches on the same data\n",
    "\n",
    "---\n",
    "\n",
    "OK, so what did we learn in this notebook\n",
    "\n",
    "This notebook expanded upon what we reviewed in the review notebook\n",
    "\n",
    "We remembered that maximum likelihood estimation does not tell the whole story\n",
    "\n",
    "If we want to compare two groups of things, we cannot just compare their maximum likelihood means \n",
    "\n",
    "This will always give us an answer one way or another\n",
    "\n",
    "Instead, we need to include other factors, like the variance in the data and the number of samples we've collected\n",
    "\n",
    "This led us to the concept of the confidence interval\n",
    "\n",
    "We learned how to quantify the confidence interval using the normal distribution\n",
    "\n",
    "This is justified by the fact that we can employ the central limit theorem \n",
    "\n",
    "In modern online systems, we typically collect enough data to make this justification\n",
    "\n",
    "However, do note that this is still just an approximation most of the time \n",
    "\n",
    "In the Bayesian notebook, we will learn how to calculate the distribution of the unknown parameter exactly\n",
    "\n",
    "---\n",
    "\n",
    "Next, we learned how to do hypothesis testing, in particular A/B testing\n",
    "\n",
    "This is perhaps one of the most practical techniques we can learn in data science\n",
    "\n",
    "In practice, this technique can be applied in many real world applications\n",
    "\n",
    "Anything from testing webpages to the reliability of mechanical parts in our rocket ship\n",
    "\n",
    "The particular A/B tests we use was called the $z$-test\n",
    "\n",
    "This assumes that the sample mean is normally distributed and that the variance of the data is known\n",
    "\n",
    "And again, we note that in modern systems, usually so much data is collected that invoking the central limit theorem is justified\n",
    "\n",
    "We learned about one sample test and two sample tests\n",
    "\n",
    "We also learned about one side of tests and two sided tests\n",
    "\n",
    "---\n",
    "\n",
    "Next, in order to bridge the gap between the frequentist and Bayesian methods, let's talk about some extensions and limitations of what we've done \n",
    "\n",
    "First, as with confidence intervals, we can stop making the assumption that we know the standard deviation\n",
    "\n",
    "In this case, the -test turns into the  t-test just as the z confidence interval turns into the t confidence interval\n",
    "\n",
    "Since the t test is included in ```scipy```, it takes essentially no more work to use either test\n",
    "\n",
    "However, as noted, we'll typically have so much data that they will both give us the same answer\n",
    "\n",
    "---\n",
    "\n",
    "In these notebooks, one of the primary kinds of data we are concerned with is clickthrough rates\n",
    "\n",
    "This is because many of us work in online systems, and what we are tracking a lot of the time is what users click on \n",
    "\n",
    "If we want it to be very exact, we would note that since the data is Bernoulli the sample mean is not normal\n",
    "\n",
    "If we wanted to avoid making such an assumption, we might want to look into the Chi Square test\n",
    "\n",
    "$$\\large \\chi^2_c = \\sum \\frac{(O_i-E_i)^2}{E_i}$$\n",
    "\n",
    "This might be of interest if for our data $N $is small\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Paired Samples</h3>\n",
    "\n",
    "Another situation we did not consider is when you have paired samples, which is not usually relevant in online systems with thousands or millions of users, and all we want to do is test the click rate of a link\n",
    "\n",
    "However, there might be situations where we want to do a paired test \n",
    "\n",
    "To describe the situation, imagine we want to test a drug, but instead of having two separate groups of people, we only have one group of people and we take measurements before and after treatment\n",
    "\n",
    "So we have two samples or two groups of data, but in each of these groups of data, one data point in one group corresponds to another data point in the second group (so now there is correlation in samples)\n",
    "\n",
    "<img src='extras/51.24.PNG' width='300'></img>\n",
    "\n",
    "In this situation, we cannot do a two sample test like we did earlier, we would instead have to do a pair test\n",
    "\n",
    "In fact, the tests we learned about earlier was called an independent sample test\n",
    "\n",
    "---\n",
    "\n",
    "<h3>More Than 2 Groups</h3>\n",
    "\n",
    "Here's another situation we did not consider \n",
    "\n",
    "Suppose that we have more than two groups of data that we want to test\n",
    "\n",
    "For example, instead of just testing one drug, we test drug A and then we test drug B and then we test drug C and so on\n",
    "\n",
    "In this case, our significance threshold is no longer trustworthy\n",
    "\n",
    "Why might this be?\n",
    "\n",
    "Well, remember that by using a significance threshold of $5 \\%$, we are giving ourselves a $5 \\%$ chance of a false detection\n",
    "\n",
    "By doing more tests, we are more likely to find a false positive\n",
    "\n",
    "\n",
    "In practice, researchers modify their significance thresholds to correct against this \n",
    "\n",
    "One simple but conservative solution is called the Bonferroni correction\n",
    "\n",
    "The way this works is we divide your original significance threshold by the number of tests we performed\n",
    "\n",
    "$$\\large \\alpha_{\\text{Bonferroni}} = \\frac{\\alpha}{\\# tests}$$\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Frequentist Concerns</h3>\n",
    "\n",
    "There are many other concerns and frequentist A/B testing that do not appear in the Bayesian setting\n",
    "\n",
    "Researchers are often concerned with the power of a test also known as the probability of detection\n",
    "\n",
    "This is influenced by the effect size and the number of samples and the variance in the data and also the significance threshold\n",
    "\n",
    "<img src='extras/51.25.PNG' width='400'></img>\n",
    "\n",
    "---\n",
    "\n",
    "Another concern is when researchers peek at their data to look for significance or not running a test to completion \n",
    "\n",
    "For reasons outside the scope of this notebook, this is a big NO NO in statistics\n",
    "\n",
    "Basically, our p-value can fluctuate as a function of the number of samples\n",
    "\n",
    "<img src='extras/51.26.PNG' width='400'></img>\n",
    "\n",
    "So imagine we are working as a data scientist and every day we look at our data and check the p-value, considering all the data we've collected so far \n",
    "\n",
    "After collecting one hundred samples, our p-value\n",
    "is not significant\n",
    "\n",
    "But after collecting 200 samples, our p-value is significant and we conclude that advertisement A\n",
    "is better than advertisement B \n",
    "\n",
    "However, we had originally intended to run our test for 1000 samples\n",
    "\n",
    "But what we want to do is, we want to notice that at two hundred samples, things are significant and then we to stop our test \n",
    "\n",
    "Under the rules of the frequentist paradigm, this would not be allowed\n",
    "\n",
    "---\n",
    "\n",
    "We can imagine why this might lead to an ethical dilemma\n",
    "\n",
    "Imagine we are running a drug tria and we discover that your drug works.\n",
    "\n",
    "We might feel obligated to help the patients in the control group by providing them with the drug so that they can feel better\n",
    "\n",
    "But the frequentist paradigm says, we are not allowed to do this if we want a valid answer to our hypothesis test\n",
    "\n",
    "---\n",
    "\n",
    "<h3>The Bayesian Approach</h3>\n",
    "\n",
    "So what is the takeaway?\n",
    "\n",
    "The takeaway is that none of these problems appear in the Bayesian paradigm\n",
    "\n",
    "Furthermore, we'll learn how the Bayesian paradigm leads to software that adapts to our users as we collect more data\n",
    "\n",
    "We don't have to worry about not being allowed to peek at our data and getting an invalid result because we ended our test early\n",
    "\n",
    "We don't have to worry about the power of our test or the number of samples we collect or the effect size\n",
    "\n",
    "We also don't have to worry about the very strict rules that statisticians have about their terminology\n",
    "\n",
    "For example, whether we accept or reject something or what the meaning of a confidence interval really is\n",
    "\n",
    "As you recall, the confidence interval is not the probability that the thing we are estimating lies between point A and point B\n",
    "\n",
    "However, in the Bayesian paradigm, we will get a distribution on our estimate and you can answer the question, what is this probability?\n",
    "\n",
    "And we can all agree that this idea of rejecting or failing to reject is kind of a strange concept\n",
    "\n",
    "A much more simple question would be what is the probability that advertisement A is better than\n",
    "advertisement B or what is the probability that the drug works better than the standard treatment \n",
    "\n",
    "Frequentist methods cannot answer these questions\n",
    "\n",
    "As we'll see, the Bayesian method leads to a much more natural interpretation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
