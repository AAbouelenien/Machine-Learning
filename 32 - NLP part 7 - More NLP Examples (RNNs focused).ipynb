{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we begin by reviewing how to deal with text data in NLP\n",
    "\n",
    "this directly ties into the previous notebook which was on using RNNs for modelling sequence data and serves as a good review (in fact we will have multiple reviews throughout this notebook , which are rather thorough and easy)\n",
    "\n",
    "Text is also sequence data , but there is a major difference between text sequences and the continuous valued sequences we were dealing with in the previous section\n",
    "\n",
    "That difference is , text is made of words and words are categorical objects , in other words they are not continuous\n",
    "\n",
    "continuous : [1,0.5,-2,3,...]\n",
    "\n",
    "categorical : ['the','quick','brown','fox','jumps','over','the','lazy','dog']\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Dealing with Text</h4>\n",
    "\n",
    "suppose we are given a sequence of words : ['the','quick','brown','fox','jumps','over','the','lazy','dog']\n",
    "\n",
    "so $x_1$ = 'the' , $x_2$ = 'quick' , ...\n",
    "\n",
    "but here is the problem , we know that in order to calculate the output of an RNN unit , we have to multiply each x by the input to hidden weight $W_{xh}$ , recall the formula for RNN :\n",
    "\n",
    "$$h_t = \\sigma(W_{xh}^Tx_t + W_{hh}h_{t-1}+b_h)$$\n",
    "\n",
    "we can see that if x is a category then that is not possible\n",
    "\n",
    "---\n",
    "\n",
    "<h4>One-Hot Encoding</h4>\n",
    "\n",
    "we might be tempted to think that , since we have categories , all we need to do is use one-hot encoding\n",
    "\n",
    "so what we would do is , create an array which has length equal to the size of the vocabulary , in other words the number of words in the English language (typically we denote that with the capital letter V)\n",
    "\n",
    "so here is how we are going to one-hot encode a word :\n",
    "\n",
    "<ol>\n",
    "    <li>create a vector of size V containing all 0s = [0,0,0,...,0]</li>\n",
    "    <li>Then we are goint to create a mapping , where we have for each word a corresponding integer starting from 1 </li>\n",
    "    <li>then once we have a map for each word to an integer , we simply set that corresponding integer to 1 for ex: <ul><li>a $\\rightarrow$ [1,0,0,...,0] (index 1)</li><li>aa $\\rightarrow$ [0,1,0,...,0] (index 2)</li><li>....</li><li>zoo $\\rightarrow$ [0,0,0...,1] (index 1 million)</li></ul></li>\n",
    "    <li>Eventually each of our vectors is jsut a bunch of zeros with only a single one at a unique position</li>\n",
    "</ol>\n",
    "\n",
    "so what happens after we do this ?\n",
    "\n",
    "well now we can go back to our usual scenario , it we have a sequence of T words , and each of them becomes a vector of size V , then we have a TxV matrix which represents our sequence\n",
    "\n",
    "This is the same shape as a generic TxD matrix which can then be passed to our RNN as normal\n",
    "\n",
    "so lets do a very simple example :\n",
    "\n",
    "suppose we have the sentence 'I like cats'\n",
    "\n",
    "this is a sequence of length 3 (T=3) , because this sentence has 3 words\n",
    "\n",
    "this might turn into the sequence of vectors [[0,0,0,1],[0,1,0,0],[1,0,0,0]]\n",
    "\n",
    "for this simple example , we have assumed that our vocabulary contained only 4 words , which of course is much smaller than a real English language dataset\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Problem</h4>\n",
    "\n",
    "But there are some problems with this approach\n",
    "\n",
    "some English datasets have about 1 million possible tokens/words \n",
    "\n",
    "that would lead to an extremely large one hot encoded feature vector which means that our weight matrix would also be very large\n",
    "\n",
    "so we have a TxV matrix but V (or equivalently) is a very big number\n",
    "\n",
    "Not only is the input large , but the input-hidden weight matrix will also be large !\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Another problem</h4>\n",
    "\n",
    "recall that we would like our input features to have some structure\n",
    "\n",
    "if we also recall , one of the first earliest rules we encountered was 'Machine learning is nothing but a geometry problem'\n",
    "\n",
    "This rule relies on the fact that there is some geometrical structure in the data\n",
    "\n",
    "data vectors from the same class are probably close to each other\n",
    "\n",
    "but what do one-hot encoded features look like ?\n",
    "\n",
    "well if we take any two one-hot encoded vectors , ex , [1,0,0] vs [0,1,0] , and we calculate the Euclidean distance , we will always get $\\sqrt{1^2+1^2} = \\sqrt{2}$\n",
    "\n",
    "it doesnot matter which two words we select because they are all one-hot encoded\n",
    "\n",
    "so for ex , the distance between 'cat' and 'feline' is $\\sqrt{2}$\n",
    "\n",
    "and the distance between 'cat' and 'airplane' is also $\\sqrt{2}$\n",
    "\n",
    "In other words , this data has no useful geometrical structure\n",
    "\n",
    "---\n",
    "\n",
    "<h4>A better solution : Embeddings</h4>\n",
    "\n",
    "so what can we do instead ?\n",
    "\n",
    "well it would be nice if for each word , we could map them to a D dimensional vector\n",
    "\n",
    "luckily we have just the tool for this , it is called an embedding layer\n",
    "\n",
    "now we may be wondering , how can we make these vectors have a useful structure ? (we will get back to this later)\n",
    "\n",
    "now we want to revise a coding trick\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Coding Trick</h4>\n",
    "\n",
    "consider what would happen if we multiply a one-hot encoded vector with a weight matrix\n",
    "\n",
    "<img src='extras/32.1.PNG' width='400'><img>\n",
    "\n",
    "now consider the one-hot encoded vector [0,1,0] multiplied by the same weight matrix\n",
    "\n",
    "<img src='extras/32.2.PNG' width='400'><img>\n",
    "\n",
    "now again with [0,0,1]\n",
    "\n",
    "<img src='extras/32.3.PNG' width='400'><img>\n",
    "\n",
    "---\n",
    "\n",
    "<h4>What's the pattern ?</h4>\n",
    "\n",
    "if the index in the one hot encoded vector which was set to 1 , was 1 then we get the first row of the weight matrix\n",
    "\n",
    "<img src='extras/32.4.PNG' width='400'><img>\n",
    "\n",
    "if the index is set to 2 , then we get the second row of the weight matrix\n",
    "\n",
    "and if the index is set to 3 , then we get the third row of the weight matrix\n",
    "\n",
    "in other words , if we one-hot encode the integer k and we multiply it by the weight matrix , all its really doing is selecting the kth row of the weight matrix\n",
    "\n",
    "```one_hot(k)*W == W[k]```\n",
    "\n",
    "---\n",
    "\n",
    "<h4>why is it more effecient ?</h4>\n",
    "\n",
    "so here is a shortcut\n",
    "\n",
    "old way takes 2 steps :\n",
    "\n",
    "<ul>\n",
    "    <li>create a vector of size V containing all zeros . set the kth entry to 1</li>\n",
    "    <li>multiply the one hot vector by the weight matrix</li>\n",
    "</ul>\n",
    "\n",
    "New way takes 1 step:\n",
    "\n",
    "<ul>\n",
    "    <li>index the weight matrix W[k]</li>\n",
    "</ul>\n",
    "\n",
    "this is obviously more effecient than creating a one-hot vector then doing matrix multiplication\n",
    "\n",
    "Think of it this way :\n",
    "\n",
    "Indexing an array is O(1) - constant time\n",
    "\n",
    "But how long does it take to create a one-hot vector and then do matrix multiplication ?\n",
    "\n",
    "if our vector is of size V and the weight matrix is of size VxD then this is $O(VD)$\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Tensorflow Embedding</h4>\n",
    "\n",
    "so this is exactly what the embedding layer in tensorflow does\n",
    "\n",
    "instead of just doing all the work ourselves to create one_hot encoded vectors , the only step we need to do is map our dataset with sequences of words into a dataset of sequences of word indicies\n",
    "\n",
    "now that we have only integers , we can use an embedding layer to map each word intiger to a corresponding word vector\n",
    "\n",
    "[50,25,3] $\\rightarrow$ [[0.3,-0.5],[1.2,-0.7],[-2.1,0.9]]\n",
    "\n",
    "so our T-length array becomes a TxD matrix\n",
    "\n",
    "from there on out , our sequence becomes a TxD matrix at which point we can use an RNN as we normally would\n",
    "\n",
    "---\n",
    "\n",
    "conceptually we can think of the process as this :\n",
    "\n",
    "first we have some sentence , a sequence of words , lets say for simplicity sake ['I','like','cats']\n",
    "\n",
    "then this sequence of words becomes a sequence of integers , obviously it doesnot matter which integer do we assign to each word as long as they are unique\n",
    "\n",
    "this is just like when we are doing classification , it doesnot matter if we set dog to 1 and cat to 0 or vice versa , they are just arbitary assignements\n",
    "\n",
    "finally we can use these integers to index an embedding matrix which will convert each integer into a word vector\n",
    "\n",
    "[50,25,3] $\\rightarrow$ [[0.3,-0.5],[1.2,-0.7],[-2.1,0.9]]\n",
    "\n",
    "so in the end what we have done is 2 steps :\n",
    "\n",
    "<ol>\n",
    "    <li>converted words to integers</li>\n",
    "    <li>mapped those integers to vectors</li>\n",
    "</ol>\n",
    "\n",
    "---\n",
    "\n",
    "<h4>How are the weights found ? </h4>\n",
    "\n",
    "we know intuitively that similar words should be closer together than dissimilar words\n",
    "\n",
    "in other words , these feature vectors should exist somewhere meaningful relative to each other\n",
    "\n",
    "for ex: , king should be close to queen , car should be close to automobile\n",
    "\n",
    "<img src='extras/32.5.PNG' width='200'></img>\n",
    "\n",
    "but queen should not be close to car and king should not be close to automobile\n",
    "\n",
    "so how can we make sure that that is the case ?\n",
    "\n",
    "the answer is simple , these are just weights in a neural network so they all get trained automatically , there is nothing fancy we need to do\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Pre-trained vectors</h4>\n",
    "\n",
    "now there is one caveat to that , that is what people often do is use pre-trained word vectors\n",
    "\n",
    "how this works is , when they create an embedding layer , they set the weights to a set of pretrained vectors that were obtained throgh other methods\n",
    "\n",
    "then they freeze that layer , so that when we call ```model.fit()``` those weights are never changed\n",
    "\n",
    "typically these word vectors are found throgh algorithms such as word2vec and GloVe\n",
    "\n",
    "since we already discussed those , now we will train embeddings like any other layer , by calling ```model.fit()``` and letting gradient descent do its magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we are going to do some code preperation\n",
    "\n",
    "we discussed embeddings , and how that would help us convert a sequence of words into a TxD matrix of numbers , which we could then pass into an RNN\n",
    "\n",
    "now we want to focus on the details of how this is done\n",
    "\n",
    "---\n",
    "\n",
    "<h4>words to integers</h4>\n",
    "\n",
    "we know that the first thing we have to do when converting a sequence of words into a sequence of vectors is that we need to first convert that sequence of words into a sequence of integers\n",
    "\n",
    "each word needs to have an integer representation because that tells us which row of the word embedding matrix to index\n",
    "\n",
    "so the question is how do we do this ?\n",
    "\n",
    "lets look at a psuedocode :\n",
    "\n",
    "```python\n",
    "dataset = long sequence of words\n",
    "\n",
    "current_idx = 1\n",
    "\n",
    "word2idx = {}\n",
    "\n",
    "for word in dataset:\n",
    "    if word not in word2idx:\n",
    "        word2idx[word] = current_idx\n",
    "        current_idx += 1\n",
    "```\n",
    "\n",
    "so we loop through each word in our dataset , and assign integer indicies as we encounter each new word\n",
    "\n",
    "what we really want to do is find a mapping or a dictionary that tells us , for each word , what is the corresponding integer value\n",
    "\n",
    "---\n",
    "\n",
    "we might look at this and wonder , if it is in a computer , why do we start at index 1 and not index 0 ?\n",
    "\n",
    "this is pretty important for tensorflow in particular\n",
    "\n",
    "if we recall , we mentioned before that tensorflow uses constant length time series\n",
    "\n",
    "so we will always have an NxTxD array containing our data\n",
    "\n",
    "but , T represents the maximum sequence (sentence) length , so any sentence shorter than that will need to include padding\n",
    "\n",
    "therefore we need a special number to represent padding , and that number is 0\n",
    "\n",
    "therefore we do not use 0 for word indicies because its already being used for padding (but more on padding later)\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Words to Integers in Tensorflow</h4>\n",
    "\n",
    "the previous psuedocode we looked at was rather for intuition since tensorflow/keras already have some built in functions to help us do this work\n",
    "\n",
    "the first thing we have to realsie is that text itself is not formatted as a sequence of words\n",
    "\n",
    "istead text , when we load it from a file , is just string\n",
    "\n",
    "we have \"The quick brown fox jumps over the lazy dog\"\n",
    "\n",
    "NOT : [\"The\",\"quick\",\"brown\",\"fox\",\"jumps\",\"over\",\"the\",\"lazy\",\"dog\"]\n",
    "\n",
    "we will have one single string containing possibly multiple sentences and each sentence will of course contain multiple words\n",
    "\n",
    "so it should be clear that , the very first thing we need to do , is seperate each word from the other words\n",
    "\n",
    "wwhat we mean by that is , given a single string cintaining multiple words , what we would really like to have is just a <strong>list of strings</strong> where each string contains only a single <strong>word</strong>\n",
    "\n",
    "this is a process known as <strong>tokenisation</strong> because we are going to create a list of tokens\n",
    "\n",
    "so just to add a little more detial to this process , we have discovered that we actually need to do two things here\n",
    "\n",
    "first we need to convert a string , which may contain multiple words , into a list of individual words\n",
    "\n",
    "second this allows us to then loop through each word and then assign word indicies\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Tensorflow Tokeniser</h4>\n",
    "\n",
    "luckily the tensorflow tokeniser does all this work for us\n",
    "\n",
    "for example suppose we are given three sentences in a list :\n",
    "\n",
    "```python\n",
    "\n",
    "sentences = [\n",
    "    \"I like eggs and burger\",\n",
    "    \"I love chocolate and bunnies\",\n",
    "    \"I hate onions\"\n",
    "]\n",
    "```\n",
    "\n",
    "what the tokeniser will do , is return a corresponding list of sequences of integers , where each sentence has been converted into a list of integers\n",
    "\n",
    "```python\n",
    "sequences = [\n",
    "    [1,2,3,4,5],\n",
    "    [1,6,7,4,8],\n",
    "    [1,9,10]\n",
    "]\n",
    "```\n",
    "\n",
    "each integer of course corresponds to a word\n",
    "\n",
    "so here is what it looks like in tensorflow code\n",
    "\n",
    "```python\n",
    "MAX_VOCAB_SIZE = 20000\n",
    "tokeniser = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "tokeniser.fit_on_texts(sentences)\n",
    "sequences = tokeniser.texts_to_sequences(sentences)\n",
    "```\n",
    "\n",
    "now we notice one more important thing which is that the tokeniser accepts an argument called ```num_words```\n",
    "\n",
    "this allows us to specify how many words we want our tokeniser to actually keep\n",
    "\n",
    "we can imagine that if we have a huge Google-sized dataset , we may have 1 million + tokens , most of which are extremely rare and probably useless for classification or whatever else we are trying to do , also consider misspellings\n",
    "\n",
    "thus num words allows us to limit the total number of words in our vocabulary and everything else is just assigned the same token\n",
    "\n",
    "so we can think of that token as representing $<RARE>$ or $<UKNOWN>$ token\n",
    "\n",
    "---\n",
    "\n",
    "<h4>We still Need Padding</h4>\n",
    "\n",
    "the second preprocessing step we have to consider is this :\n",
    "\n",
    "when we convert our sentences into sequence of integers through the tokeniser , those sentences all have different lengths\n",
    "\n",
    "```python\n",
    "\n",
    "sentences = [\n",
    "    \"I like eggs and burger\",\n",
    "    \"I love chocolate and bunnies\",\n",
    "    \"I hate onions\"\n",
    "]\n",
    "```\n",
    "\n",
    "```python\n",
    "sequences = [\n",
    "    [1,2,3,4,5],\n",
    "    [1,6,7,4,8],\n",
    "    [1,9,10]\n",
    "]\n",
    "```\n",
    "\n",
    "this is a problem for us because we know that in tensorflow RNNs do not accept sequences of different lengths\n",
    "\n",
    "as we discussed previously , the solution to this is <strong>padding</strong>\n",
    "\n",
    "each sentence in the dataset will be padded so that shorter sentences will all have the same length as the longest sentence\n",
    "\n",
    "so how do we do this in tensorflow ?\n",
    "\n",
    "---\n",
    "\n",
    "<h4>How would we implement padding ?</h4>\n",
    "\n",
    "first lets thing about how we would implement this ourselves\n",
    "\n",
    "```python\n",
    "max_size = max(len(seq) for seq in sequences)\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    sequences[i] = sequences[i] + [0]*(max_size - len(sequences[i]))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "so we go from :\n",
    "\n",
    "```python\n",
    "sequences = [\n",
    "    [1,2,3,4,5],\n",
    "    [1,6,7,4,8],\n",
    "    [1,9,10]\n",
    "]\n",
    "```\n",
    "\n",
    "to \n",
    "\n",
    "```python\n",
    "sequences = [\n",
    "    [1,2,3,4,5],\n",
    "    [1,6,7,4,8],\n",
    "    [1,9,10,0,0]\n",
    "]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Padding in Tensorflow</h4>\n",
    "\n",
    "luckily (too much luck today) , while we could also do this by ourselves manually , we dont have to because there is a tensorflow function to do this for us\n",
    "\n",
    "```python\n",
    "data = pad_sequences(sequences,maxlen=MAXLEN)\n",
    "```\n",
    "so all we need to do is pass in our jagged array of sequences into ```pad_sequences()``` and we get back a nice NxT matrix padded where 0s where necessary\n",
    "\n",
    "there is some arguments into this function that are important to be aware of\n",
    "\n",
    "first there is the ```maxlen``` argument , this controls tbe size of $T$\n",
    "\n",
    "we mentioned earlier that this would be the size of the maximum length sequence , which is True of we use the default setting where ```maxlen=None```\n",
    "\n",
    "but there is always the option to set it to a different number\n",
    "\n",
    "for example , if our dataset contains some really long sentences , but we know that those sentences contain mostly data that can be ignored then we may want to simply truncate those sentences , in other words make them shorter by cutting off the beginning/ending\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Truncating</h4>\n",
    "\n",
    "but if we are going to truncate a sentence , how do we know if it is goint to cut off the beginning or the end\n",
    "\n",
    "<ul>\n",
    "    <li>[<del>1,2</del>,3,4,5]</li>\n",
    "    <li>[1,2,3,<del>4,5</del>]</li>\n",
    "</ul>\n",
    "\n",
    "well we can control whether to cut-off the beginning or the end by setting the argument ```truncating``` to ```'pre'``` or ```'post'```\n",
    "\n",
    "```python\n",
    "data = pad_sequences(\n",
    "    sequences,\n",
    "    maxlen = MAXLEN , \n",
    "    truncating='pre'\n",
    ")\n",
    "```\n",
    "\n",
    "on the other hand , there is really no reason to set ```maxlen``` to be bigger than our MAXLEN sequences since that would be just a waste of space\n",
    "\n",
    "so in other words every sentence will end up being padded with useless zeros\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Padding Options</h4>\n",
    "\n",
    "the next important argument is the ```padding``` argument which can also be ```'pre'``` or ```'post'``` , this lets us control whether to pad the shorter sentences with 0s at the beginning of the sequence or at the end of the sequence\n",
    "\n",
    "```python\n",
    "data = pad_sequences(\n",
    "    sequences,\n",
    "    maxlen = MAXLEN , \n",
    "    padding='pre' # or 'post'\n",
    ")\n",
    "```\n",
    "\n",
    "there are some instances where we would want the padding at the beginning and some instances where we would want the padding at the end\n",
    "\n",
    "[0,0,1,2,3] vs [1,2,3,0,0]\n",
    " \n",
    "for example , suppose we are building a spam detection classifier , that reads in an entire sequences and decides at the final time step whether or not the email is spam\n",
    "\n",
    "well in that case , we would want to have padding at the beginning , why ?\n",
    "\n",
    "because remember , RNNs have trouble with long distance memory , so we wouldnot want to end our sequence with a bunch of zeros and risk the RNN forgetting what it saw earlier\n",
    "\n",
    "---\n",
    "\n",
    "on the other hand , consider a task such as Neural Machine Translation\n",
    "\n",
    "suppose that the target language has a sentence which is longer than the input language\n",
    "\n",
    "what would happen if we added 0s at the beginning ?\n",
    "\n",
    "<img src='extras/32.6.PNG' width='500'></img>\n",
    "\n",
    "we can see here that this is no good , how can we predict the first word in the target language if all the RNN has seen so far is a bunch of zeros ?\n",
    "\n",
    "we cannot , and thus , in this case , post padding will be better\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Recap So Far</h4>\n",
    "\n",
    "Data is list of strings (usually called a 'document')\n",
    "\n",
    "Each string is a sentence or possibly multiple sentences\n",
    "\n",
    "either way each string will contain multiple words bunched up together in a single string\n",
    "\n",
    "second we use the tokeniser to convert those strings into a list of sequences of integers\n",
    "\n",
    "those integers each correspond to a different word which of course can be used later to index a word embedding matrix\n",
    "\n",
    "third we pad those sequences so that they all come out the same length and thus we end up with a 2D array of size NxT\n",
    "\n",
    "N = # samples\n",
    "\n",
    "T = sequence length\n",
    "\n",
    "each entry of this array is a word index , so the entry at X[n,t] will tell us the word that appears in the nth document at time step t\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Then what ?</h4>\n",
    "\n",
    "the next step is to consider what do we do with this NxT matrix ?\n",
    "\n",
    "as we discussed earlier we pass this through an embedding layer , again this is all about keeping in mind the shapes\n",
    "\n",
    "remember that and embedding layer is going to return a D-size word vector given a word index\n",
    "\n",
    "so when we pass it an array of size NxT , what do we get ?\n",
    "\n",
    "we get an NxTxD array , hmmm and what is this ?\n",
    "\n",
    "This should look familiar , this is exactly what we need to pass this through the rest of the RNN\n",
    "\n",
    "```python\n",
    "i = Input(shape=(T,))\n",
    "x = Embedding(V,D)(i) # x is now an NxTxD\n",
    "# the we pass this to the rest of our RNN\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "<h4>A full RNN for text classification</h4>\n",
    "\n",
    "so here is the whole neural network \n",
    "\n",
    "```python\n",
    "i = Input(shape=(T,))\n",
    "x = Embedding(V,D)(i) # x is now NxTxD\n",
    "x = LSTM(M)(x)\n",
    "x = Dense(K,activation='softmax')(x)\n",
    "``` \n",
    "\n",
    "optionally , as we know , we can set ```return_sequences = True``` for the LSTM and use ```GLOBALMAXPOOLING1D```\n",
    "\n",
    "```python\n",
    "i = Input(shape=(T,))\n",
    "x = Embedding(V,D)(i) # x is now NxTxD\n",
    "x = LSTM(M)(x,return_sequences=True)(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(K,activation='softmax')(x)\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>code</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense,Input,GlobalMaxPooling1D,Embedding,LSTM\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('datasets/spam.csv',encoding='ISO-8859-1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['v2'].to_numpy()\n",
    "Y = data['v1'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets one hot encode Y , spam 0 , ham 1\n",
    "spam = Y == 'spam'\n",
    "ham = np.logical_not(spam)\n",
    "Y[spam] = 0\n",
    "Y[ham] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Xtest,Ytrain,Ytest = train_test_split(X,Y,test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next lets begin processing X\n",
    "# first we tokenise\n",
    "MAX_VOCAB_SIZE = 20000\n",
    "tokeniser = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "tokeniser.fit_on_texts(Xtrain)\n",
    "Xtrain = tokeniser.texts_to_sequences(Xtrain)\n",
    "Xtest = tokeniser.texts_to_sequences(Xtest)\n",
    "\n",
    "# also get word2idx\n",
    "word2idx = tokeniser.word_index\n",
    "V = len(word2idx)  # vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next is padding\n",
    "Xtrain = pad_sequences(Xtrain)\n",
    "# get sequence length , the default is the max sequence length\n",
    "T = Xtrain.shape[1]\n",
    "# apply same padding on Xtest\n",
    "Xtest = pad_sequences(Xtest,maxlen=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 20\n",
    "M = 15\n",
    "\n",
    "i = Input(shape=(T,))\n",
    "# our vocabulary is of size V\n",
    "# we have an extra token for padding\n",
    "# so thats V+1\n",
    "x = Embedding(V+1,D)(i)\n",
    "x = LSTM(M,return_sequences=True)(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model = Model(i,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = 'binary_crossentropy',\n",
    "    optimizer = 'adam',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain = Ytrain.astype('uint8')\n",
    "Ytest = Ytest.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "117/117 [==============================] - 9s 59ms/step - loss: 0.5357 - accuracy: 0.8780 - val_loss: 0.4018 - val_accuracy: 0.8608\n",
      "Epoch 2/10\n",
      "117/117 [==============================] - 6s 54ms/step - loss: 0.3780 - accuracy: 0.8724 - val_loss: 0.3881 - val_accuracy: 0.8608\n",
      "Epoch 3/10\n",
      "117/117 [==============================] - 6s 54ms/step - loss: 0.3777 - accuracy: 0.8603 - val_loss: 0.2841 - val_accuracy: 0.8608\n",
      "Epoch 4/10\n",
      "117/117 [==============================] - 6s 54ms/step - loss: 0.2115 - accuracy: 0.9063 - val_loss: 0.1088 - val_accuracy: 0.9782\n",
      "Epoch 5/10\n",
      "117/117 [==============================] - 6s 53ms/step - loss: 0.0706 - accuracy: 0.9908 - val_loss: 0.0708 - val_accuracy: 0.9826\n",
      "Epoch 6/10\n",
      "117/117 [==============================] - 6s 54ms/step - loss: 0.0368 - accuracy: 0.9943 - val_loss: 0.0588 - val_accuracy: 0.9859\n",
      "Epoch 7/10\n",
      "117/117 [==============================] - 6s 55ms/step - loss: 0.0219 - accuracy: 0.9952 - val_loss: 0.0634 - val_accuracy: 0.9842\n",
      "Epoch 8/10\n",
      "117/117 [==============================] - 6s 55ms/step - loss: 0.0155 - accuracy: 0.9977 - val_loss: 0.0597 - val_accuracy: 0.9831\n",
      "Epoch 9/10\n",
      "117/117 [==============================] - 6s 55ms/step - loss: 0.0088 - accuracy: 0.9996 - val_loss: 0.0594 - val_accuracy: 0.9837\n",
      "Epoch 10/10\n",
      "117/117 [==============================] - 6s 54ms/step - loss: 0.0089 - accuracy: 0.9989 - val_loss: 0.0613 - val_accuracy: 0.9821\n"
     ]
    }
   ],
   "source": [
    "r = model.fit(Xtrain,Ytrain,epochs=10,validation_data=(Xtest,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(r.history['loss'],label='loss')\n",
    "plt.plot(r.history['val_loss'],label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de3Rc5Xnv8e+j0c26WbIlX2Us2zG+YMAOxhBIYogTgkmJG0J7TG6rtIlLGwjh9JyGkK5Fz0rTcHJIG9JQXDehlISGckhYpTkOJGCDm4SbjQTGtgRCNrYs25JvkiXrOnrOH3ssj6SRNbZHGmnm91lr1sy+zTwztn6z53333q+5OyIikroykl2AiIiMLAW9iEiKU9CLiKQ4Bb2ISIpT0IuIpLjMZBcQS2lpqVdUVCS7DBGRcWPbtm2H3b0s1rIxGfQVFRVs3bo12WWIiIwbZvbeUMvUdCMikuIU9CIiKU5BLyKS4sZkG30s3d3d1NfX09HRkexSxqTc3FzKy8vJyspKdikiMsYMG/Rm9jDwe0Cjuy+JsdyAB4AbgJPAH7n765Fl10eWhYAfuvt951pofX09hYWFVFRUELyknOLuHDlyhPr6eubMmZPsckRkjImn6eYR4PozLF8NzI/c1gEPAZhZCHgwsnwxcIuZLT7XQjs6Opg8ebJCPgYzY/Lkyfq1IyIxDRv07r4FOHqGVdYAj3rgZaDYzKYDK4Bad69z9y7g8ci650whPzR9NiIylES00c8E9kVN10fmxZp/xVBPYmbrCH4RcMEFFySgLBFJZ93hXk52hmnr6uFkV5iTA++jlnV2h5NdLgB5OZnctnJewp83EUEfa1fSzzA/JnffAGwAWL58uS6SL5IG3J2ucC/tXWHausK0d/XQ1hnuC+Toee3dYdo6ewYsC+b1XxYs7w6fXYyMhR/FpQU5Yzbo64FZUdPlQAOQPcR8EUkB3eFeWjt6ONHRw4nObk509ATTnd20dvTQ0tFDa2cPJzq6o9YL7luj1u/pjT+QQxlGXnaI/OxM8nJC5GWHyMvOZFJ+NrNK8iLTIfJyMsnLCu7zs0NMOLVN9uB5E7JD5GRmpHTzZyKC/mngdjN7nKBpptndD5hZEzDfzOYA+4G1wGcS8HpJ8/u///vs27ePjo4O7rzzTtatW8czzzzDPffcQzgcprS0lOeff57W1lbuuOMOtm7diplx77338ulPfzrZ5YsAwV50a1/gBkF8oqP/9KCgPrV+3/xuOrp7h32tzAyjMDeTgtxMCnOyKMjNZGZxLgU5BRTmBtP5kbCOFcID52WHUjuQR0o8h1f+FLgGKDWzeuBeIAvA3dcDGwkOrawlOLzy1siyHjO7HXiW4PDKh919RyKK/l//uYOdDS2JeKo+i2cUce+NF51xnYcffphJkybR3t7O5Zdfzpo1a/jSl77Eli1bmDNnDkePBn3W3/zmN5k4cSLbt28H4NixYwmtVQSgozvM8ZPdNLd3c/xkF83t3YNufcvbu2mJmh8eZi/aDAqyM0+HdG4WJXnZXDApj8LIdEFOZHlOMH36cbBNUW5Wyu8pjxfDBr273zLMcge+PMSyjQRfBCnh+9//Pk899RQA+/btY8OGDXz4wx/uO3Z90qRJADz33HM8/vjjfduVlJSMfrEyLnSHe/sFckt7N8fbu2g+2U1ze0/wuL07Mn06tJvbu+nqGXqP2gyKcrMozsti4oTgNqtkQt/jiROyKJqQNSioT03nZ2eSkaGAThXj5szYaMPteY+EF154geeee46XXnqJvLw8rrnmGi699FJqamoGrevu2otJY509YRpbOmk80cGhlk4OtQT3jS0dHDrRwZHWrr6967auMx/tUZCT2S+c55UV9IV30YT+QV48ITt4nJdFYY6CWk4bl0GfDM3NzZSUlJCXl0d1dTUvv/wynZ2dvPjii+zevbuv6WbSpElcd911/OAHP+B73/seEDTdaK9+/OsJ93K4tSsS3B0cOhEJ75YODracfnzsZPegbbNCxpTCXKYU5VBeksfEGZFwzjt9X9QX2KeDPCuky1HJ+VPQx+n6669n/fr1XHLJJSxYsIArr7ySsrIyNmzYwE033URvby9Tpkzh17/+NX/1V3/Fl7/8ZZYsWUIoFOLee+/lpptuSvZbkCH09jpHT0YFeIy98EMtnRxu7cQHNG1nGJQV5jC1KJfykjwum13C1KJcphblMKUol2lFuUwtyqV4Qpb2sCVpFPRxysnJ4Ze//GXMZatXr+43XVBQwL/+67+ORlkSpyOtnWyqbqTxRGe/QG9s6aDxRGfMQ/wm52czJRLaS2ZM7Hs8tTC3L8wnF+QQUoDLGKegl5QX7nU++8NXqD54AoCJE7KCwC7KZV5Zad/jU3vhU4tyKSvIITtTzSaSGhT0kvJ+9no91QdP8J2bL+GTl84gNyuU7JJERpWCXlJae1eY7/6qhqWzivmDy8p1NJSkJf02lZT28G93c6ilk3tuWKSQl7SloJeUdbi1k4deeJePLZ7KijmTkl2OSNIo6CVlff/5d2jvDnP36oXJLkUkqRT0kpLqmlr5t1f2csuKWcwrK0h2OSJJpaAfIQUFCpdk+s4zNeRkZnDnqguTXYpI0inoJeVse+8oz+w4yJ+unEdZYU6yyxFJuvF5eOUv74aD2xP7nNMuhtX3Dbn4a1/7GrNnz+bP//zPAfjrv/5rzIwtW7Zw7Ngxuru7+Zu/+RvWrBl+WNzW1lbWrFkTc7tHH32U+++/HzPjkksu4cc//jGHDh3itttuo66uDoCHHnqIq666KgFvOvW4O9/6f7uYUpjDFz80J9nlBMLdcHwvHN0Nx3aD98KEkuCWWxz1eCKExuefpIxt+l8Vp7Vr1/LVr361L+ifeOIJnnnmGe666y6Kioo4fPgwV155JZ/85CeHPYwvNzeXp556atB2O3fu5Fvf+ha//e1vKS0t7bu+/Ve+8hVWrlzJU089RTgcprW1dcTf73j17I6DvL73OPfddDF52aP437ur7XSQ993XBY+b68HjHJM0pwgmFPf/AphQHOOLYcC87PyxMRaejEnjM+jPsOc9UpYtW0ZjYyMNDQ00NTVRUlLC9OnTueuuu9iyZQsZGRns37+fQ4cOMW3atDM+l7tzzz33DNpu06ZN3HzzzZSWlgKnr2+/adMmHn30UQBCoRATJ04c2Tc7TnWHe/nfz9Qwf0oBN19Wntgnd4eTR2MH+bHd0Hqo//oTSqBkDpRfDpf8YfB40pzgPpQF7ceg/Xjk/hh0RD0+Nb/jODTuPD2vd/BVMftkZJ3hS2GI+TkFwRdEVj5kqBU3lY3PoE+Sm2++mSeffJKDBw+ydu1aHnvsMZqamti2bRtZWVlUVFTQ0dEx7PMMtZ2uY39+fvrqXnYfbuPhP1pO5rlc3re3F040xA7yo3ugs7n/+oUzYNJcmP+xSJDPPR3mE4rP/Fr5pWdXm3vwq6Hfl8IZvihaGiJfEsehM47R2LLyglt2PmRHvgCy86Ie50eWR033uxUM3j5rwuj9ynCH3jCEuyK37sGPe7tjzw93BdtPKIbcqC/F3ImQkRqXy1DQn4W1a9fypS99icOHD/Piiy/yxBNPMGXKFLKysti8eTPvvfdeXM/T3Nwcc7tVq1bxqU99irvuuovJkyf3Xd9+1apVPPTQQ3z1q18lHA7T1tZGUVHRSL7VcedERzcPPPcOV86dxLULpgy9Yk9X0F4+KMh3w7E9EO48vW5GJhTPDsK7fEVwP2luEOQls4MgGy1mwR54TgEw6+y2DfdAR/PgL4Wu1uDLo6st6vHJ/vPbDvef7j55NkX3/zLIivEFkTUhEtBDBHC4OxLQ0fNjrdsNxD/IeNz15xaducls4C+mU/NG80suDgr6s3DRRRdx4sQJZs6cyfTp0/nsZz/LjTfeyPLly1m6dCkLF8Z3Ys5Q21100UV84xvfYOXKlYRCIZYtW8YjjzzCAw88wLp16/jRj35EKBTioYce4gMf+MBIvtVxZ/2L73KkrYtHblgc/CoK98CRWjj0VtBxf+gtOPx2pL08agi+rPwgwEvnw4XXnQ7ySXOgqDw1OkdDmZA/Obidr97eIOxPfTlEP471RdE9YLqrLfjSaWk4vTwjE0LZQZNWv/tsyMyGUMHg+dGP+7Yf4jlCWWeYH3kM/b8Mh/q11Fx/+vGZ+l1COYPDP67+lpH5FWE+cCSFMWD58uW+devWfvN27drFokWLklTR+JCun9HBQwf5H//wGJ+acYxPzzwGB9+CpmroiTSjZWRB2UKYsrB/kJfMgYIpY2rPS8YJ9+ALLJ6+lr75kVvXiaGfN28y/GXdOZVkZtvcfXmsZXHtrpjZ9cADQAj4obvfN2B5CfAwMA/oAP7Y3d+KLLsL+CLB76rtwK3uPnxDtshAvb1BM8uht4Iwj+ypT2vex08ygUagtRSmLYHLvxgcMjt1CZReGOwZiiSKGeQUBrfiC85u23B3EPixvhRGyLBBb2Yh4EHgY0A98JqZPe3uO6NWuweocvdPmdnCyPqrzGwm8BVgsbu3m9kTwFrgkQS/jzFp+/btfP7zn+83Lycnh1deeSVJFY0jna1BZ+KpZpeDbwXTXZFDSy0DJs+npWwZDx25mtmLVrD2xhugcJr20GVsC2VBQVlwGyXx7NGvAGrdvQ7AzB4H1gDRQb8Y+DaAu1ebWYWZTY16jQlm1g3kAQ3nWux4Oyrl4osvpqqqalReayw2wcXFHZr3BUEe3Z5+dDd9nWs5E4O99KWfDe6nLoEpiyBrAnc8/CqVmcfY8qlrIU977SKxxBP0M4F9UdP1wBUD1nkDuAn4jZmtAGYD5e6+zczuB/YC7cCv3P1XsV7EzNYB6wAuuGDwT6Hc3FyOHDnC5MmTx1XYjwZ358iRI+Tm5ia7lDPrbofGXaf30A9Fbh1Rhy1OmhsE+aW3BPfTlsDEWTH30n/zzmFefLuJb9ywiGKFvMiQ4gn6WKk6cPfxPuABM6siaIevBHoibfdrgDnAceD/mtnn3P0ng57QfQOwAYLO2IHLy8vLqa+vp6mpKY6S009ubi7l5Qk+SSgRGqvhv+4P9tQPv3P6SIWsfJi6GC66KWhLn3YxTFkcOXxweL29zrd/uYuZxRP4/Admj+AbEBn/4gn6evofuFvOgOYXd28BbgWwYHd7d+T2cWC3uzdFlv0cuAoYFPTDycrKYs6cMXLtEonfq/8EO/8D5q2CRTdG9tIvDo54OY+zMf/jjf3saGjhgbVLNQasyDDiCfrXgPlmNgfYT9CZ+pnoFcysGDjp7l0ER9hscfcWM9sLXGlmeQRNN6uA/sdNSmprqIJZV8BnHk/YU3Z0h7n/2bdZMrOIGy+ZkbDnFUlVw+5SuXsPcDvwLLALeMLdd5jZbWZ2W2S1RcAOM6sGVgN3RrZ9BXgSeJ2gSSeDSPOMpIGerqANfsayhD7tI7/bw/7j7dxzwyIyMtRfIzKcuI6jd/eNwMYB89ZHPX4JmD/EtvcC955HjTJeNe4MTk+fsTRhT3msrYsHN9fykYVTuGreWV4vRiRN6ZJ1MnIORA4tTeAe/T9sqqWts0fjwIqcBQW9jJyGyuDaHSWJ6UTfe+QkP355D3+4fBYXTi1MyHOKpAMFvYychkqYvjRhZ6p+59lqMjMyuOtjGgdW5Gwo6GVk9HTCoZ0Ja7ap2necX7x5gC99aA5Ti8b4iWEiY4yCXkbGoR3BdcQT0BHr7vztxl2UFmSzbuW8BBQnkl4U9DIyEtgR+/yuRl7dfZQ7P3ohBTkpcH14kVGmoJeR0VAZDKxQfH6XJ+gJ9/LtX+5ibmk+ay8/y5GVRARQ0MtIaagM9ubPsyP237fu492mNr62eiFZ5zIOrIgo6GUEdHcEV6k8z2abts4e/v7X73B5RQnXLZ46/AYiEpOCXhLv0A7o7TnvjtgNW+o43NrJ129YpEtTi5wHBb0k3oHK4P489ugbWzr45/+q4xMXT+f9F5QkqDCR9KSgl8RrqAwGOZ547p2nf//cO3SHe/mfH1+QwMJE0pOCXhKvoeq8zoitbTzBv7+2l89eMZuK0vwEFyeSfhT0klinhgs8j2ab+35ZTX52Jl9ZFfOCqCJylhT0klgH3wqGCzzHjtiX647w3K5G/uzaeUzK1ziwIomgoJfEOo8zYnt7nW9v3MX0ibn88dUaNlIkURT0klgNlZBfBkUzz3rTX2w/wBv1zfzFdQs0DqxIAinoJbHO8dLEnT1h/s+z1SyaXsSnlp39l4SIDE1BL4nTdRKaqs+p2ebHL73HvqPtfH31QkIaB1YkoeIKejO73sxqzKzWzO6OsbzEzJ4yszfN7FUzWxK1rNjMnjSzajPbZWYfSOQbkDHk4Hbw3rPuiG0+2c0/bKrlQ/NL+fCFZSNUnEj6GjbozSwEPAisBhYDt5jZ4gGr3QNUufslwBeAB6KWPQA84+4LgUuBXYkoXMagc+yI/ccXamnp6ObrqxeNQFEiEs8e/Qqg1t3r3L0LeBxYM2CdxcDzAO5eDVSY2VQzKwI+DPwosqzL3Y8nrHoZWxoqoWAqFE6Pe5P6Yyf5l9/t4aZl5SyeUTSCxYmkr3iCfiawL2q6PjIv2hvATQBmtgKYDZQDc4Em4F/MrNLMfmhmMU91NLN1ZrbVzLY2NTWd5duQMeEcOmK/+6u3MeAvrtM4sCIjJZ6gj/VX6wOm7wNKzKwKuAOoBHqATOD9wEPuvgxoAwa18QO4+wZ3X+7uy8vK1E477nS2wuG3z6rZ5q39zTxVuZ8//uAcZhRPGMHiRNJbPOOy1QPRV6cqBxqiV3D3FuBWAAuuJ7s7cssD6t39lciqTzJE0Ms4d5Ydse7Ot3+5i5K8LP7sGo0DKzKS4tmjfw2Yb2ZzzCwbWAs8Hb1C5MiaU+erfxHY4u4t7n4Q2Gdmpy5BuArYmaDaZSw51RE7Pb6gf+HtJn5be4SvrJpPUW7WCBYmIsPu0bt7j5ndDjwLhICH3X2Hmd0WWb4eWAQ8amZhgiD/k6inuAN4LPJFUEdkz19STENl0AlbNHxHbLjXuW9jNbMn5/HZK85vTFkRGV48TTe4+0Zg44B566MevwTEvNSgu1cBy8+jRhkPTnXExuFn2+qpOXSCBz/zfrIzdc6eyEjTX5mcv84TcPiduDpi27vCfPfXNSydVcwNF08bheJEREEv5+/Am4DH1RH7o9/Ucailk298QuPAiowWBb2cvzg7Yg+3drL+xTquWzyVyysmjUJhIgIKekmEhsrgssSFU8+42veff4f27jBfW71wlAoTEVDQSyLE0RFb19TKv72yl1tWzGJeWcEoFSYioKCX89XRAkdqh+2I/c4zNeRkZnDnKl3qQGS0Kejl/Bx4I7g/Q9Bv3XOUZ3Yc5E9XzqOsMGeUChORUxT0cn76Lk0cu+nG3fnbjbuYUpjDFz+kcWBFkkFBL+enoRImzoL80piLf7XzEK/vPc5//9iF5GXHdX6eiCSYgl7OT0MlTL90yMVPvb6faUW53HxZ+SgWJSLRFPRy7tqPw9G6Idvnu3p6+U3tYa5dOIXMkP6riSSL/vrk3A3TEbt1z1FaO3v4yMIpo1iUiAykoJdzN8wYsZuqG8kOZXDVvMmjWJSIDKSgl3PXUAnFF0Be7MsZbKpp5Iq5k8jPUSesSDIp6OXcneGM2PeOtFHX1KZmG5ExQEEv56b9GBzbM2SzzebqRgCuXaCgF0k2Bb2cm4Zh2udrmphbmk9Faf4oFiUisSjo5dw0VAb3MY6hP9nVw8t1R7hWzTYiY4KCXs7NgSooqYjZEfu72iN09fSq2UZkjFDQy7k5Q0fspppG8rNDrJijwUVExoK4gt7MrjezGjOrNbO7YywvMbOnzOxNM3vVzJYMWB4ys0oz+0WiCpckOnkUju+N2T7v7rxQ3cgH55dq4G+RMWLYv0QzCwEPAquBxcAtZrZ4wGr3AFXufgnwBeCBAcvvBHadf7kyJpxqn48R9DWHTtDQ3KFmG5ExJJ5drhVArbvXuXsX8DiwZsA6i4HnAdy9Gqgws6kAZlYOfAL4YcKqluQ6Q0fsplOHVaojVmTMiCfoZwL7oqbrI/OivQHcBGBmK4DZwKnLFX4P+Eug90wvYmbrzGyrmW1tamqKoyxJmgNVMGkuTCgetOiF6iYumlHE1KLcJBQmIrHEE/QWY54PmL4PKDGzKuAOoBLoMbPfAxrdfdtwL+LuG9x9ubsvLysri6MsSZqGqpgdsc0nu9m295iabUTGmHguQlIPzIqaLgcaoldw9xbgVgAzM2B35LYW+KSZ3QDkAkVm9hN3/1wCapdkaDsMzftgxbpBi158p4lwr6vZRmSMiWeP/jVgvpnNMbNsgvB+OnoFMyuOLAP4IrDF3Vvc/evuXu7uFZHtNinkx7kznBH7QnUjJXlZLJ01uElHRJJn2D16d+8xs9uBZ4EQ8LC77zCz2yLL1wOLgEfNLAzsBP5kBGuWZOrriL2k3+xwr/PC202svLCMUEas1j4RSZa4rh/r7huBjQPmrY96/BIwf5jneAF44awrlLHlQBVMfh/kTuw3+4364xxt61KzjcgYpDNa5Ow0VA7ZbJNhsPJCdaSLjDUKeolfayO07I95xM2mmkbef0EJxXnZMTYUkWRS0Ev8huiIbWzp4K39LWq2ERmjFPQSv4ZKwAZ1xG6uCc6G1WhSImOTgl7id6AKSudDTmG/2Zurm5g+MZeF0wqH2FBEkklBL/GL0RHb1dPLb2oPc82CKQTnyonIWKOgl/icOAgnDgzqiH1tz1FaO3vUbCMyhinoJT5DdMRurm4kO5TB1e+bnISiRCQeCnqJz6mO2GkX95u9qaaRK+ZOIi87rnPvRCQJFPQSnwNVULYAcgr6Zr13pI26pjY124iMcQp6iU+MjtjNpwYZ0WWJRcY0Bb0Mr+UAtB4a1BG7qaaJuaX5VJTmJ6kwEYmHgl6GF2OM2JNdPbxcd0Rnw4qMAwp6GV5DJVhGv47Y39UeoaunV+3zIuOAgl6Gd6AKyhZCdl7frE01jeRnh7i8YlISCxOReCjo5czcB3XEujubqxv54PxSsjP1X0hkrNNfqZxZSwO0NfXriK05dIIDzR1qthEZJxT0cmYxOmI3RQ6rvEaHVYqMCwp6ObOGSrAQTFvSN2tzdSMXzShialFuEgsTkXjFFfRmdr2Z1ZhZrZndHWN5iZk9ZWZvmtmrZrYkMn+WmW02s11mtsPM7kz0G5ARdqAKpiyCrAkANJ/sZtt7x9RsIzKODBv0ZhYCHgRWA4uBW8xs8YDV7gGq3P0S4AvAA5H5PcBfuPsi4ErgyzG2lbGqryP2dPv8i+800etqthEZT+LZo18B1Lp7nbt3AY8Dawassxh4HsDdq4EKM5vq7gfc/fXI/BPALmBmwqqXkdVcDyeP9OuI3VzdyKT8bJbOKk5iYSJyNuIJ+pnAvqjpegaH9RvATQBmtgKYDZRHr2BmFcAy4JVYL2Jm68xsq5ltbWpqiqd2GWl9HbHvByDc67z4dhMrLywjlKFBRkTGi3iCPtZftA+Yvg8oMbMq4A6gkqDZJngCswLgZ8BX3b0l1ou4+wZ3X+7uy8vKyuIqXkZYQyVkZMLUiwB4o/44R9u6uGaB/n1ExpN4LiJeD8yKmi4HGqJXiIT3rQAWjCe3O3LDzLIIQv4xd/95AmqW0dLXERscXbO5upEMg5UXKuhFxpN49uhfA+ab2RwzywbWAk9Hr2BmxZFlAF8Etrh7SyT0fwTscve/S2ThMsJinBG7uaaRy2aXUJyXfYYNRWSsGTbo3b0HuB14lqAz9Ql332Fmt5nZbZHVFgE7zKya4OicU4dRXg18HviImVVFbjck/F1I4h3fC+3H+jpiG1s6eGt/i65WKTIOxTX+m7tvBDYOmLc+6vFLwPwY2/2G2G38MtYNOCN2c40GGREZr3RmrMTWUAkZWX0dsZurm5g+MZeF0wqTXJiInC0FvcR2oAqmLobMHLp6evlN7WGuXTiFoNtFRMYTBb0MNqAj9rU9R2nt7FGzjcg4paCXwY7tho7mvo7YTdWNZGdmcPX7Jie5MBE5Fwp6GayhKriP6oi9cu5k8rLj6rsXkTFGQS+DNVRCKBumLOa9I23UNbVxrc6GFRm3FPQy2IGq4GibzOy+QUZ0WWKR8UtBL/319kLDG1HNNk3MLctn9uT8JBcmIudKQS/9HdsNnUFH7MmuHl6uO6KjbUTGOQW99Bd1Ruxva4/Q1dOrZhuRcU5BL/01VEIoB6YsYnNNI/nZIS6vmJTsqkTkPCjopb8Db8C0JXhGJpurG/ng/FKyM/XfRGQ801+wnNbbGxxDP2MZ1QdPcKC5Q802IilAQS+nHX0Xuk7A9KV9V6vUIOAi45+CXk6LOiN2c3UjF80oYmpRbnJrEpHzpqCX0xoqITOX4wVz2fbeMTXbiKQIBb2cdqAKpl3MlneP0+toNCmRFKGgl0BvODjiJtJsMyk/m0vLi5NdlYgkgIJeAkdqoauV3ulLeaGmkZUXlhHK0CAjIqlAQS+BSEdsdcY8jp3sVrONSAqJK+jN7HozqzGzWjO7O8byEjN7yszeNLNXzWxJvNvKGNFQCVl5PHOwkAyDlfN1WWKRVDFs0JtZCHgQWA0sBm4xs8UDVrsHqHL3S4AvAA+cxbYyFkQ6Yp+vOcpls0uYmJeV7IpEJEHi2aNfAdS6e527dwGPA2sGrLMYeB7A3auBCjObGue2kmyRjtiTpRezo6FFzTYiKSaeoJ8J7Iuaro/Mi/YGcBOAma0AZgPlcW5LZLt1ZrbVzLY2NTXFV70kxuG3ofskb/bOBTTIiEiqiSfoYx164QOm7wNKzKwKuAOoBHri3DaY6b7B3Ze7+/KyMrUPj6pIR+wzR6cyfWIuC6YWJrkgEUmkeEZ7rgdmRU2XAw3RK7h7C3ArgJkZsDtyyxtuWxkDGirxrHx+9l4eNy6bQvBPKCKpIp49+teA+WY2x8yygbXA09ErmFlxZBnAF4EtkfAfdlsZAw5U0VK8iBNdzkd0ETORlDPsHr2795jZ7cCzQAh42N13mNltkeXrgUXAo2YWBnYCf3KmbUfmrcg5CffAgTfZNemTZGdmcNX7Jie7IhFJsHiabnD3jcDGAfPWRz1+CZgf77YyhonHFlUAAAmFSURBVByugZ52nm+ewZVzJ5OXHdd/CREZR3RmbLqLdMRuapnBRxaoE1wkFSno011DJd2hPOp8uo6fF0lRCvp0d6CKdzPnMaeskNmT85NdjYiMAAV9Ogt34we387uTF+hoG5EUpqBPZ03VWE8HVeE5arYRSWEK+nQW6Yh9N+t9XF4xKcnFiMhI0bF0acwbKmkjjwvmLSE7U9/5IqlKf91prGPvNraHK7hm0dRklyIiI0hBn656ushq2smbPodr1RErktIU9OmqaReZ3sXx4ouYUpSb7GpEZAQp6NPUyT1bASidf0WSKxGRkaagT1OHal6mxfNYtvT9yS5FREaYgj5NhQ6+wS6bx6WzSpJdioiMMAV9Ggp3dTC9o5a2yUsIZWiQEZFUp6BPQ29vf5UswhTOW5HsUkRkFCjo09C+Hb8DYMHSDyW5EhEZDQr6NNS7/3VarYCi6e9LdikiMgoU9GnmUEsHM9trOFZ8EWgQcJG0oKBPM1t27mOB7SOvYnmySxGRURJX0JvZ9WZWY2a1ZnZ3jOUTzew/zewNM9thZrdGLbsrMu8tM/upmek0zCR6Z/srZFuYSe9TR6xIuhg26M0sBDwIrAYWA7eY2eIBq30Z2OnulwLXAN81s2wzmwl8BVju7kuAELA2gfXLWejsCdO9rxIAm7EsydWIyGiJZ49+BVDr7nXu3gU8DqwZsI4DhWZmQAFwFOiJLMsEJphZJpAHNCSkcjlrW/ccY0FvLV3ZxVB8QbLLEZFREk/QzwT2RU3XR+ZF+wGwiCDEtwN3unuvu+8H7gf2AgeAZnf/VawXMbN1ZrbVzLY2NTWd5duQeGyqbuTS0G5C5e9XR6xIGokn6GMlgg+Y/jhQBcwAlgI/MLMiMysh2PufE1mWb2afi/Ui7r7B3Ze7+/KysrK434DE77e79jHf6gnNVLONSDqJJ+jrgVlR0+UMbn65Ffi5B2qB3cBC4KPAbndvcvdu4OfAVedftpytPYfbyD1aTSZhUPu8SFqJJ+hfA+ab2RwzyyboTH16wDp7gVUAZjYVWADUReZfaWZ5kfb7VcCuRBUv8dtc08iSjN3BxPSlyS1GREbVsGPGunuPmd0OPEtw1MzD7r7DzG6LLF8PfBN4xMy2EzT1fM3dDwOHzexJ4HWCztlKYMPIvBU5k03VjXxmwl7ILoWJ5ckuR0RGUVyDg7v7RmDjgHnrox43ANcNse29wL3nUaOcp7bOHl6pO8r9RXuCZht1xIqkFZ0ZmwZ+9+4RMsLtTOnYAzPUbCOSbhT0aWBTdSOX5ezHXB2xIulIQZ/i3J0Xahq5sexQMENBL5J2FPQprvrgCQ40d3BF7l7InwKF05NdkoiMMgV9ittU3QjArPZqdcSKpCkFfYrbXN3IZTOyyTz6jjpiRdKUgj6FHT/Zxet7j/EHM46B96p9XiRNKehT2ItvN9Hr8MH8+mCGzogVSUsK+hS2ubqRSfnZzGivhoJpUKSOWJF0pKBPUeFe58W3m7jmwjIyGqrUbCOSxuK6BMJ4cfNDv6OzpzfZZYwJ3eFejp3s5qPvy4ddb8OSm5JdkogkSUoFfWlBDl1hBf0pC6cVcu3Eg4Brj14kjaVU0K///GXJLmHseekfg3t1xIqkLbXRp7qGSiicAYVTk12JiCSJgj7VNVSq2UYkzSnoU1lHCxyp1RmxImlOQZ/KDr6JOmJFREGfyhqqgnt1xIqkNQV9KmuohKJyKChLdiUikkQK+lTWUKn2eRGJL+jN7HozqzGzWjO7O8byiWb2n2b2hpntMLNbo5YVm9mTZlZtZrvM7AOJfAMyhI5mOPqugl5Ehj9hysxCwIPAx4B64DUze9rdd0at9mVgp7vfaGZlQI2ZPebuXcADwDPufrOZZQN5iX8bEf+0Eno6Ruzpx5VTn4M6YkXSXjxnxq4Aat29DsDMHgfWANFB70ChmRlQABwFesysCPgw8EcAkeDvSlj1A5VeCOHOEXv6cWfOh2H21cmuQkSSLJ6gnwnsi5quB64YsM4PgKeBBqAQ+G/u3mtmc4Em4F/M7FJgG3Cnu7cNfBEzWwesA7jgggvO9n0EPv3P57adiEgKi6eNPtYgoz5g+uNAFTADWAr8ILI3nwm8H3jI3ZcBbcCgNn4Ad9/g7svdfXlZmY4SERFJlHiCvh6YFTVdTrDnHu1W4OceqAV2Awsj29a7+yuR9Z4kCH4RERkl8QT9a8B8M5sT6UxdS9BME20vsArAzKYCC4A6dz8I7DOzBZH1VtG/bV9EREbYsG307t5jZrcDzwIh4GF332Fmt0WWrwe+CTxiZtsJmnq+5u6HI09xB/BY5EuijmDvX0RERom5D2xuT77ly5f71q1bk12GiMi4YWbb3H15rGU6M1ZEJMUp6EVEUpyCXkQkxY3JNnozawLeO8fNS4HDw66VHvRZ9KfPoz99Hqelwmcx291jnoQ0JoP+fJjZ1qE6JNKNPov+9Hn0p8/jtFT/LNR0IyKS4hT0IiIpLhWDfkOyCxhD9Fn0p8+jP30ep6X0Z5FybfQiItJfKu7Ri4hIFAW9iEiKS5mgH25c23RiZrPMbHNkjN4dZnZnsmtKNjMLmVmlmf0i2bUkm8Zx7s/M7or8nbxlZj81s9xk15RoKRH0UePargYWA7eY2eLkVpVUPcBfuPsi4Ergy2n+eQDcCexKdhFjxKlxnBcCl5LGn4uZzQS+Aix39yUEV+hdm9yqEi8lgp6ocW0j49KeGtc2Lbn7AXd/PfL4BMEf8szkVpU8ZlYOfAL4YbJrSbaocZx/BME4zu5+PLlVJV0mMMHMMoE8Bg+sNO6lStDHGtc2bYMtmplVAMuAV868Zkr7HvCXQG+yCxkDosdxrjSzH5pZfrKLShZ33w/cTzB40gGg2d1/ldyqEi9Vgj6ecW3TjpkVAD8DvuruLcmuJxnM7PeARnffluxaxoi4x3FOB2ZWQvDrfw7BmNf5Zva55FaVeKkS9PGMa5tWzCyLIOQfc/efJ7ueJLoa+KSZ7SFo0vuImf0kuSUllcZx7u+jwG53b3L3buDnwFVJrinhUiXo4xnXNm2YmRG0we5y979Ldj3J5O5fd/dyd68g+H+xyd1Tbo8tXhrHeZC9wJVmlhf5u1lFCnZODztm7Hgw1Li2SS4rma4GPg9sN7OqyLx73H1jEmuSsUPjOEe4+ytm9iTwOsHRapWk4OUQdAkEEZEUlypNNyIiMgQFvYhIilPQi4ikOAW9iEiKU9CLiKQ4Bb2ISIpT0IuIpLj/DySIMcKV9omxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(r.history['accuracy'],label='acc')\n",
    "plt.plot(r.history['val_accuracy'],label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we are going to go back again to word embeddings (though this overlaps with what we said earlier , it is still useful)\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Why do we need embeddings ?</h4>\n",
    "\n",
    "NLP is machine learning applied to text\n",
    "\n",
    "text is represented in a computer as a string\n",
    "\n",
    "Deep learning (neural networks in particular) expects numbers as inputs\n",
    "\n",
    "this is because the first thing we do in a neural network is multiplication\n",
    "\n",
    "we know how we multiply numbers , we dont know how we multiply strings \n",
    "\n",
    "so the question is , how do we turn strings , specifically words , into numbers\n",
    "\n",
    "thats what word embeddings are all about\n",
    "\n",
    "---\n",
    "\n",
    "<h4>what is a feature vector ?</h4>\n",
    "\n",
    "The first thing we need to discuss when talking about word embedding is what are feature vectors ?\n",
    "\n",
    "lets review what a feature vector is , in short we are going to first remind ourselves what we are doing in machine learning\n",
    "\n",
    "we have some dataset and we want to analyse it\n",
    "\n",
    "for ex , we want to take a survey of some of our students , and we want to predict whether or not they will succeed in our course\n",
    "\n",
    "we may ask them some questions such as :\n",
    "\n",
    "<ul>\n",
    "    <li>Do you meet the prerequisites of this course ?</li>\n",
    "    <li>Are you and independant learner and are you able to do independant research if you come acroos a topic you dont know ?</li>\n",
    "</ul>\n",
    "\n",
    "for each of these , the students will give us their score on a scale from 1 $\\ldots$ 10\n",
    "\n",
    "and so we tally these up for Alice,Bob,Carol,David,Eric and each of these rows is a feature vector\n",
    "\n",
    "<img src='extras/32.7.PNG' width='700'></img>\n",
    "\n",
    "so for example , the first row [10,10] thats a vector , the second row [1,1] is also a vector\n",
    "\n",
    "remember that a vector is just a tuple of numbers\n",
    "\n",
    "we can see that the number [10,10] maps to Alice succeeded\n",
    "\n",
    "we see that Bob , [1,1] , maps to the student did not succeed\n",
    "\n",
    "---\n",
    "\n",
    "<h4>How do we use the data ?</h4>\n",
    "\n",
    "<img src='extras/32.8.PNG' width='400'></img>\n",
    "\n",
    "and so our goal in machine learning , say we are doing classification , is to draw a boundary between the yellow dots and the purple dots\n",
    "\n",
    "The yellow dot mean succeeded and the purple dot mean did not succeed\n",
    "\n",
    "lets see we have a new person , the grey point , and we want to be able to predict if this person will succeed in this course\n",
    "\n",
    "we can use the boundary we found before (the black curve)\n",
    "\n",
    "so if it falls on the yellow side we predict succeed , if it falls in the purple side we predict will not succeed\n",
    "\n",
    "so why is this important ?\n",
    "\n",
    "the basic idea is , the location of this vector is important , it tells us everything we need to know , it allows us to make accurate model predictions\n",
    "\n",
    "so our goal is to always create feature vectors that put each individual point in a useful position relative to the others (very simple)\n",
    "\n",
    "in this example , actually one encouraging thing about this is , if we look at the space , there is more space where student succeed and there is a very small space where students do not succeed , so we can conclude that most studens , if they fall under this big area , have a better chance of succeeding in this course\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Now an NLP example</h4>\n",
    "\n",
    "Another example with feature vectors but this time with NLP\n",
    "\n",
    "usually with NLP we want to know the features of a word\n",
    "\n",
    "so suppose we have a list of words [king,Queen,Prince,Princess,Britain,Spain]\n",
    "\n",
    "now we want these to have some attributes so lets put them in a table\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td></td>\n",
    "        <td>Gender</td>\n",
    "        <td>Age</td>\n",
    "        <td>Place</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>King</td>\n",
    "        <td>+1</td>\n",
    "        <td>+1</td>\n",
    "        <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Queen</td>\n",
    "        <td>-1</td>\n",
    "        <td>+1</td>\n",
    "        <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Prince</td>\n",
    "        <td>+0.9</td>\n",
    "        <td>-1</td>\n",
    "        <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Princess</td>\n",
    "        <td>-0.8</td>\n",
    "        <td>-0.9</td>\n",
    "        <td>0.0000001</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Britain</td>\n",
    "        <td>0</td>\n",
    "        <td>0</td>\n",
    "        <td>0.9</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Spain</td>\n",
    "        <td>0</td>\n",
    "        <td>0</td>\n",
    "        <td>1</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "so we might say , King is a very male word and it probably refers to an older person , it is also not a place so thats [+1,+1,0]\n",
    "\n",
    "we can say princess is a very female word and it probably refers to a younger person , it is also not a place , so maybe [-0.8,-0.9,0.0000001]\n",
    "\n",
    "sain has no gender associated with it nor age , but it is place so we say it has the feature vector [0,0,1]\n",
    "\n",
    "and so these are feature vectors that correspond to words , so we call them word vectors\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Automation</h4>\n",
    "\n",
    "In real life , unlike with people , we cant ask each word what 'age' it feels like , in fact we cant ask words anything (also there are way too many words in the dictionary to individually survey)\n",
    "\n",
    "so we need some automated way to find feature vectors for words\n",
    "\n",
    "one very simple way is to just use counting \n",
    "\n",
    "---\n",
    "\n",
    "<h4>How to count</h4>\n",
    "\n",
    "suppsoe we are looking at the words : [Electron,Newton,Energy,Mitochondria,Cell]\n",
    "\n",
    "now suppose we have some books , so we have our Favourite biology book and our favourite physics book and we count up each time one of those words appear in that book\n",
    "\n",
    "we know that in the physics book , [Electron,Newton,Energy] are going to show up a lot , but [Mitochondria,Cell] probably wont\n",
    "\n",
    "In a biology book , we know that [Mitochondria,Cell] are going to show up a lot , maybe [Energy] too (since it is related to both topics)\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td></td>\n",
    "        <td>favourite biology book</td>\n",
    "        <td>favourite physics book</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Electron</td>\n",
    "        <td>50</td>\n",
    "        <td>800</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Newton</td>\n",
    "        <td>1</td>\n",
    "        <td>500</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Energy</td>\n",
    "        <td>20</td>\n",
    "        <td>350</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Mitochondria</td>\n",
    "        <td>400</td>\n",
    "        <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Cell</td>\n",
    "        <td>600</td>\n",
    "        <td>30</td>\n",
    "    </tr>\n",
    "    \n",
    "</table>\n",
    "\n",
    "now what happens if we make a scatterplot of each point similar to what we did before ?\n",
    "\n",
    "<img src='extras/32.9.PNG' width='400'></img>\n",
    "\n",
    "well we can see that [Electron,Newton,Energy] show up close together , we can also see that [Mitochondria,Cell,Energy] show up close together\n",
    "\n",
    "so these are reasonable feature vectors , we can also call these word vectors\n",
    "\n",
    "---\n",
    "\n",
    "<h4>In modern times ...</h4>\n",
    "\n",
    "in modern times we have more interesting ways of finding these word vectors\n",
    "\n",
    "typically this is an unsupervised task adn the output is going to be a list of feature vectors\n",
    "\n",
    "but those feature vectors dont necessarily have to have any meaning for us humans\n",
    "\n",
    "so before we did the example with agae,gender,place but when we use an unsupervised learning method each dimension can be whatever it wants , we as humans dont get to decide that\n",
    "\n",
    "so they are not going to tell us , this is a biology word and this is a physics word , they might , but there is no guarantee that they will do\n",
    "\n",
    "unsupervised learning means the model can find whatever it wants to find , it doesnot have to make any sense to us , it just has to make sense geometrically\n",
    "\n",
    "and by geometrically we mean that , if we plotted the word vectors like we did earlier , we would still find that electron is probably close to ther physics related words and mitochondria is probably still close to other biology related words\n",
    "\n",
    "when this happens , we call these vectors 'latent vectors' or 'hidden vectors'\n",
    "\n",
    "it has the same meaning as the hidden layers of a neural network , they sure are useful at doing whatever task the neural network is doing , but if we look at them , its just a list of numbers , its not going to make any sense to us humans (and it doesnot have to)\n",
    "\n",
    "and so typically we would find these word vectors using an algorithm such as Word2Vec,GloVe,FastText , these are the big three algorithms right now for finding word vectors \n",
    "\n",
    "---\n",
    "\n",
    "<h4>Word Analogies</h4>\n",
    "\n",
    "One interesting thing about these modern word vector techniques is that they model the relationships between words very well\n",
    "\n",
    "so one famous application of word vectors is analogies\n",
    "\n",
    "so if we take the vector of king and subtract from it the vector of man Vec('king') - Vec('man') ,  and we take the vector of queen and we subtract from it the vector of woman , Vec('queen') - Vec('woman') , we find that these two differences are approximately equal\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Word Similarity</h4>\n",
    "\n",
    "Another common task is word similarity , so we pick a wo rd , find its corresponding word vector , and then we try to find the words closest to it\n",
    "\n",
    "those words end up being very related to each other\n",
    "\n",
    "<img src='extras/32.10.PNG' width='600'></img>\n",
    "\n",
    "so for example , we pick the word <span style=\"color:blue;\">light</span> , and its close to <span style=\"color:blue;\">fan</span> , <span style=\"color:blue;\">led</span> and <span style=\"color:blue;\">bulb</span> , so that makes sense\n",
    "\n",
    "so the point is word vectors learn an effecient and useful representation of the words\n",
    "\n",
    "---\n",
    "\n",
    "<h4>what does this have to do with embeddings ?</h4>\n",
    "\n",
    "word embeddings are word vectors :)\n",
    "\n",
    "different name , same thing\n",
    "\n",
    "so typically in deep learning we are working with matricies , every dense layer in a neural network is a matrix multiply\n",
    "\n",
    "so if we line up each word vector one after the other we get a matrix , this matrix is called word embedding and it contains singular word vectors\n",
    "\n",
    "<img src='extras/32.11.PNG' width='600'></img>\n",
    "\n",
    "one important thing to remember is that each word has a specific row in this matrix\n",
    "\n",
    "so later on we are going to have to have a way to map each word to its corresponding location in this matrix\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Conventions</h4>\n",
    "\n",
    "we refer to the vocabulary size , the total number of words in our data with V\n",
    "\n",
    "we refer to the embedding dimension , the feature vector size , with the capital letter D\n",
    "\n",
    "so the word embedding is a VxD matrix\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Computational Trick</h4>\n",
    "\n",
    "one important computational trick we learned about is this :\n",
    "\n",
    "we know that when we have categorical variables such as words we need to one hot encode them , so\n",
    "\n",
    "<ul>\n",
    "    <li>A word at index 0 becomes [1,0,0,0,...,0]</li>\n",
    "    <li>A word at index 1 becomes [0,1,0,0,...,0]</li>\n",
    "    <li>A word at index 2 becomes [0,0,1,0,...,0]</li>\n",
    "    <li>A word at index V-1 becomes [0,0,0,0,...,1]</li>\n",
    "</ul>\n",
    "\n",
    "so the index tells us the position of the 1 in the one-hot encoded vector\n",
    "\n",
    "once we have one-hot encoded the words we can put them into the neural network as usual\n",
    "\n",
    "one important thing to remember is that , when we are inputing words into the neural network , the first layer that attaches words to the rest of the neural network will always be an embedding\n",
    "\n",
    "now where is the computational trick ?\n",
    "\n",
    "well we know that in a neural network , the first step is to do a matrix multiply\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Computational Trick</h4>\n",
    "\n",
    "so lets look at an example , notice the results of the following multiplications between a one-hot encoded vector and a weight matrix\n",
    "\n",
    "<img src='extras/32.12.PNG' width='350'></img>\n",
    "\n",
    "notice how we get the row at index 0 in the weight matrix , and how [1,0,0] is the one-hot encoding of 0\n",
    "\n",
    "<img src='extras/32.13.PNG' width='350'></img>\n",
    "\n",
    "notice how we get the row at index 1 in the weight matrix , and how [0,1,0] is the one-hot encoding of 1\n",
    "\n",
    "<img src='extras/32.14.PNG' width='350'></img>\n",
    "\n",
    "notice how we get the row at index 2 in the weight matrix , and how [0,0,1] is the one-hot encoding of 2\n",
    "\n",
    "so the pattern should be clear by now , multiplying a one hot encoded vector of some integer k by the weight matrix is the same as selecting the kth row from the weight matri\n",
    "\n",
    "so this is equivalent to the much simpler and more effecient , W[k] , we should never multiply a one_hot vector by a matrix since this is very slow\n",
    "\n",
    "in tensorflow , there is ```tf.nn.embedding_lookup``` should we need to make the selection manually\n",
    "\n",
    "in keras the ```Embedding()``` layer is already doing that for us (never use ```Dense()``` for an embedding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we previously looked at algorithms such as word2vec/GloVe\n",
    "\n",
    "for now what we want to do is something more like transfer learning (which we should have known about had we arranged these notebooks in a better order ) , where we take pretrained word embeddings , found by experts with more powerful computers than us , and initialise our neural network to use those embeddings instead\n",
    "\n",
    "this is acctually pretty great since we already know that finding good hyperparameters is not easy , but in this way we can take advantage of results found by other experts\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Using Word Embeddings</h4>\n",
    "\n",
    "so architecturely speaking , how does this work ?\n",
    "\n",
    "suppose we have some simple feedforwad neural network , remember that a neural network consists of a bunch of weight matricies at each layer\n",
    "\n",
    "now typically , when we create a neural network , we would use random initialisation for these weight matricies\n",
    "\n",
    "so for example , we would call ```np.random.randn()``` and multiply result by some small number to reduce the variance of those weights\n",
    "\n",
    "but with pretraining , we dont initialsie randomly , instead we take this VxD matrix , and we fill it with pretrained state of the art values (available on the internet) \n",
    "\n",
    "so instead of ```W = np.random.randn(V,D)*0.01``` we do something like ```W = preloaded from CSV```\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Problem!</h4>\n",
    "\n",
    "now there is a slight problem when it comes to pretrained word embeddings , we might as k , what if there is a word in our dataset that doesnot appear in the pre-trained embeddings that we downloaded ?\n",
    "\n",
    "typically this happens for uncommon words , since if a word was common then it probably shows up in the existing word embedding\n",
    "\n",
    "so sometimes the words that dont appear might be so uncommon that it wont affect the results\n",
    "\n",
    "but typically what we do in this situation is just to initialise those word embeddings randomly (or 0)\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Train pre-trained embeddings ?</h4>\n",
    "\n",
    "the next question we might have is , should we allow backpropagation to flow through word embeddings ?\n",
    "\n",
    "we might think that this is necessary , since if some words have randomly initialised embeddings , then we definitely want to train them\n",
    "\n",
    "unfortunately , most of the deep learning libraries dont have fine-grained control so that we only train the word embeddings that are not pre-trained , so its either train the entire matrix or none of it , the whole matrix gets updated or none of it gets updated\n",
    "\n",
    "typically in transfer learning , we dont bother to train the pretrained weights and we just assume they are good , and we can do that here too\n",
    "\n",
    "remember that uncommon words are definition 'uncommon' , so their prescence is small , and their effect on the results is also probably small\n",
    "\n",
    "we can also assume that the word embeddings that are pretrained are already pretty good , so their might not be any need to fine tune them\n",
    "\n",
    "their have been cases where fine-tuning lead to worse results , so for a real life project we would just have to experiment\n",
    "\n",
    "so we try both and do whatever works best\n",
    "\n",
    "---\n",
    "\n",
    "<h4>In Keras</h4>\n",
    "\n",
    "implementation-wise , remember that in keras , if we want to train the weights of a layer , we just set ```embedding_layer.trainable=True ``` , which is the default , to keep the weights constant we set ```embedding_layer.trainable=False```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next we are going to do a quick introduction to CNNs (this will be discussed thoroughly later)\n",
    "\n",
    "CNNs wont be a major concern for us at this point , the thing we want to get out of using CNNs is just setting up a simple static neural network and training it\n",
    "\n",
    "---\n",
    "\n",
    "<h4>What is a CNN ?</h4>\n",
    "\n",
    "CNNs stand for Convolutional Neural Network , and what that means is , its a neural network with convolution\n",
    "\n",
    "so to understand CNNs , we first have to understand convolution\n",
    "\n",
    "normally in deep learning we use convolution on images which are two dimensional  , a typical example is edge detection\n",
    "\n",
    "<img src='extras/32.15.PNG' width='350'></img>\n",
    "\n",
    "so we can see above on the left , we have the original image , we have an image that kind of looks like the one on the left , but we can see white where there are edges in the original image and then black otherwise\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Convolution</h4>\n",
    "\n",
    "so what happens during convolution , is we have some kind of edge detection filter (or any other kind of filter) , and we slide this filter over every part of the input image\n",
    "\n",
    "at each point where we slide it , we multiply the filter by the image pixels element-wise and we sum them all together to produce the result\n",
    "\n",
    "<img src='extras/32.16.GIF' width='350'></img>\n",
    "\n",
    "but then we might ask , how do we know what values we should put in the filter in order to get an edge detector ?\n",
    "\n",
    "and of course this is machine learning so we dont want to choose these parameters manually\n",
    "\n",
    "machine learning means that the machine is supposed to learn these parameters and in deep learning thats done by backpropagation\n",
    "\n",
    "so as long as we can set up a loss function at the end of this neural network , and we can backpropagate the error , those filter parameters automatically be found during training\n",
    "\n",
    "---\n",
    "\n",
    "<h4>1-D Convolution</h4>\n",
    "\n",
    "now when we are talking about things like audio and text , we actually have a simpler situation\n",
    "\n",
    "audio an text are both 1D objects , because time is the only independant variable\n",
    "\n",
    "so for now , we will be using 1D convolution and this is actually a lot simpler to visualise\n",
    "\n",
    "<img src='extras/32.17.GIF' width='350'></img>\n",
    "\n",
    "its just a signal going in one direction , and the filter slides along that signal  in that one direction\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Cross-Correlation</h4>\n",
    "\n",
    "now a lot of people dont know this , but what we call convolution in deep learning is actually not real convolution as its known in the rest of the engineering world\n",
    "\n",
    "the operation we do in deep learning is actually called Cross-Correlation\n",
    "\n",
    "$$Convolution : \\left(f*g\\right)\\left[n\\right] = \\sum_mf[m]g[n\\boxed{-}m]$$\n",
    "\n",
    "$$Cross-Correlation : \\left(f\\star g\\right)\\left[n\\right] = \\sum_mf[m]g[n\\boxed{+}m]$$\n",
    "\n",
    "the only difference between true convolution and cross-correlation is that the filter is reversed for convolution\n",
    "\n",
    "otherwise , these operations are all the same , just multiply and add\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Why is Correlation Significant ?</h4>\n",
    "\n",
    "we intuitively know what correlation means , if two  things are correlated to each other , then we say that they are correlated\n",
    "\n",
    "in fact the word 'correlation' contains the word 'relation'\n",
    "\n",
    "for example , we know that weight is correlated with height , so the taller we are , the heavier we probably are , so we say that height and weight have a strong correlation\n",
    "\n",
    "---\n",
    "\n",
    "so lets say we have two signals , one is our input signal and one is our filter\n",
    "\n",
    "what happens if we perform convolution , or in other words cross-correlation between these input signal and this filter\n",
    "\n",
    "<img src='extras/32.18.PNG' width='800'></img>\n",
    "\n",
    "well the filter just acts as a pattern finder , it outputs a small number where the filter doesnot match the input and it outputs a big number where the filter does match the input\n",
    "\n",
    "so the job of the filter is just to find the parts of the signal that look like itself , and it outputs a large number when that happens\n",
    "\n",
    "so thats why we see that big spike in the middle , because as we slide the lower image across the upper image we find out that they match exactly when they are lined up perfectly in the centre\n",
    "\n",
    "so thats what correlation does and thats what in deep learning we call convolution\n",
    "\n",
    "---\n",
    "\n",
    "<h4>1-D Convolution</h4>\n",
    "\n",
    "one obvious application of 1D convolution on audio signals is speech recognition\n",
    "\n",
    "this is because speech is recorded as an audio signal\n",
    "\n",
    "<img src='extras/32.19.PNG' width='700'></img>\n",
    "\n",
    "one of the most famous applications of NLP , speech recognition , involves taking a sound signal as input and producing the words being said as output (as text)\n",
    "\n",
    "we might also call this text-transcription\n",
    "\n",
    "---\n",
    "\n",
    "recall that the first step of any neural network that takes in a sequence as input , is to create an embeddings of those words\n",
    "\n",
    "or in other words , given a sequence of words we are going to turn that into a sequence of word vectors\n",
    "\n",
    "well this basically creates a one-dimensional signal , but whereas audio is a scalar signal , where in each point of time we have one value , for word embeddings we get a vector signal , where for each point of time we have multiple values\n",
    "\n",
    "\"The quick brown fox\" $\\rightarrow$ [Vec(\"the\"),Vec(\"quick\"),Vec(\"brown\"),Vec(\"fox\")]\n",
    "\n",
    "hmmmmmmmmmmmm\n",
    "\n",
    "---\n",
    "\n",
    "lets take a look at the structure of the data so this becomes clear \n",
    "\n",
    "<img src='extras/32.20.PNG' width='600'></img>\n",
    "\n",
    "first we have a sequence of words , say of length T\n",
    "\n",
    "then we convert each word into a vector by grabbing it from some pretrained word embedding , each of these vectors is of size D\n",
    "\n",
    "so now we have T objects , each of them is of size D\n",
    "\n",
    "we can also think of that as a TxD matrix if we stack them all together\n",
    "\n",
    "now importantly that is not the same as a HxW (Height x Width) image \n",
    "\n",
    "with images , we use 2D convolution , so we are going to do convolution along the height dimension and the width dimension\n",
    "\n",
    "with 1D convolution , we are only doing convolution along the time dimension , so we are only going down\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Architecture</h4>\n",
    "\n",
    "so the architecture of the model we are going to look at is going to be like this :\n",
    "\n",
    "<img src='extras/32.21.PNG' width='600'></img>\n",
    "\n",
    "<ol>\n",
    "    <li>convert input sentence into sequence of word embeddings</li>\n",
    "    <li>we do 1D Convolution on that 1D vector signal</li>\n",
    "    <li>then we follow the usual pattern of a CNN , so that convolution followed by pooling , another convolution , another pooling and so on</li>\n",
    "    <li>we do that a few times , then we pass it through a couple of dense layers to get the output prediction</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1>Code</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense,Input,GlobalMaxPooling1D,Conv1D,MaxPooling1D,Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can get the dataset from here\n",
    "# https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data\n",
    "# we will be using train.csv\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_VOCAB_SIZE = 20000\n",
    "EMBEDDING_DIM = 100 # we will be using GloVe [50,100,200,300]\n",
    "VALIDATION_SPLIT = 0.2\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first lets load in data and take a look at it\n",
    "data = pd.read_csv('datasets/toxic comments/train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we have a multilabel classification problem\n",
    "X = data['comment_text'].to_numpy()\n",
    "Y = data.iloc[:,2:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next lets tokenise our sentences\n",
    "tokeniser = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "tokeniser.fit_on_texts(X)\n",
    "X = tokeniser.texts_to_sequences(X)\n",
    "\n",
    "word2idx = tokeniser.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next we pad our sentences\n",
    "X = pad_sequences(X,maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next we want to create our embedding matrix\n",
    "# first we load in the pre trained word vectors\n",
    "file = 'datasets/glove/glove.6B.'+str(EMBEDDING_DIM)+'d.txt'\n",
    "word2vec = {}\n",
    "for line in open(file,encoding='utf8'):\n",
    "    line = line.split()\n",
    "    word = line[0]\n",
    "    vec = line[1:]\n",
    "    vec = np.array(vec).astype('float32')\n",
    "    word2vec[word] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = min(len(word2idx)+1,MAX_VOCAB_SIZE)\n",
    "# now lets create our embedding matrix\n",
    "embedding = np.zeros((V,EMBEDDING_DIM))\n",
    "\n",
    "# now we fill the matrix with the pretrained word embeddings\n",
    "# if a word is not in our pretrained vectors , we leave it as zeros\n",
    "\n",
    "for word,idx in word2idx.items():\n",
    "    vec = word2vec.get(word,0)\n",
    "    if idx < V:\n",
    "        embedding[idx] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we are ready to build our model !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(\n",
    "    V,\n",
    "    EMBEDDING_DIM,\n",
    "    weights = [embedding],\n",
    "    input_length=MAX_SEQUENCE_LENGTH,\n",
    "    trainable = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input shape now is NxT\n",
    "# so at each time step we have index of a word\n",
    "i = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "x = embedding_layer(i) # NxTxD\n",
    "x = Conv1D(128,3,activation='relu')(x)\n",
    "x = MaxPooling1D(3)(x)\n",
    "x = Conv1D(128,3,activation='relu')(x)\n",
    "x = MaxPooling1D(3)(x)\n",
    "x = Conv1D(128,3,activation='relu')(x)\n",
    "# here we have a GlobalMaxPooling\n",
    "# this means we have a time series and wedont care how long it is\n",
    "# just take the max value in time series in each dimension\n",
    "# so if the input is of size TxM , the output is of size M\n",
    "# we can think of this as choosing which point of time was the most important for computing the output\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(128,activation='relu')(x)\n",
    "# we are doing 6 seperate binary classifications\n",
    "o = Dense(Y.shape[1],activation='sigmoid')(x)\n",
    "\n",
    "model = Model(i,o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='rmsprop',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "998/998 [==============================] - 49s 48ms/step - loss: 0.1047 - accuracy: 0.9369 - val_loss: 0.0752 - val_accuracy: 0.9936\n",
      "Epoch 2/10\n",
      "998/998 [==============================] - 46s 46ms/step - loss: 0.0687 - accuracy: 0.9926 - val_loss: 0.0712 - val_accuracy: 0.9934\n",
      "Epoch 3/10\n",
      "998/998 [==============================] - 46s 46ms/step - loss: 0.0629 - accuracy: 0.9927 - val_loss: 0.0684 - val_accuracy: 0.9932\n",
      "Epoch 4/10\n",
      "998/998 [==============================] - 46s 46ms/step - loss: 0.0587 - accuracy: 0.9928 - val_loss: 0.0694 - val_accuracy: 0.9941\n",
      "Epoch 5/10\n",
      "998/998 [==============================] - 46s 47ms/step - loss: 0.0571 - accuracy: 0.9930 - val_loss: 0.0716 - val_accuracy: 0.9843\n",
      "Epoch 6/10\n",
      "998/998 [==============================] - 46s 46ms/step - loss: 0.0534 - accuracy: 0.9926 - val_loss: 0.0687 - val_accuracy: 0.9941\n",
      "Epoch 7/10\n",
      "998/998 [==============================] - 46s 46ms/step - loss: 0.0524 - accuracy: 0.9938 - val_loss: 0.0822 - val_accuracy: 0.9939\n",
      "Epoch 8/10\n",
      "998/998 [==============================] - 46s 46ms/step - loss: 0.0513 - accuracy: 0.9932 - val_loss: 0.0889 - val_accuracy: 0.9934\n",
      "Epoch 9/10\n",
      "998/998 [==============================] - 46s 46ms/step - loss: 0.0491 - accuracy: 0.9932 - val_loss: 0.0887 - val_accuracy: 0.9940\n",
      "Epoch 10/10\n",
      "998/998 [==============================] - 46s 46ms/step - loss: 0.0482 - accuracy: 0.9930 - val_loss: 0.0821 - val_accuracy: 0.9924\n"
     ]
    }
   ],
   "source": [
    "r = model.fit(\n",
    "    X,Y,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_split = VALIDATION_SPLIT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(r.history['loss'],label='loss')\n",
    "plt.plot(r.history['val_loss'],label='val_loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(r.history['accuracy'],label='acc')\n",
    "plt.plot(r.history['val_accuracy'],label='val_acc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC :  0.9776202939043088\n"
     ]
    }
   ],
   "source": [
    "# next lets calculate the auc score\n",
    "# first we want to make predictions\n",
    "p = model.predict(X)\n",
    "# then we want to calculate auc for each column\n",
    "# then take the mean\n",
    "aucs = []\n",
    "for i in range(p.shape[1]):\n",
    "    auc = roc_auc_score(Y[:,i],p[:,i])\n",
    "    aucs.append(auc)\n",
    "\n",
    "print('AUC : ',np.mean(aucs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next is a review of RNNs\n",
    "\n",
    "---\n",
    "\n",
    "<h4>What is an RNN ?</h4>\n",
    "\n",
    "so in the grand scheme of things , a CNN is still pretty basic\n",
    "\n",
    "we have one input and we get one output , a static network\n",
    "\n",
    "<img src='extras/32.22.PNG' width='300'></img>\n",
    "\n",
    "if we think of our brain which consists of billions of neurons , they are not connected in some linear fashion where we have an input and they all just point towards the output\n",
    "\n",
    "the neurons in our brain are all conencted together and their are many loops\n",
    "\n",
    "when we make a decision now , we are not just making t hat decision based on what we see and hear now\n",
    "\n",
    "we can read what we are writing now , and remember what we wrote before and so we can think and reason based on past inputs as well\n",
    "\n",
    "so it is reasonable then to wonder what would happen if we added feedback loops to ANNs\n",
    "\n",
    "---\n",
    "\n",
    "The most basic RNN we can have looks like this , where we just connect the hidden layer back to itself\n",
    "\n",
    "<img src='extras/32.23.PNG' width='500'></img>\n",
    "\n",
    "since the independant variable here is time , our three major data variables need to be indexed by time \n",
    "\n",
    "so we call our input $x(t)$ (instead of just x) , we call our output $y(t)$ (instead of just y) , and we call the hidden layer value $h(t)$ instead of just h\n",
    "\n",
    "---\n",
    "\n",
    "since $x(t)$ is given, we dont need to calculate it\n",
    "\n",
    "$$x(t) = given$$\n",
    "\n",
    "since $y(t)$ only depends on $h(t)$ , calculating $y(t)$ is as simple as it usually is , just a regular dense layer\n",
    "\n",
    "$$y(t) = softmax \\left(W_o^T h(t) + b_o\\right)$$\n",
    "\n",
    "the layer of interest in an RNN is the hidden layer\n",
    "\n",
    "to calculate $h(t)$ we add both a term that depends on $x(t)$ and a term that depends on $h(t-1)$\n",
    "\n",
    "$$h(t) = \\mathcal{f}\\left(W_i^T x(t) + W_h^T h(t-1) + b_h\\right)$$\n",
    "\n",
    "since $x(t)$ is a vector of size D , and $h(t)$ is a vector of size M , we need to set the weight matricies to consistent with these sizes\n",
    "\n",
    "so as usual , $W_i$ is of size $D\\times M$ , $W_h$ must be of size $M \\times M$ since it connects $h(t-1)$ to $h(t)$ and both of these are of size M , and assuming we are doing multiclass classification , the output $y(t)$ will be of size K and the output weight will be of size $M \\times K$ as usual\n",
    "\n",
    "$$shape(x(t)) = D \\\\ shape(h(t)) = M \\\\ shape(y(t)) = K \\\\ shape(W_i) = D \\times M \\\\ shape(W_h) = M \\times M \\\\ shape(W_0) = M \\times K$$\n",
    "\n",
    "---\n",
    "\n",
    "one way to think of $h(t)$ is that it is just a feature vector like it is in a feed forward neural network but it also contains a \"memory of the past\" via $h(t-1)$\n",
    "\n",
    "we can think of $W_h$ as a weight matrix that tells $h(t)$ which parts of $h(t-1)$ are important to remember and which are not\n",
    "\n",
    "$$x(t) = given$$\n",
    "\n",
    "$$h(t) = \\mathcal{f}\\left(W_i^T x(t) + W_h^T h(t-1) + b_h\\right)$$\n",
    "\n",
    "$$y(t) = softmax \\left(W_o^T h(t) + b_o\\right)$$\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Unrolling an RNN</h4>\n",
    "\n",
    "one way to think of RNNs is to just unroll them in time \n",
    "\n",
    "so if we imagine time going horizontally , and the neural netwok layers growing upwards , then we can unroll a neural network\n",
    "\n",
    "<img src='extras/32.24.PNG'></img>\n",
    "\n",
    "this brings us to an important idea which is that , what if we dont think of the sequence as a sequence in time but rather just a static set of inputs\n",
    "\n",
    "so , lets forget about the fact that this is a sequence for now , and lets pretend we are just going to input a bunch of $x$s into this really stange looking neural network\n",
    "\n",
    "well then we have what is simply a neural network with shared weights\n",
    "\n",
    "so we see that $W_i$ shows up T times (here T = 4) , as well as $W_h$ and $W_o$\n",
    "\n",
    "so it is a specially desined neural network , where the same weights keep repeating over and over again , so we dont have to think of it in terms of time\n",
    "\n",
    "in this case its all happening at the same time , with this weird stange architecture\n",
    "\n",
    "theoretically , these weights can also be hidden weights , such that we did not share the same weights at each stage , and that would also be perfectly fine\n",
    "\n",
    "but its more common is the study of RNNs to keep using the RNNs over and over again\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Feedforward Neural Networks</h4>\n",
    "\n",
    "one question we might have is , well , if we want to classify a sequence , why cant we jsut input this sequence into the neural network , why do we need this special architecture ?\n",
    "\n",
    "as an example suppose we have inputs [x(1),x(2),x(3),x(4)] (here we assume T=4)\n",
    "\n",
    "but instead of putting this through an RNN , we just concatenate all the $x$s into one big vector of size $TD$\n",
    "\n",
    "similarly , we create T diiferent $h$s and $T$ different $y$s , so that we have all the same variables we had before , except now thay are all concatenated together\n",
    "\n",
    "<img src='extras/32.25.PNG' width='300'></img>\n",
    "\n",
    "at the end we can just unconcatenate the outputs to get back each of the individual $y$s and $h$s (if we need them)\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Numerical Calculation (feedforward)</h4>\n",
    "\n",
    "well lets look at what happens if we do this (use ANN)\n",
    "\n",
    "<ul>\n",
    "    <li>Suppose<ul>\n",
    "    <li>T = 20 (so every sequence is of length 20)</li>\n",
    "    <li>D = 10 (input dimensionality)</li>\n",
    "    <li>M = 15 (hidden layer size)</li>\n",
    "    <li>K = 3 (number of output classes)</li>\n",
    "</ul></li>\n",
    "    <li>Input to hidden weight will be of size TxDxTxM = 60,000 parameters</li>\n",
    "    <li>Hidden to output weight is of size TxMxTxK = 18,000 parameters</li>\n",
    "    <li>Total : 78,000 parameters , not counting the bias terms</li>\n",
    "</ul>\n",
    "\n",
    "so this is a really big fat neural network\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Numerical Calculation (RNN)</h4>\n",
    "\n",
    "Now lets look at what happens if we had used an RNN\n",
    "\n",
    "<ul>\n",
    "    <li>Suppose<ul>\n",
    "    <li>T = 20 (so every sequence is of length 20)</li>\n",
    "    <li>D = 10 (input dimensionality)</li>\n",
    "    <li>M = 15 (hidden layer size)</li>\n",
    "    <li>K = 3 (number of output classes)</li>\n",
    "</ul></li>\n",
    "    <li>Input to hidden : DxM = 10x15 = 150</li>\n",
    "    <li>Hidden to Hidden : MxM = 15x15=225</li>\n",
    "    <li>Hidden to output 15x3 = 45</li>\n",
    "    <li>Total = 420 parameters !</li>\n",
    "</ul>\n",
    "\n",
    "---\n",
    "\n",
    "now we remember that we looked at the idea that a feedforward neural network is capable of approximating any function\n",
    "\n",
    "so the feedforward neural network is the most general function approximator\n",
    "\n",
    "so in theory , we actually have no need for RNNs since hte ANNs should work just fine\n",
    "\n",
    "we even have a mathematical proof that it should work\n",
    "\n",
    "unfortunately , as promising as that sounds , they dont work that well in practice\n",
    "\n",
    "the reason is that they are over parameterised , in other words there are too many parameters\n",
    "\n",
    "further there is no structure , so we just have tons of weights where everything is connected to everything which makes the model very flexible but incapable of learning anything\n",
    "\n",
    "so with RNNs we have structure , we are taking into account the structure of the data , which allows us to have a fraction of the weights and allows us to use the weights we do have in a more intelligent way\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Another Problem</h4>\n",
    "\n",
    "there is also a big problem with the feedforward neural network (other than the fact that it has too many parameters) , which is that the input has to be constant size\n",
    "\n",
    "thats not really very effective in reality since we can easily think of sequences that dont have context size \n",
    "\n",
    "for example sentences , or an audi signal of someone saying words , some sentences are longer than others , number of words in a document \n",
    "\n",
    "so Most problems in NLP deal with variable length sequences\n",
    "\n",
    "<img src='extras/32.26.PNG' width='300'></img>\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Variable Length Sequences</h4>\n",
    "\n",
    "The reason we bring up the idea of variable length sequences is because in deep learning dealing with them is actually hard\n",
    "\n",
    "RNN cells in Tensorflow (Keras) require constant-length sequences\n",
    "\n",
    "Advantages:\n",
    "\n",
    "<ul>\n",
    "    <li>Easier to represent data , since data is always rectangulary shaped NxTxD</li>\n",
    "    <li>N : number of samples , T : sequence length , D : input feature dimension</li>\n",
    "    <li>Easier to store data in a numpy array , since numpy arrays dont work when we have multiple length sequences (T is not constant)</li>\n",
    "    <li>if T is not constant , we must use list</li>\n",
    "    <li>numpy arrays are superiror since we can do batch operations instead of looping over everything</li>\n",
    "    <li>Easier to write code</li>\n",
    "</ul>\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Disadvantages</h4>\n",
    "\n",
    "Despite the advantages of having constant length , there is still one big dis-advantage with this method\n",
    "\n",
    "that is we have to choose T\n",
    " \n",
    "sometimes we can choose T simply based on the maximum length sequence in our training set\n",
    "\n",
    "but there are two major problem with that :\n",
    "\n",
    "<ul>\n",
    "    <li>If there is a sequence in our test set that is longer , then our network wont be able to handle it , we will be forced to cut parts of the neural network to make it fit into the neural network (will need to truncate it)</li>\n",
    "    <li>now all sequences will be forced to have the same length as the maximum length sequence</li>\n",
    "    <li>we can imagine that very long sentences are rare , so we might have a few sentences that are 50 words long but most sentences are maybe 5-10 words long , whats the result ?</li>\n",
    "    <li>The result is that even though a sentence takes up only 5 words , we still need an array of size 50 to represent it</li>\n",
    "    <li>that array is going to contain 45 0s , that means that we have to do 45 matrix multiplications that we dont have to do</li>\n",
    "    <li>thats a lot of extra work , and a lot of extra processing time , just to multiply lots of 0s specially since very long sentences are so rare</li>\n",
    "    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now for a review of GRUs and LSTMs\n",
    "\n",
    "---\n",
    "\n",
    "<h4>GRU</h4>\n",
    "\n",
    "GRU : Gated Recurrent unit\n",
    "\n",
    "This introduces the concept of gates which allow the hidden layer to remember or forget certain values\n",
    "\n",
    "here is a diagram (pretty much useless)\n",
    "\n",
    "<img src='extras/32.27.PNG' width ='300'></img>\n",
    "\n",
    "and here are the equations :) \n",
    "\n",
    "$$Update \\ gate \\ : z_t = \\sigma \\left(W_{xz}^{\\ T}x_t + W_{hz}h_{t-1} + b_z\\right)$$\n",
    "\n",
    "$$Reset \\ gate \\ : \\ r_t = \\sigma \\left(W_{xr}^{\\ T}x_t + W_{hr}^{\\ T}h_{t-1} + b_r\\right)$$\n",
    "\n",
    "$$Candidate \\ state : \\hat h_t = \\tanh \\left(W_{xh}^{\\ T}x_t + W_{hh}^{\\ T} \\left(r \\circ h_{t-1}\\right) + b_h\\right)$$\n",
    "\n",
    "$$Next \\ state : h_t = \\left(1-z_t\\right) \\circ h_{t-1} + z_t \\circ \\hat h_t$$\n",
    "\n",
    "note : here we use $\\circ$ t odenote element-wise multiplication\n",
    "\n",
    "with the GRU we have two gates , we call $z_t$ the reset gate , and we call $r_t$ the update gate\n",
    "\n",
    "lets consider $r_t \\circ h_{t-1}$ in the Candidate state\n",
    "\n",
    "$$Candidate \\ state : \\hat h_t = \\tanh \\left(W_{xh}^{\\ T}x_t + W_{hh}^{\\ T} \\left(\\boxed{r \\circ h_{t-1}}\\right) + b_h\\right)$$\n",
    "\n",
    "since $r_t$ is the output of a sigmoid , it contains only values between 0 and 1\n",
    "\n",
    "so if we have something closer to 0 , that tells us forget about what was in this cell of $h_{t-1}$ , forget what was there by making it closer to 0\n",
    "\n",
    "if it is closer to 1 , that is saying remember what was in that cell of $h_{t-1}$ and that value is important to remember\n",
    "\n",
    "so its sort of a binary mask , but instead of only binary values 0 and 1 , there is a spectrum between 0 and 1 where we have different degrees of remembering and forgetting\n",
    "\n",
    "we then use $x_t$ and $h_{t-1}$ to create a candidate value for $h_t$ which we will call $\\hat h_t$\n",
    "\n",
    "$$Candidate \\ state : \\hat h_t = \\tanh \\left(W_{xh}^{\\ T}\\boxed{x_t} + W_{hh}^{\\ T} \\left(r \\circ \\boxed{h_{t-1}}\\right) + b_h\\right)$$\n",
    "\n",
    "In a simple RNN that would be it , we would set that to $h_t$ and we are done \n",
    "\n",
    "notice how the equation for $\\hat h_t$ is very similar to the equation of $h_t$ in a simple recurrent unit except for the reset gate\n",
    "\n",
    "But in the GRU we have yet another gate , $z_t$\n",
    "\n",
    "this tells us how much of the candidate $h_t$ do we want to keep and how much of the old $h_{t-1}$ do we want to keep\n",
    "\n",
    "notice how we multiply by $z_t$ or $1-z_t$ so we are always getting the weighted average of these 2 to create the new $h_t$\n",
    "\n",
    "this also has a sort of rememberring and forgetting function , so if $z_t$ is very small then $(1-z_t)$ is bigger , closer to 1 , so thats like saying remember what was in $h_{t-1}$ before , otherwise if $z_t$ is close to 1 , then its saying take more of what is in $\\hat h_t$\n",
    "\n",
    "and by having these remembering and forgetting functions , we can make the neural network learn long term dependencies \n",
    "\n",
    "---\n",
    "\n",
    "<h4>Systems of Neural Networks</h4>\n",
    "\n",
    "one convineat way of conceptualising a GRU/LSTM is that they are really just a mini-system of neural networks\n",
    "\n",
    "so the Update gate is made of a mini-binary classification neural network\n",
    "\n",
    "the reset gate has a similar format , it is just a mini-binary classification neural network , actually they are jsut logistic regressions , which is even simpler\n",
    "\n",
    "the prediction for the Hidden state is itself the output of a mini-neural network \n",
    "\n",
    "so basically we just have these mini-neural networks or neurons everywhere and they are all making their own little predictions about what the hidde nstate should be , how much to remember or forget and so on\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Concatenation Trick</h4>\n",
    "\n",
    "One cool trick we can do for convenience is that we see how $x_t$ and $h_{t-1}$ appear very often , these equations are also quite long\n",
    "\n",
    "so what we can do when we are implementing them is , just concatenate $x_t$ and $h_{t-1}$ together into one big vector of size M+D and then create a giant weight matrix of size Mx(M+D) so that we only have one matrix multiply to do\n",
    "\n",
    "<img src='extras/32.28.PNG' width=\"600\"></img>\n",
    "\n",
    "we can verify that we have the same number of parameters , just things are easier to write this way\n",
    "\n",
    "our equations then become :\n",
    "\n",
    "$$Update \\ gate : z_t = \\sigma \\left(W_z^{\\ T}[x_t,h_{t-1}]+bz\\right)$$\n",
    "\n",
    "$$Reset \\ gate : r_t = \\sigma \\left(W_r^T [x_t,h_{t-1}] + b_r\\right)$$\n",
    "\n",
    "$$Candidate \\ state : \\hat h_t = \\tanh \\left(W_h^{\\ T}[x_t,(r_t \\circ h_{t-1})] + b_h\\right)$$\n",
    "\n",
    "$$Next \\ state : h_t = (1-z_t) \\circ h_{t-1} + z_t \\circ \\hat h_t$$  \n",
    "\n",
    "---\n",
    "\n",
    "<h4>LSTM</h4>\n",
    "\n",
    "here is the useless diagram :\n",
    "\n",
    "<img src='extras/32.29.PNG' width='300'></img>\n",
    "\n",
    "what we can still get out of this diagram is that the LSTM haas 2 states , $C_t$ and $h_t$\n",
    "\n",
    "we typically call $h$ the hidden state , hence the letter h , and we call $C$ the cell state , hence the letter C\n",
    "\n",
    "---\n",
    "\n",
    "so in an LSTM we basically have a gate for everything , importantly we now have two state vectors , $c_t$ and $h_t$\n",
    "\n",
    "$c_t$ kind of takes on $h_t$ old role and $h_t$ is now jsut a small modification on $c_t$\n",
    "\n",
    "here are the equations :\n",
    "\n",
    "$$Forget \\ gate : f = \\sigma \\left(W_{f}^{\\ T} [x_t,h_{t-1}] + b_f\\right)$$\n",
    "\n",
    "$$Input \\ gate : i_t = \\sigma \\left(W_i^T [x_t,h_{t-1}] + b_i\\right)$$\n",
    "\n",
    "$$Output \\ gate : o_t = \\sigma \\left(W_o^T [x_t,h_{t-1}] + b_o\\right)$$\n",
    "\n",
    "$$Candidate \\ cell : \\tilde c_t = \\tanh \\left(W_c^T [x_t,h_{t-1}] + b_c\\right)$$\n",
    "\n",
    "$$Cell \\ state : c_t = f_t \\circ c_{t-1} + i_t \\circ \\tilde c_t$$\n",
    "\n",
    "$$Hidden \\ state : h_t = o_t \\circ \\tanh(c_t)$$\n",
    "\n",
    "---\n",
    "\n",
    "the input gate tells us us how much of the candidate $\\tilde c_t$ to keep , the forget gate tells us how much of the previous cell state $c_{t-1}$ to keep\n",
    "\n",
    "$$Cell \\ state : c_t = \\boxed{f_t \\circ c_{t-1}} + \\boxed {i_t \\circ \\tilde c_t}$$\n",
    "\n",
    "note that in the GRU , $z_t$ performs both of these roles , in the LSTM forget and input are seperate gates (recall in the GRU we just had $z_t$ and $(1-z_t)$ )\n",
    "\n",
    "finally the output gate just tells us how much of the cell to pass on to the output\n",
    "\n",
    "$$Hidden \\ state : h_t = \\boxed{o_t \\circ \\tanh(c_t)}$$\n",
    "\n",
    "note : sometimes we call $c_t$ the cell not to be confused with other uses of the word cell such as an element of a table or an element of a vector which is terminology we have used before\n",
    "\n",
    "---\n",
    "\n",
    "<h4>In Keras</h4>\n",
    "\n",
    "Normally , each layer outputs one thing :\n",
    "\n",
    "```output = Dense(128)(input)```\n",
    "\n",
    "with recurrent units , we actually have the option to output the hidden states as well , in order to get the GRU and the LSTM to output the states we pass in the argument ```return_state=True``` \n",
    "\n",
    "so as per what we just discussed , the GRU will output that layers output along with the hidden state h\n",
    "\n",
    "```output,h = GRU(128,return_state=True)(input)```\n",
    "\n",
    "but the LSTM will output that layer's output along with the hidden state h and the cell state c\n",
    "\n",
    "```output,h,c = LSTM(128,return_state=True)(input)```\n",
    "\n",
    "one question we might as k is , what is the difference between a recurrent layer's output and its hidden state h , the answer is surprisingly is that they are not different , they actually output the same thing\n",
    "\n",
    "---\n",
    "\n",
    "<h4>return_sequences</h4>\n",
    "\n",
    "one exception is that if we pass yet another argument , ```return_sequences=True```\n",
    "\n",
    "if we do this then we will get a sequence of output values but the hidden state and cell state will still only give us the final value\n",
    "\n",
    "```output,h,c = LSTM(128,return_state=True,return_sequences=True)(input)```\n",
    "\n",
    "so here output is a sequence , but h and c are not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will be looking at the different types of problems an RNN can solve\n",
    "\n",
    "The general theme of this section is <strong>shapes</strong>\n",
    "\n",
    "<img src='extras/32.30.PNG' width='400'></img>\n",
    "\n",
    "as we know, when we are talking about deep learning, this is a very important topic\n",
    "\n",
    "we always want to keep track of the shape of everything in our neural network\n",
    "\n",
    "once we know the shape of something, the visualisation of it becomes implicit\n",
    "\n",
    "the reason people often ask for pictures, is because they dont have a good visualistaion system\n",
    "\n",
    "If we say a word like \"rectangle\" or \"square\" we should be able to picture that in our head immediately\n",
    "\n",
    "so if we are not a very geometrical person, we should excercise these abilities since they are very helpful in deep learning\n",
    "\n",
    "so if we say something like, this data is 2x3 a picture of that should pop-up in our head even if we are not shown one\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Types of RNN task</h3>\n",
    "\n",
    "So when we talk about different types of tasks that an RNN can solve, we are not talking about different applications, although we will be looking at several simple examples\n",
    "\n",
    "So we dont mean an RNN can be used for machine translation, or it can be used to build a Question Answering System, or whatever\n",
    "\n",
    "what we mean is, given an input of some shape, what kinds of shapes can we get at the output ?\n",
    "\n",
    "---\n",
    "\n",
    "<h3>RNN Input</h3>\n",
    "\n",
    "lets first talk about, what is the shape of an RNN input ?\n",
    "\n",
    "we will be saying this again and again , $T \\times D$\n",
    "\n",
    "so what is $T$ and what is $D$ ?\n",
    "\n",
    "$T$ : is the sequence length\n",
    "\n",
    "$D$ : is the vector dimensionality\n",
    "\n",
    "so as an example, lets suppose we have a short sentence :\n",
    "\n",
    "\"The quick brown fox jumps\"\n",
    "\n",
    "5 words, so $T = 5$\n",
    "\n",
    "now what happens to these words ?\n",
    "\n",
    "well good thing we reviewed this, the first thing we always do when we put words into a neural network is what ?\n",
    "\n",
    "word embeddings is the correct answer\n",
    "\n",
    "ok, so each word becomes a word vector\n",
    "\n",
    "since we had 5 words, that going to give us 5 word vectors\n",
    "\n",
    "suppose our word vectors are of size 50, so $D=50$\n",
    "\n",
    "we saw this in our CNN example earlier where we got to choose $D$, in the case where we are using pre-trained embeddings then we have limited selection, we have to choose whatever the authors give us\n",
    "\n",
    "so lets say we choose $D=50$\n",
    "\n",
    "Then we have 5 word vectors, each of them of size 50\n",
    "\n",
    "so our input is $5 \\times 50$\n",
    "\n",
    "<img src='extras/32.31.PNG' width='400'></img>\n",
    "\n",
    "one we have this sequence of words, we can pass it through any RNN unit, such as a GRU or an LSTM or any simple recurrent unit\n",
    "\n",
    "---\n",
    "\n",
    "Lets think of another situation where we might have a sequence of vectors\n",
    "\n",
    "suppose we want to track the weather at several locations over time\n",
    "\n",
    "so we pick 10 different locations, and every hour, we record the temperature at each location\n",
    "\n",
    "lets say we do this for an entire day\n",
    "\n",
    "so what does this give me ?\n",
    "\n",
    "well at each point of time, we have 10 different temperatures corresponding to the 10 different locations\n",
    "\n",
    "that means in this case, $D = 10$\n",
    "\n",
    "since there are 24 hours in a day, that means we have recorded a sequence of 24 observations , so $T = 24$\n",
    "\n",
    "Therefore, our data would be of size $24 \\times 10$\n",
    "\n",
    "---\n",
    "\n",
    "The important thing to notice that, in either of these situations, whether we are measuring the weather or looking at setnences, the result we get is a $T \\times D$ input signal into our RNN\n",
    "\n",
    "---\n",
    "\n",
    "<h3>RNN output</h3>\n",
    "\n",
    "so now lets say, we take our input, whatever it is, and we pass it through an RNN\n",
    "\n",
    "well we know that, for each input $x(t)$, we can calculate the hidden state $h(t)$ and the output prediction $y(t)$\n",
    "\n",
    "the question now is, what is the meaning of $y(t)$ ?\n",
    "\n",
    "In this section, we want to focus on the different types of tasks an RNN can do, so the meaning of $y(t)$ is particularly important\n",
    "\n",
    "as an example, suppose we are doing spam classification, given the text in an email, we would like to know, is this email spam or not ?\n",
    "\n",
    "<img src='extras/32.32.PNG' width='400'></img>\n",
    "\n",
    "(we will look at this specific example later)\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Spam Classification</h3>\n",
    "\n",
    "So suppose we have an input email containing 100 words, that means we will end up with a sequence of 100 word vectors $x_1,x_2,\\ldots,x_{100}$\n",
    "\n",
    "for each of these, we can calculate $y_1,y_2,\\ldots,y_{100}$\n",
    "\n",
    "the big question here is, whoch of these $y$s do we care about ?\n",
    "\n",
    "Remember that we have only one question which has a Yes\\no answer , is this email spam or not ?\n",
    "\n",
    "So it makes sense then to take $y_{100}$ as our answer since only $y_{100}$ has seen the entire email\n",
    "\n",
    "if we look at some eariler outputs, say $y_{50}$ that means we have only read half the email which may not be enough\n",
    "\n",
    "---\n",
    "\n",
    "In fact, if we draw this out in a diagram, basically we see that what we can do is ignore all of the $h(t)$s except $h(100)$ and only calculate $y(100)$\n",
    "\n",
    "<img src='extras/32.33.PNG' width='400'></img>\n",
    "\n",
    "remember that this is easy to accomplish in keras, we just pass in ```return_sequences = False```, and this automatically only returns the last RNN output\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Fancy method</h3>\n",
    "\n",
    "There is actually an even fancier way to get just one output for an RNN, instead of considering an entire sequence of outputs, and this is something we are going to look at in the code\n",
    "\n",
    "The answer is something we saw earlier when we looked at CNNs, which was Global Max Pooling\n",
    "\n",
    "remember that this looks at a sequence of numbers, and regardless of its length, just returns the maximum value\n",
    "\n",
    "<img src='extras/32.34.PNG' width='400'></img>\n",
    "\n",
    "so this can be useful in spam classification, since maybe a very obvious spam word appears in the middle of an email or even near the beginning\n",
    "\n",
    "for example, if an email starts with \"Hi, I am a Nigerian Prince...\", well we know thats probably going to be spam, we dont need to read to the end of the email to know that\n",
    "\n",
    "and what might happen is, if we did read the whole email, we might end up losing that information by the time we got to the end\n",
    "\n",
    "we claim that LSTMs are good at learning long-term dependencies, but there is still a limit\n",
    "\n",
    "this appears in machine translation and all types of tasks, basically LSTMs are still better at processing short sequences than they are at very long sequences\n",
    "\n",
    "so in any case, global max pooling allows us to consider all the $h(t)$s but still only get one output\n",
    "\n",
    "we dont have to choose the last one since that might not be the best one\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Back to shapes</h3>\n",
    "\n",
    "so it makes sense to take only one $y$ as our output prediction\n",
    "\n",
    "and since the theme of this section is shapes, and we are talking about classification, then supposing we have $K$ classes, our output will be of size $K$\n",
    "\n",
    "<img src='extras/32.35.PNG' width='300'></img>\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Parts-of-Speech Tagging</h3>\n",
    "\n",
    "now lets consider a slightly more complex problem\n",
    "\n",
    "this one is also NLP-related, and its called Parts-of-Speech Tagging, which is something we studied before several times\n",
    "\n",
    "remember that POS Tagging classifies a word into something like noun,verb,adjective,...\n",
    "\n",
    "So why are RNNs a good model for this task ?\n",
    "\n",
    "well it has to do with the fact that some words are ambiguous\n",
    "\n",
    "so we cant say that \"milk\" is definetly a noun or definetly a verb because the word \"milk\" can be either\n",
    "\n",
    "<ul>\n",
    "    <li>\"I went to the grocery store I bough milk today\" $\\leftarrow$ \"milk\" is a noun</li>\n",
    "    <li>\"The thief wanted to milk her victims out of their savings\" $\\leftarrow$ \"milk\" is a verb</li>\n",
    "</ul>\n",
    "\n",
    "so and RNN is important for that problem, because it has to take into account the other words of the sentence\n",
    "\n",
    "---\n",
    "\n",
    "The other important part of the Parts-of-Speech Tagging problem is that we need to make a prediction for every word we see\n",
    "\n",
    "so this is not like spam classification, where we just make one prediction for the entire sequence\n",
    "\n",
    "each word of the sentence will have a corresponding parts-of-speech tag\n",
    "\n",
    "so in this case, if we have $x_1,\\ldots,x_{100}$, then we must also have $y_1,\\ldots,y_{100}$\n",
    "\n",
    "each of those $y$s is going to represent the predicted parts-of-speech tag for the corresponding word\n",
    "\n",
    "<img src='extras/32.36.PNG' width='800'></img>\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Back to shapes</h3>\n",
    "\n",
    "lets again return to this idea of shapes\n",
    "\n",
    "in this case, both our input and our output are of length $T$\n",
    "\n",
    "But the input has $D$ dimensions, so its shape is $TxD$\n",
    "\n",
    "if there are $K$ output classes, then the shape of the output will be $T \\times K$\n",
    "\n",
    "<img src='extras/32.37.PNG' width='300'></img>\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Machine Translation</h3>\n",
    "\n",
    "Lets think of another example, where we dont just have one output, but many\n",
    "\n",
    "This one is very popular in NLP and is something we will be looking at later, that is Machine Translation\n",
    "\n",
    "so for example, we have an input sentence in English, and then we predict an output sentence in Japanese\n",
    "\n",
    "<img src='extras/32.38.PNG' width='500'></img>\n",
    "\n",
    "we might see right away that there is a problem with this approach however, its that if we pass in 100 words in english, its most certainly not the case that the japanse translation also has 100 words\n",
    "\n",
    "so how do we deal with the situation where the input sequence length is different from the output sequence length ?\n",
    "\n",
    "well one strategy is to do something we have already talked about, thats just to pad all our sequences to be much longer than our data, so that all our data fits into the RNN\n",
    "\n",
    "This allows us to have an input that is of different length than the output since they can just have variable amounts of padding\n",
    "\n",
    "however, there is an even better approach than this, and that's something we will be talking about later\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Back to shapes</h3>\n",
    "\n",
    "so how can we think of the shapes if the input length and the output length and the output length are different\n",
    "\n",
    "in this case we usually call the shape of the input $T_x \\times D$, and we call the shape of the output $T_y \\times K$\n",
    "\n",
    "so the length of the input is $T_x$ and the length of the output is $T_y$\n",
    "\n",
    "<img src='extras/32.39.PNG' width='300'></img>\n",
    "\n",
    "---\n",
    "\n",
    "<h3>Categories of Tasks</h3>\n",
    "\n",
    "so looking at these tasks allows us to categorise each type of tasks\n",
    "\n",
    "<img src='extras/32.40.PNG' width='700'></img>\n",
    "\n",
    "<ul>\n",
    "    <li>we can think of a regular feed-forward neural network as a one to one task</li>\n",
    "    <ul>\n",
    "        <li>we have one input and we get one output\n",
    "</li>\n",
    "        <li>for example we pass in an image, and we get what object is in that image</li>\n",
    "    </ul>\n",
    "    <li>we can think of things as like spam classification and sentiment classification as many to one\n",
    "</li>\n",
    "    <ul>\n",
    "        <li>the input sequence contains many things, but the output is just one thing</li>\n",
    "    </ul>\n",
    "    <li>We can think of tasks like POS tagging and Machine translation as many to many</li>\n",
    "    <ul>\n",
    "        <li>The input is a sequence of many things, and the output is also a sequence of many things</li>\n",
    "        <li>note how there are two different types of many to many here</li>\n",
    "        <ul>\n",
    "            <li>one of these, which we already talked about, is where the input sequence length is the same as the output sequence length</li>\n",
    "            <li>but there is another type of many to many that we will be looking at later</li>\n",
    "        </ul>\n",
    "    </ul>\n",
    "    <li>There is also a concept of one to many which we will see later on, but in general we can think of this as text generation </li>\n",
    "    <ul>\n",
    "        <li>We have looked at this in the past, where we did thigs like generate poetry</li>\n",
    "    </ul>\n",
    "</ul>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>code</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is an example to help us understand the shape of everything\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input,LSTM,GRU\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 8 # sequence length\n",
    "D = 2 # input dimensionality\n",
    "M = 3 # hidden layer size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next lets create some dummy input data\n",
    "# just one sample of size (TxD)\n",
    "# we can think of this as a single sentence of word vectors\n",
    "X = np.random.randn(1,T,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o [[-0.0974059   0.0730459   0.01771228]]\n",
      "h [[-0.0974059   0.0730459   0.01771228]]\n",
      "c [[-0.17349625  0.16124561  0.03740309]]\n"
     ]
    }
   ],
   "source": [
    "# next we have our first experiment\n",
    "i = Input(shape=(T,D))\n",
    "x = LSTM(M,return_state=True)(i)\n",
    "\n",
    "model = Model(i,x)\n",
    "\n",
    "# now we capture three outputs , o,h,c\n",
    "# o : actual output from LSTM \n",
    "# h : hidden state , same as o\n",
    "# c : cell state\n",
    "o,h,c = model.predict(X)\n",
    "print('o',o)\n",
    "print('h',h)\n",
    "print('c',c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o [[[ 0.07153962  0.08506     0.21476986]\n",
      "  [-0.19892992 -0.13391218 -0.0966043 ]\n",
      "  [-0.12303185 -0.14212097  0.01647807]\n",
      "  [ 0.01555805 -0.03163124  0.23405011]\n",
      "  [ 0.10796213  0.06940186  0.26995882]\n",
      "  [ 0.10736642  0.07418838  0.19604875]\n",
      "  [ 0.07511207 -0.05569559 -0.03729638]\n",
      "  [ 0.10174719 -0.01145611  0.07957759]]]\n",
      "h [[ 0.10174719 -0.01145611  0.07957759]]\n",
      "c [[ 0.19351314 -0.02114321  0.1362746 ]]\n"
     ]
    }
   ],
   "source": [
    "# in our second LSTM experiment we pass retur_sequences=True\n",
    "i = Input(shape=(T,D))\n",
    "x = LSTM(M,return_state=True,return_sequences=True)(i)\n",
    "\n",
    "model = Model(i,x)\n",
    "\n",
    "o,h,c = model.predict(X)\n",
    "# h and c are same as before\n",
    "# o is a list of all hidden states \n",
    "# so we see 8 lists (T) each of size 3 (M)\n",
    "print('o',o)\n",
    "print('h',h)\n",
    "print('c',c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o [[-0.04380884  0.05802852  0.14173822]]\n",
      "h [[-0.04380884  0.05802852  0.14173822]]\n"
     ]
    }
   ],
   "source": [
    "# next is an experiment for the GRU\n",
    "i = Input(shape=(T,D))\n",
    "x = GRU(M,return_state=True)(i)\n",
    "\n",
    "model = Model(i,x)\n",
    "\n",
    "# since GRU has only one state h only two things are returned\n",
    "# again both o and h are the same\n",
    "o,h = model.predict(X)\n",
    "\n",
    "print('o',o)\n",
    "print('h',h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o [[[ 0.11554503  0.13384068 -0.16903783]\n",
      "  [ 0.06451906 -0.68656206  0.6032783 ]\n",
      "  [ 0.22957173 -0.26279095  0.18927789]\n",
      "  [ 0.27256823  0.06068474 -0.04105842]\n",
      "  [ 0.14097208  0.24028166 -0.15049753]\n",
      "  [ 0.03591045  0.1597526  -0.10280327]\n",
      "  [-0.09302896  0.14200236  0.20374927]\n",
      "  [ 0.01353341  0.11905333 -0.00562129]]]\n",
      "h [[ 0.01353341  0.11905333 -0.00562129]]\n"
     ]
    }
   ],
   "source": [
    "# pass return_sequences = True\n",
    "i = Input(shape=(T,D))\n",
    "x = GRU(M,return_state=True,return_sequences=True)(i)\n",
    "\n",
    "model = Model(i,x)\n",
    "\n",
    "o,h = model.predict(X)\n",
    "\n",
    "print('o',o)\n",
    "print('h',h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>code</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the same as the CNN example\n",
    "# except that this time we use LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense,Input,LSTM,GlobalMaxPool1D,Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_VOCAB_SIZE = 20000\n",
    "EMBEDDING_DIM = 100 # we will be using GloVe [50,100,200,300]\n",
    "VALIDATION_SPLIT = 0.2\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10\n",
    "M = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first lets load in data and take a look at it\n",
    "data = pd.read_csv('datasets/toxic comments/train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we have a multilabel classification problem\n",
    "X = data['comment_text'].to_numpy()\n",
    "Y = data.iloc[:,2:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next lets tokenise our sentences\n",
    "tokeniser = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "tokeniser.fit_on_texts(X)\n",
    "X = tokeniser.texts_to_sequences(X)\n",
    "\n",
    "word2idx = tokeniser.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next we pad our sentences\n",
    "X = pad_sequences(X,maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next we want to create our embedding matrix\n",
    "# first we load in the pre trained word vectors\n",
    "file = 'datasets/glove/glove.6B.'+str(EMBEDDING_DIM)+'d.txt'\n",
    "word2vec = {}\n",
    "for line in open(file,encoding='utf8'):\n",
    "    line = line.split()\n",
    "    word = line[0]\n",
    "    vec = line[1:]\n",
    "    vec = np.array(vec).astype('float32')\n",
    "    word2vec[word] = vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = min(len(word2idx)+1,MAX_VOCAB_SIZE)\n",
    "# now lets create our embedding matrix\n",
    "embedding = np.zeros((V,EMBEDDING_DIM))\n",
    "\n",
    "# now we fill the matrix with the pretrained word embeddings\n",
    "# if a word is not in our pretrained vectors , we leave it as zeros\n",
    "\n",
    "for word,idx in word2idx.items():\n",
    "    vec = word2vec.get(word,0)\n",
    "    if idx < V:\n",
    "        embedding[idx] = vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(\n",
    "    V,\n",
    "    EMBEDDING_DIM,\n",
    "    weights = [embedding],\n",
    "    input_length=MAX_SEQUENCE_LENGTH,\n",
    "    trainable = False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we are ready to build our model !\n",
    "# Input shape now is NxT\n",
    "# so at each time step we have index of a word\n",
    "i = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "x = embedding_layer(i) # NxTxD\n",
    "x = LSTM(M,return_sequences=True)(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(128,activation='relu')(x)\n",
    "# we are doing 6 seperate binary classifications\n",
    "o = Dense(Y.shape[1],activation='sigmoid')(x)\n",
    "\n",
    "model = Model(i,o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='rmsprop',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "998/998 [==============================] - 43s 40ms/step - loss: 0.1342 - accuracy: 0.8344 - val_loss: 0.0626 - val_accuracy: 0.9941\n",
      "Epoch 2/10\n",
      "998/998 [==============================] - 38s 38ms/step - loss: 0.0582 - accuracy: 0.9941 - val_loss: 0.0569 - val_accuracy: 0.9941\n",
      "Epoch 3/10\n",
      "998/998 [==============================] - 40s 40ms/step - loss: 0.0552 - accuracy: 0.9940 - val_loss: 0.0553 - val_accuracy: 0.9941\n",
      "Epoch 4/10\n",
      "998/998 [==============================] - 40s 40ms/step - loss: 0.0533 - accuracy: 0.9942 - val_loss: 0.0548 - val_accuracy: 0.9941\n",
      "Epoch 5/10\n",
      "998/998 [==============================] - 39s 39ms/step - loss: 0.0519 - accuracy: 0.9920 - val_loss: 0.0550 - val_accuracy: 0.9941\n",
      "Epoch 6/10\n",
      "998/998 [==============================] - 40s 40ms/step - loss: 0.0507 - accuracy: 0.9942 - val_loss: 0.0533 - val_accuracy: 0.9941\n",
      "Epoch 7/10\n",
      "998/998 [==============================] - 40s 40ms/step - loss: 0.0500 - accuracy: 0.9940 - val_loss: 0.0524 - val_accuracy: 0.9941\n",
      "Epoch 8/10\n",
      "998/998 [==============================] - 39s 40ms/step - loss: 0.0491 - accuracy: 0.9937 - val_loss: 0.0545 - val_accuracy: 0.9939\n",
      "Epoch 9/10\n",
      "998/998 [==============================] - 40s 40ms/step - loss: 0.0489 - accuracy: 0.9940 - val_loss: 0.0540 - val_accuracy: 0.9941\n",
      "Epoch 10/10\n",
      "998/998 [==============================] - 40s 40ms/step - loss: 0.0484 - accuracy: 0.9944 - val_loss: 0.0527 - val_accuracy: 0.9941\n"
     ]
    }
   ],
   "source": [
    "r = model.fit(\n",
    "    X,Y,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_split = VALIDATION_SPLIT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de3SddZ3v8fc390tzbdOSJmmSllIsRVq6W0BmuMigLTrWy+iAoyDjiIzgjM6sNcOZWefomnM8h+XR48gapgiIgjogMqBVq8gwFmQUbAql9EIhTS9Jk7ZJ2qRt7pfv+eN5kuymabObS3eS/Xmttdfe+3l+z96/vaH7k9/l+T3m7oiISOJJincFREQkPhQAIiIJSgEgIpKgFAAiIglKASAikqBS4l2BczFnzhyvqKiIdzVERKaVLVu2NLl70fDt0yoAKioqqKqqinc1RESmFTPbP9J2dQGJiCQoBYCISIKKKQDMbI2Z7TazajO7Z4T9Zmb3hfu3mdnlUfu+aGY7zGy7mT1uZhnh9i+b2UEz2xrebpq4jyUiIqMZNQDMLBm4H1gLLAVuMbOlw4qtBRaHtzuA9eGxJcBfARF3XwYkAzdHHfcNd18e3jaO98OIiEjsYmkBrAaq3b3G3buBJ4B1w8qsAx7zwMtAvpkVh/tSgEwzSwGygPoJqruIiIxDLAFQAtRGPa8Lt41axt0PAl8DDgANQKu7/yqq3N1hl9EjZlYw0pub2R1mVmVmVY2NjTFUV0REYhFLANgI24YvITpimfBHfR1QCcwHss3sE+H+9cAiYDlBOHx9pDd39wfdPeLukaKi06axiojIGMUSAHVAWdTzUk7vxjlTmT8C9rp7o7v3AE8D7wJw98Pu3ufu/cBDBF1Nk+LXu4/wr5uqJ+vlRUSmpVgCYDOw2MwqzSyNYBB3w7AyG4Bbw9lAVxJ09TQQdP1caWZZZmbADcAugKgxAoAPAdvH+VnO6Hd7mvnn596ms6dvst5CRGTaGTUA3L0XuBt4luDH+0l332Fmd5rZnWGxjUANUE3w1/znwmNfAZ4CXgXeCN/vwfCYr5rZG2a2Dbge+OKEfaphIuUFdPf1s/1g62S9hYjItBPTUhDhFM2Nw7Y9EPXYgbvOcOyXgC+NsP2T51TTcVhZHowvb953jEhF4fl6WxGRKS0hzgSePSudhUXZbNl/NN5VERGZMhIiACDoBqraf4z+fl0DWUQEEikAKgppae9hT+PJeFdFRGRKSJgAWBX2/VftPxbnmoiITA0JEwAVs7OYnZ3G5n0aBxARgQQKADMjUlHAFrUARESABAoAgEh5Ifub2zlyvDPeVRERibvECoCK4HwAjQOIiCRYAFwyP4+M1CSq9ikAREQSKgDSUpK4rDSfKp0QJiKSWAEAwXTQHfXHaevqjXdVRETiKuECYGVFAX39zuu1LfGuiohIXCVcAFy+oACzYGE4EZFElnABkJeZypJ5ORoHEJGEl3ABAMF00Ff3H6O3rz/eVRERiZuEDIBVFYW0dffx5qET8a6KiEjcJGQADFwURstCiEgiS8gAKMnPpDgvQwvDiUhCiykAzGyNme02s2ozu2eE/WZm94X7t5nZ5VH7vmhmO8xsu5k9bmYZ4fZCM3vOzN4O7wsm7mONLlJRSNW+YwRXsxQRSTyjBoCZJQP3A2uBpcAtZrZ0WLG1wOLwdgewPjy2BPgrIOLuy4Bk4ObwmHuA5919MfB8+Py8iZQXcOh4JwdbOs7n24qITBmxtABWA9XuXuPu3cATwLphZdYBj3ngZSDfzIrDfSlAppmlAFlAfdQxj4aPHwU+OI7Pcc4GF4bT+QAikqBiCYASoDbqeV24bdQy7n4Q+BpwAGgAWt39V2GZee7eABDezx3pzc3sDjOrMrOqxsbGGKobm4svyGVWeorOBxCRhBVLANgI24Z3nI9YJuzXXwdUAvOBbDP7xLlU0N0fdPeIu0eKiorO5dCzSk4yVizIVwtARBJWLAFQB5RFPS9lqBtntDJ/BOx190Z37wGeBt4Vljk80E0U3h859+qPz6qKQnYfPkFrR8/5fmsRkbiLJQA2A4vNrNLM0ggGcTcMK7MBuDWcDXQlQVdPA0HXz5VmlmVmBtwA7Io65rbw8W3AT8b5Wc5ZpLwAd3j1gFoBIpJ4Rg0Ad+8F7gaeJfjxftLdd5jZnWZ2Z1hsI1ADVAMPAZ8Lj30FeAp4FXgjfL8Hw2PuBW40s7eBG8Pn59XyBfkkJxlVOh9ARBJQSiyF3H0jwY989LYHoh47cNcZjv0S8KURtjcTtAjiJisthWXzczUOICIJKSHPBI62sryQrbUtdPdqYTgRSSwJHwCrKgro6u1nR31rvKsiInJeJXwArNQJYSKSoBI+AObmZFA+O0sLw4lIwkn4AACIlBeyZb8WhhORxKIAIFgXqLmtm71NbfGuiojIeaMAIBgIBo0DiEhiUQAAC+fMIj8rVQvDiUhCUQAASUlGpLxALQARSSgKgFCkopCapjaaT3bFuyoiIueFAiAUKQ/HAXSheBFJEAqA0KWleaSlJGlhOBFJGAqAUHpKMpeV5qkFICIJQwEQZWV5IdsPttLZ0xfvqoiITDoFQJRVFQX09Dmv17bEuyoiIpNOARBlpQaCRSSBKACi5GelsXjuLC0MJyIJQQEwTKQiWBiuv18Lw4nIzBZTAJjZGjPbbWbVZnbPCPvNzO4L928zs8vD7UvMbGvU7biZfSHc92UzOxi176aJ/WhjEykv4ERnL28dORHvqoiITKpRrwlsZsnA/QQXbq8DNpvZBnffGVVsLbA4vF0BrAeucPfdwPKo1zkIPBN13Dfc/WsT8UEmyqqKQiBYGO7iC3LjXBsRkckTSwtgNVDt7jXu3g08AawbVmYd8JgHXgbyzax4WJkbgD3uvn/ctZ5EZYWZFOWk64QwEZnxYgmAEqA26nlduO1cy9wMPD5s291hl9EjZlYw0pub2R1mVmVmVY2NjTFUd3zMjFUVBWzWwnAiMsPFEgA2wrbhI6RnLWNmacAHgB9F7V8PLCLoImoAvj7Sm7v7g+4ecfdIUVFRDNUdv0h5IQdbOmho7Tgv7yciEg+xBEAdUBb1vBSoP8cya4FX3f3wwAZ3P+zufe7eDzxE0NU0JUR0gRgRSQCxBMBmYLGZVYZ/yd8MbBhWZgNwazgb6Eqg1d0bovbfwrDun2FjBB8Ctp9z7SfJ0uJcstKS2aITwkRkBht1FpC795rZ3cCzQDLwiLvvMLM7w/0PABuBm4BqoB24feB4M8simEH02WEv/VUzW07QVbRvhP1xk5KcxPKyfJ0QJiIz2qgBAODuGwl+5KO3PRD12IG7znBsOzB7hO2fPKeanmeRikL+5T/f5mRXL7PSY/qaRESmFZ0JfAarKgrod3jtgLqBRGRmUgCcwYoFBSQZmg4qIjOWAuAMZqWn8I7iXJ0QJiIzlgLgLCLlBWytbaGnrz/eVRERmXAKgLOIVBTS3t3Hrobj8a6KiMiEUwCchU4IE5GZTAFwFsV5mZTkZ1K1X+MAIjLzKABGMbAwXHCqg4jIzKEAGEWkopDGE13UHtXCcCIysygARjEwDqBlIURkplEAjOKiuTnkZKRQpYXhRGSGUQCMIinJWFleoBPCRGTGUQDEYFVFIW8fOUlLe3e8qyIiMmEUADGIlAfjALo+gIjMJAqAGFxWlk9qsmlhOBGZURQAMchITWZZSR5bdEKYiMwgCoAYRcoLeL22lc6evnhXRURkQigAYhSpKKS7r5/tB1vjXRURkQkRUwCY2Roz221m1WZ2zwj7zczuC/dvM7PLw+1LzGxr1O24mX0h3FdoZs+Z2dvhfcHEfrSJNTAQrPMBRGSmGDUAzCwZuB9YCywFbjGzpcOKrQUWh7c7gPUA7r7b3Ze7+3JgJcEF458Jj7kHeN7dFwPPh8+nrNmz0lk4J1vnA4jIjBFLC2A1UO3uNe7eDTwBrBtWZh3wmAdeBvLNrHhYmRuAPe6+P+qYR8PHjwIfHNMnOI8iFQVs2X+M/n4tDCci018sAVAC1EY9rwu3nWuZm4HHo57Pc/cGgPB+biwVjqdIeSHH2nuoaToZ76qIiIxbLAFgI2wb/ifwWcuYWRrwAeBHsVdt8Ng7zKzKzKoaGxvP9fAJNbQwnMYBRGT6iyUA6oCyqOelQP05llkLvOruh6O2HR7oJgrvj4z05u7+oLtH3D1SVFQUQ3UnT+WcbGZnp+kKYSIyI8QSAJuBxWZWGf4lfzOwYViZDcCt4WygK4HWge6d0C2c2v0zcMxt4ePbgJ+cc+3PM7NwYTidECYiM8CoAeDuvcDdwLPALuBJd99hZnea2Z1hsY1ADVANPAR8buB4M8sCbgSeHvbS9wI3mtnb4f57x/lZzotVFYXsb27nyInOeFdFRGRcUmIp5O4bCX7ko7c9EPXYgbvOcGw7MHuE7c0EM4OmlZXhOMCWfcdYe+nwiU4iItOHzgQ+R8vm55GekqSBYBGZ9hQA5ygtJYnlZflaGE5Epj0FwBhEKgrYXn+c9u7eeFdFRGTMFABjEKkopK/f2XqgJd5VEREZMwXAGFy+oAAzLQwnItObAmAM8jJTWTIvh81aGE5EpjEFwBhFKgp47UALfVoYTkSmKQXAGEXKCznZ1cubh47HuyoiImOiABijgYXhtC6QiExXCoAxKsnPpDgvQwPBIjJtKQDGaHBhOA0Ei8g0pQAYh1UVhTS0dnKwpSPeVREROWcKgHFYOXCheLUCRGQaUgCMw8UX5DArPUXnA4jItKQAGIeU5CRWLMjXTCARmZYUAOMUKS9k9+ETtHb0xLsqIiLnRAEwTqsqCnCH1w6oFSAi04sCYJyWL8gnOcnUDSQi044CYJyy0lK4ZH6uBoJFZNqJKQDMbI2Z7TazajO7Z4T9Zmb3hfu3mdnlUfvyzewpM3vTzHaZ2VXh9i+b2UEz2xrebpq4j3V+RcoLeb2uhe7e/nhXRUQkZqMGgJklA/cDa4GlwC1mtnRYsbXA4vB2B7A+at83gV+6+8XAZcCuqH3fcPfl4e2Ui85PJ5GKAjp7+tlR3xrvqoiIxCyWFsBqoNrda9y9G3gCWDeszDrgMQ+8DOSbWbGZ5QLXAN8GcPdud59xl9GKhCeEbdG6QCIyjcQSACVAbdTzunBbLGUWAo3Ad8zsNTN72Myyo8rdHXYZPWJmBSO9uZndYWZVZlbV2NgYQ3XPv7m5GSwozNI4gIhMK7EEgI2wbfhVUM5UJgW4HFjv7iuANmBgDGE9sAhYDjQAXx/pzd39QXePuHukqKgohurGR6SigKp9x3DXBWJEZHqIJQDqgLKo56VAfYxl6oA6d38l3P4UQSDg7ofdvc/d+4GHCLqapq1VFYU0t3Wzr7k93lUREYlJLAGwGVhsZpVmlgbcDGwYVmYDcGs4G+hKoNXdG9z9EFBrZkvCcjcAOwHMrDjq+A8B28fzQeJtYBxA3UAiMl2kjFbA3XvN7G7gWSAZeMTdd5jZneH+B4CNwE1ANdAO3B71Ep8HfhCGR03Uvq+a2XKCrqJ9wGcn5BPFyaKiWeRnpVK17ygfi5SNfoCISJyNGgAA4RTNjcO2PRD12IG7znDsViAywvZPnlNNp7ikJCNSXqArhInItKEzgSfQyvJCahrbaD7ZFe+qiIiMSgEwgVZV6HwAEZk+FAATaFlJHmnJSeoGEpFpQQEwgTJSk3lnaZ5mAonItKAAmGCRikK2H2yls6cv3lURETmrxAmA83SGbqS8gJ4+5/XaGbfkkYjMMIkRAFsehSc+Dj0dk/5WK8MTwjQOICJTXWIEQF837P4FfO/D0DG5f5kXZKdx4dxZVGkcQESmuMQIgNWfgT95BOo2w3ffBycOTerbraooYMv+Y/T3a2E4EZm6EiMAAJZ9GP7sR3B0L3z7PdC8Z9LeKlJeyPHOXt4+cnLS3kNEZLwSJwAAFl0Pn/opdJ+ER94L9Vsn5W0iFVoYTkSmvsQKAICSlfDnz0JKBnz3/bD3xQl/iwWFWRTlpOuMYBGZ0hIvAADmLIZP/wrySuH7H4Gdw1e3Hh+zYGE4tQBEZCpLzAAAyJ0Pt2+E+SvgR7dB1Xcm9OUjFYXUHevgUGvnhL6uiMhESdwAAMgqhE/+GC68EX72BXjh/07YCWMDC8NV7VcrQESmpsQOAIC0LLj5B/DOm+HX/wt+8ffQ3z/ul31HcS6ZqclU7dM4gIhMTTFdEGbGS06FD66H7Dnwu3+B9ubgeUramF8yNTmJFQvy1QIQkSlLLYABSUnw3q/Ajf8E25+Cx/8UusY3jz9SXsDO+uOc7OqdoEqKiEycmALAzNaY2W4zqzaze0bYb2Z2X7h/m5ldHrUv38yeMrM3zWyXmV0Vbi80s+fM7O3wvmDiPtY4XP3XsO5+qNkEj30A2prH/FKRikL6HV47oG4gEZl6Rg0AM0sG7gfWAkuBW8xs6bBia4HF4e0OYH3Uvm8Cv3T3i4HLgF3h9nuA5919MfB8+HxqWPEJ+NMfwOEdwQljLbVje5kF+SQZGgcQkSkplhbAaqDa3WvcvRt4Alg3rMw64DEPvAzkm1mxmeUC1wDfBnD3bndviTrm0fDxo8AHx/lZJtbFN8EnnoaTR4IQOPLmOb9ETkYqF1+Qq3EAEZmSYgmAEiD6T+C6cFssZRYCjcB3zOw1M3vYzLLDMvPcvQEgvJ870pub2R1mVmVmVY2NjTFUdwJVXB2cK9DfC99ZA7W/P+eXWFVRwGsHWujtG//MIhGRiRRLANgI24ZPlj9TmRTgcmC9u68A2jjHrh53f9DdI+4eKSoqOpdDJ8YFy4KzhjML4LF18PZz53R4pKKQ9u4+djWcmKQKioiMTSwBUAeURT0vBepjLFMH1Ln7K+H2pwgCAeCwmRUDhPdHzq3q51FBRbB+0OwL4fGbYduTMR+qheFEZKqKJQA2A4vNrNLM0oCbgeGL52wAbg1nA10JtLp7g7sfAmrNbElY7gZgZ9Qxt4WPbwN+Mp4PMulmzYVP/RwWXAVPfwZeXj/6MUBxXiYl+ZlaGE5EppxRTwRz914zuxt4FkgGHnH3HWZ2Z7j/AWAjcBNQDbQDt0e9xOeBH4ThURO1717gSTP7NHAA+OjEfKRJlJELf/YUPP0X8Mt7oK0R3v3fwUbqARsSqSjgd3uacXdslLIiIudLTGcCu/tGgh/56G0PRD124K4zHLsViIywvZmgRTC9pGbARx+Fn/8t/ObrQQi87xuQfOavMlJRyE+21lN7tIMFs7POY2VFRM5MS0GMRVIyvP8bkF0EL34V2o/CR74dhMMIoheGUwCIyFShpSDGygze/Y+w9qvw5s+C6wp0to5Y9KK5OeRkpLBZJ4SJyBSiABivKz4b/PVf+wp8531w4vBpRZKSjJXlBWzRCWEiMoUoACbCpX8CH/8hHK2BR94T3A8TKS/grcMnaWnvjkMFRUROpwCYKBfeALdtgM7j8O33QsO2U3ZHKgoBNB1URKYMBcBEKo3An/8SktPgu++DfS8N7rqsNJ/UZNM4gIhMGQqAiVa0BD79LOQUw/c+DLt+BkBmWjIrywt46Dc1/M2TW6k+oqUhRCS+FACTIa80aAkUvxOe/CRsCRY9ve+WFdx2VQUb32jgxm+8yF9+fwtv1I08c0hEZLKZT9BF0M+HSCTiVVVV8a5G7Lrb4Mlbofo/4Ib/AX/wN2BG88kuvvNf+3j0d/s40dnLNRcVcff1F7K6sjDeNRaRGcjMtrj7aSfkKgAmW18P/Phz8MaTcOXn4D1fCS4/CRzv7OF7v9vPIy/tpbmtm1UVBdx1/YVce1GRlowQkQmjAIin/n741T/Cy/8KpavgovdC5XUwfwUkp9DR3ccPNx/gWy/W0NDaySXzc7nr+gtZc8kFJCUpCERkfBQA8eYOmx+GVx+FQ28E29JzofxqWHgtVF5Ld+ESfry1nvUv7GFvUxuLirL5y+suZN3y+aQma7hGRMZGATCVtDXDvheh5gXY+8LQiWPZc6HyGvorr+E/u5bytd938OahE5TkZ3LntQv5aKSMjNTk+NZdRKYdBcBU1lIbBMFAIJwMlpPwggrqC1bzeFMl/3akkqRZRfzFH1byiSvLmZWudfxEJDYKgOnCHRp3DwXCvpegK5gquj91Ic91LGFrymUsuWINn7jmEgqy0+JcYRGZ6hQA01VfLzS8Dns3Qc0L9B94maS+Lno8mTdYRFvJ1Sy7+gMULLkaUtLjXVsRmYIUADNFTyfUvkLzG89xYtd/UNbxJsnmdFs6/aVXkLHk3VB5LRRfFly3QEQSngJghjpQ38CmZ3+M12ziKtvORUl1wY6MfKj4A1h4XRAIcxaPeulKEZmZxhUAZrYG+CbBNYEfdvd7h+23cP9NBNcE/pS7vxru2wecAPqA3oFKmNmXgc8AjeHL/EN46ckzUgCc2aHWTh7+TQ3PvrKNFX3b+NjsPaz27aSdDAMhZz5UXjM45ZS8kvhWWETOmzEHgJklA28BNwJ1wGbgFnffGVXmJoKLv98EXAF8092vCPftAyLu3jTsdb8MnHT3r8X6IRQAozva1s13/2sv3/3tPo539vCRyh7uKj9I5YkqbO+L0N4cFEybBVmzg1v2nKHHpzyfEz4uDFoUakGITEtnCoBY5hKuBqrdvSZ8oSeAdcDOqDLrgMfCi8O/bGb5Zlbs7g0TUHc5B4XZafzNe5bwmWsW8v2XD/Dtl2r4972VRMov564/vpfrChqxfS8FU0/bm4JAOHkEjuwKHve0j/zCSSmQWXiGsAhDIjo4smZDyhSYoeQOvV3Q1wW93dDbCX3dwbaBx1iwcF9qZrxrK3JexRIAJUBt1PM6gr/yRytTAjQADvzKzBz4lrs/GFXubjO7FagC/tbdT1ss38zuAO4AWLBgQQzVFYCcjFT+8rpF3H51BT/cXMu3XtjD7Y9uYWlxLndd/0HWrL6A5JGWmehuD4JgIBzamoeet4Xb2pvhyM7geccxgv/EI0jPDYJhsCUxLDgyC4If6L6u8Ae5a4Qf65F+uLtOPeZsZfpivAJbcjosuCIYM1l4HRQv1yC6zHixdAF9FHivu/9F+PyTwGp3/3xUmZ8D/8fdXwqfPw/8nbtvMbP57l5vZnOB54DPu/uLZjYPaCL49fifQLG7//nZ6qIuoLHr7u3nx1sP8sCmPdQ0tZGXmcofLp7DtRcVce1FRczNzRjbC/f3BSHQ3hwVEE2nBsfgvqPB897OGF/cICUjaEmkZAQ/0oOP04Jprynpw7afrcxI5dOC+uz/LdRsgsPbg7fOyAvGTCqvhYXXw+xF6gKTaWs8XUB1QFnU81KgPtYy7j5wf8TMniHoUnrR3Qevnm5mDwE/i6EuMkZpKUl8LFLGRy4v5T92Hea5nYd54a1GfrYt6KV7R3Eu1y0JwmBleUHsaw8lJQd/zWfPCS6GMxr3oJuprQk6joIlDfuxjnqclHL+fnQvfl9wf/II7H0Ran4dnIi366fB9tzSodZB5TWQM+/81CvR9HQGy6fv2gBdJ4Zai9lFYUtyYGyqKNiuc1/GJZYWQArBIPANwEGCQeCPu/uOqDLvA+5maBD4PndfbWbZQJK7nwgfPwf8k7v/MnqMwMy+CFzh7jefrS5qAUwsd2dXwwleeKuRTbuPsGX/MXr7nVnpKbxr0WyuDQOhtCAr3lWND/dgnaaaTcFt74vQ2RLsm7t0KBDK3wXpOfGq5fTX2x18vzuehjd/Dl3Hg/Gm3Plhy7EJ+ntHPjYtZ+gPkIGAGAyL6O3hfeoYW7rT3Hingd4E/DPBNNBH3P0rZnYngLs/EE4D/RdgDcE00NvdvcrMFgLPhC+TAvybu38lfM3vAcsJuoD2AZ8dbdBYATC5TnT28Ns9zbzwViMv7G7kYEsHABfOnTXYVbS6sjBxF6Tr7wvPyn4h+MHa/7tgnCEpJVjmu/LaIBBKI5CcGufKTnF9vcGCiNufDlpZnS2QngfveD8s+3DwXQ58h+7B/raB7sXGoWBoaw6eD3981sCIbkUMa1EMD5EZEhg6EUzOibuzp/Ekm3Y38sJbjbyy9yjdvf1kpCZx1cLZQSAsmUvlnOx4VzV+ejqg9pWgq6hmE9S/Bngwxbb86rCFcG3QWtD4QRCgB34X/Ojv/EnwQ502C5bcFPzoL3r3xHTpuENna1RINEUFR/MIj5ugv2fk10rLgaKLgmt3FC8P7osuhuTptRijAkDGpaO7j5drwtbBW43sbWoDoHx21mDr4KpFs8lKm17/MCZU+9Fg8b6aTUErobk62J49NwiChdcFf9nml53lRWYYd6jbDNv/HXb8GE4egpRMWLIGLvkwLL4x/tNvBwJjYLLCYIuiKRgTOrwjaPl1nwjKp2TCBcuCMBgIhjkXTelQUADIhNrf3MaLbzWyaXcjv93TTEdPH2nJSayqLODai4q4bslcFs+dldiXthxc5ntTcGsLT3qffeFQd1HlHwbTYWcS96A1tOPp4Ee/tTaYebX4RrjkQ3DRGkifFe9anpv+fji6J/hc9VuD+0PboPtksD81Cy64dFgoLJ4yU4kVADJpunr7qNp3bHAw+a3DwT+K4ryMwdbB1YvnkJuRwP3i7sG5EwPdRftegp62YBZU8fJwMPnqoLsht3TwutHThnswhXb707DjGTi2NxgbWXRD0L2z5CbIyI13LSdWf1/QyhsIhIFQGDiZMjU7OMEwOhRmXxiX/7YKADlv6ls6eDHsKnrp7SZOdPWSnGSsXFAwOLNoaXFuYl/vuLcbDm4Zah0crBoauEzJgMJFwbkHcxYHPxqzFwfPswrjWevTNe4Of/Sfhqa3wJKDabLLPgwXv3/q1Xey9fcF38MpofAG9AYTKkjLOT0UChdOeigoACQuevr6ee1ACy+8dYQX3mpk+8HjAMyZlcY1i4uIVBSyvCyfi+bNIiWRr3vcdSL40Wh+G5r3BH9ZNr0Nx/aB9w2VyyyMCoWoW+HC8zdjpXlP8IO//Rk4sgOwYOXZSz4ES9cFs2lkSF8vNO0eCoWGrWEohCdEpucGy7fPX35qKExg96kCQKaExhNd/ObtYOzgpeomjrYFSzVkpSWzrCSPFWX5LC/LZ/mCfIrztDYPfT1BCDRXD4VC854gKE4ejipoweDy7KhwmBPeT4zBaR0AAAtoSURBVESXUsuBoGtn+9PBDxhA2RXBQO7SdZBbPL7XTzR9PdD45rBQ2B5MK4bgTPTiy05tKRRUjDkUFAAy5bg7+5vb2VrbwtbaFl6rbWFX/XG6+/oBmJebHoRBWQHLy/J5Z2ke2boW8pDO48HAZFP1UEAMtCAGBidh7F1Kx+uDQdwdTwczeQDmXx507yz9YGLNZjof+nqCRRkHuo4GQmFgiuqffh/e8cdjemkFgEwLXb197Kw/PhgKW2tb2N8cDKolGVw0LycMhaCVsHhuzsiL2iUy96B10PR2VDCEt6N7z9KltCgIhpOHg7/29/8WcJh3afCjf8mHoLAybh8rIfV2B5MH6l8LliuZNXdML6MAkGnraFs3r4cthK21Lbxe20JrR/BXUXZaMpeW5g22EpaX5XNB3sw4e3NS9PXAsf1hS2GgWym8P3loqFzRxUH3zrIPBwEh05oCQGYMd2dvUxuv17Ww9UAQCjsbjtPTF/y/fEFuxmALYaDrKKFPUItV5/EgCNKyY1vYT6YNBYDMaJ09fexsOD4YCFtrWzhw9NSuoxVhICwvK+DCubPUdSQJYzzLQYtMeRmpyVy+oIDLFwydVdt8smuwlfBabQs/39bA478Prls0Kz2FS0vyWL4gn8tK81lUlE1ZYVbiLnQnCUkBIDPW7FnpvPviebz74mDt/v5+Z29z2ymthIderKG3P2gFm8H8vEwq5mRRMTs7uM3JpmJ2lsJBZiQFgCSMpCRjUdEsFhXN4iMrS4Gg6+jNQyfY39zG3qY29jW1sa+5nZ+/0UBL+9AKkWcKh8o5QTikpygcZPpRAEhCy0hNHpw9NFxLezf7mtvDUBg9HCrnZFM+Oyu8VzjI1KcAEDmD/Kw0lmeljRoOe5vaghZEjOEQtB4UDhJ/CgCRMRgtHIJQaD8lHH62rWHw/AUIZifNz88cDITywmzKCjMpLciirCCLvKwEXj1VzgsFgMgEy89KY8WCNFYsOH2d/zOFw09fPzUcAHIyUigtyKK0IJOy8L60IJOywuBxTiIvry0TIqYAMLM1wDcJrgn8sLvfO2y/hftvIrgm8Kfc/dVw3z7gBNAH9A7MRTWzQuCHQAXBNYE/5u7Hxv2JRKaws4VDa3sPtcfaqTvWTt2xDuqOdVB7tJ0Dze38V3UT7d19w14rNQiF/KzBlkN0QOjkNxnNqP+HmFkycD9wI1AHbDazDe6+M6rYWmBxeLsCWB/eD7je3ZuGvfQ9wPPufq+Z3RM+//sxfxKRaS4vK5W8rDyWleSdts/dOdbeQ92xdmqPdgT3YVBUN55k01tH6OzpP+WY2dlpYashi9LBrqWhoNC0VonlT4TVQLW71wCY2RPAOiA6ANYBj3lwWvHLZpZvZsXu3nCW110HXBc+fhTYhAJAZERmRmF2GoXZabyz9PRxB3en6WT3YChEB8XOhuM8t/Pw4CqrA4py0gcDYiAYBloS8/MzNECdAGIJgBKgNup5Haf+dX+mMiVAA+DAr8zMgW+5+4NhmXkDAeHuDWY2tmXuRAQzoygnnaKc9FPOhh7Q3+80nuyi9mj7YNdS3bEO6lraeb22hV+80TB4QlzwejA3J/20VsPA/fz8TNJSEvgCPjNELAEw0oIpwxcQOluZq929PvyBf87M3nT3F2OtoJndAdwBsGDBglgPE5EoSUnGvNwM5uVmEKk4fX9fv3PoeCe1R9s5GI4/DHQzVe0/xk+3NdA3LCDm5WScMvYQHRDFeQqI6SCWAKgDoq/8UArUx1rG3Qfuj5jZMwRdSi8Chwe6icysGDgy0puHLYYHIVgMLob6isg5Sk4ySvIzKckf+SpsvX39HDreecrg9EBI/H7vUX6ytYOofCDJglVZRwqH0oIsivMzSE3kS4BOEbEEwGZgsZlVAgeBm4GPDyuzAbg7HB+4AmgNf9izgSR3PxE+fg/wT1HH3AbcG97/ZNyfRkQmRUpyUvgDnjXi/p6+fg61dkaNQXQMzmZ6Ze9RfjxCQBTnZVJyWjgEU16L8zIS+xrR58moAeDuvWZ2N/AswTTQR9x9h5ndGe5/ANhIMAW0mmAa6O3h4fOAZ4JZoqQA/+buvwz33Qs8aWafBg4AH52wTyUi51VqchJlhcHZzSPp6eunoaUzaorrUFC8vKeZhuMHiV6ZPjnJKMhKJTczlbzMVHIzgvuBW25mStTjqDJZqcxKSyFJS33HRNcDEJG46+7tp6G145QZTM1t3Rzv6KG1o4fjncF9a0cPxzt6TmlNDJdkkHuG0MjNHLZtWJmcjJQZ2fLQ9QBEZMpKS0mifHawiN5o+vudtu7ewUAIQqF3MCxGCoyG1g5awzLDp8MONys9JaplkcLcnAzm52cyPz+D+XmZFOdnUJKfSV5mKmHvxrSlABCRaSUpycjJSCUnI5XS02e8npW709XbPyw8ek4Lk6Hn3WytbeEX2xsGLzk6IDM1OQiF/MzBYBh4PLB9qp9spwAQkYRhZmSkJpORmsy83IyYj+vvd5rauqhv6aShpYODLR00tHZS39JBfWsnbx46QuOJrtOOK8xOozhvIBiC++L8TEryMyjOy2RuTnpcu5wUACIio0hKMubmZDA3J2PEFWABunr7ONzaRX1rBw2tHdS3hAHREkybfbmmmROdvacck5xkzMtJHwyGgW6m+fmZFOcFXU35WZPX1aQAEBGZAOkpySyYncWC2SPPhAI40dkz1HJo6aShNWxNtHSyra6FZ7d3njZGkZGaxPz8TP73hy7lyoWzJ7TOCgARkfNkYOzionk5I+7v73ea27rDFsRQK6KhtZP8Sbg+hAJARGSKSEoaWtNppEX/Jvz9Jv0dRERkSlIAiIgkKAWAiEiCUgCIiCQoBYCISIJSAIiIJCgFgIhIglIAiIgkqGl1PQAzawT2j/HwOUDTBFZnutP3MUTfxan0fZxqJnwf5e5eNHzjtAqA8TCzqpEuiJCo9H0M0XdxKn0fp5rJ34e6gEREEpQCQEQkQSVSADwY7wpMMfo+hui7OJW+j1PN2O8jYcYARETkVInUAhARkSgKABGRBJUQAWBma8xst5lVm9k98a5PvJhZmZn92sx2mdkOM/vreNdpKjCzZDN7zcx+Fu+6xJuZ5ZvZU2b2Zvj/yVXxrlO8mNkXw38n283scTOL/Sry08SMDwAzSwbuB9YCS4FbzGxpfGsVN73A37r7O4ArgbsS+LuI9tfArnhXYor4JvBLd78YuIwE/V7MrAT4KyDi7suAZODm+NZq4s34AABWA9XuXuPu3cATwLo41yku3L3B3V8NH58g+MddEt9axZeZlQLvAx6Od13izcxygWuAbwO4e7e7t8S3VnGVAmSaWQqQBdTHuT4TLhECoASojXpeR4L/6AGYWQWwAnglvjWJu38G/g7oj3dFpoCFQCPwnbBL7GEzy453peLB3Q8CXwMOAA1Aq7v/Kr61mniJEAA2wraEnvtqZrOAfwe+4O7H412feDGz9wNH3H1LvOsyRaQAlwPr3X0F0AYk5JiZmRUQ9BRUAvOBbDP7RHxrNfESIQDqgLKo56XMwKZcrMwsleDH/wfu/nS86xNnVwMfMLN9BF2D7zaz78e3SnFVB9S5+0Cr8CmCQEhEfwTsdfdGd+8BngbeFec6TbhECIDNwGIzqzSzNIKBnA1xrlNcmJkR9O/ucvf/F+/6xJu7/zd3L3X3CoL/L/7T3WfcX3mxcvdDQK2ZLQk33QDsjGOV4ukAcKWZZYX/bm5gBg6Ip8S7ApPN3XvN7G7gWYKR/EfcfUecqxUvVwOfBN4ws63htn9w941xrJNMLZ8HfhD+sVQD3B7n+sSFu79iZk8BrxLMnnuNGbgkhJaCEBFJUInQBSQiIiNQAIiIJCgFgIhIglIAiIgkKAWAiEiCUgCIiCQoBYCISIL6/9ZjMxKaDiKsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(r.history['loss'],label='loss')\n",
    "plt.plot(r.history['val_loss'],label='val_loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(r.history['accuracy'],label='acc')\n",
    "plt.plot(r.history['val_accuracy'],label='val_acc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC :  0.9800663702113223\n"
     ]
    }
   ],
   "source": [
    "# next lets calculate the auc score\n",
    "# first we want to make predictions\n",
    "p = model.predict(X)\n",
    "# then we want to calculate auc for each column\n",
    "# then take the mean\n",
    "aucs = []\n",
    "for i in range(p.shape[1]):\n",
    "    auc = roc_auc_score(Y[:,i],p[:,i])\n",
    "    aucs.append(auc)\n",
    "\n",
    "print('AUC : ',np.mean(aucs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we end this by discussing some classical NLP problems and how neural networks can be used to solve them\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Parts-of-Speech Tagging</h4>\n",
    "\n",
    "The first of these problems is determining parts of speech\n",
    "\n",
    "a part of speech tag is a category that you can assign to a word according to its syntactic function\n",
    "\n",
    "In english , the main parts of speech are :\n",
    "\n",
    "<ul>\n",
    "    <li>noun</li>\n",
    "    <li>pronoun</li>\n",
    "    <li>adjective</li>\n",
    "    <li>determiner</li>\n",
    "    <li>verb</li>\n",
    "    <li>adverb</li>\n",
    "    <li>preposition</li>\n",
    "    <li>conjunction</li>\n",
    "    <li>interjection</li>\n",
    "</ul>\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Data</h4>\n",
    "\n",
    "Here is an example of what the data looks like :\n",
    "\n",
    "```\n",
    "Confidence NN B-NP\n",
    "in IN B-PP\n",
    "the DT B-NP\n",
    "pound NN I-NP\n",
    "is VBZ B-VP\n",
    "widely RB I-VP\n",
    "expected VBN I-VP\n",
    "```\n",
    "so each token is on a seperate line and the tag is beside it , we are interested in the first 2 columns\n",
    "\n",
    "---\n",
    "\n",
    "<h4>F1</h4>\n",
    "\n",
    "we want to calculate the F1 score , which is the harmonic mean of the precision and recall\n",
    "\n",
    "$$F1 = 2 \\times \\frac{precision\\times recall}{precision+recall}$$\n",
    "\n",
    "$$Precision = \\frac{TP}{TP+FP}$$\n",
    "\n",
    "$$Recall = \\frac{TP}{TP+FN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>code</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from tensorflow.keras.layers import Input,Dense,LSTM,Embedding,SimpleRNN,GRU\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.metrics import Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first lets load in the data\n",
    "# an empty line marks the end of a sentence\n",
    "\n",
    "# first train data\n",
    "Xtrain = []\n",
    "Ytrain = []\n",
    "\n",
    "# none token represents something we would see in train but not in test\n",
    "word2idx = {'<none>':1}\n",
    "pos2idx = {'<pad>':0}\n",
    "# start from one since we are going to pad\n",
    "i = 2\n",
    "# this starts from 1 , so pad has its own class\n",
    "j = 1\n",
    "sent = []\n",
    "pos_tags = []\n",
    "\n",
    "for line in open('datasets/chunking/train.txt'):\n",
    "    line = line.rstrip().split()\n",
    "    if line == []:\n",
    "        Xtrain.append(sent)\n",
    "        Ytrain.append(pos_tags)\n",
    "        sent = []\n",
    "        pos_tags = []\n",
    "        continue\n",
    "\n",
    "    w,pos,_ = line\n",
    "    if w not in word2idx:\n",
    "        word2idx[w] = i\n",
    "        i+=1\n",
    "    if pos not in pos2idx:\n",
    "        pos2idx[pos] = j\n",
    "        j+=1\n",
    "    sent.append(word2idx[w])\n",
    "    pos_tags.append(pos2idx[pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# again for test\n",
    "Xtest = []\n",
    "Ytest = []\n",
    "\n",
    "none = word2idx['<none>']\n",
    "sent = []\n",
    "pos_tags = []\n",
    "\n",
    "for line in open('datasets/chunking/test.txt'):\n",
    "    line = line.rstrip().split()\n",
    "    if line == []:\n",
    "        Xtest.append(sent)\n",
    "        Ytest.append(pos_tags)\n",
    "        sent = []\n",
    "        pos_tags = []\n",
    "        continue\n",
    "\n",
    "    w,pos,_ = line\n",
    "    sent.append(word2idx.get(w,none))\n",
    "    pos_tags.append(pos2idx[pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next lets pad our sequences\n",
    "max_seq_length = max([len(sent) for sent in Xtrain])\n",
    "\n",
    "Xtrain = pad_sequences(Xtrain,maxlen=max_seq_length)\n",
    "Xtest = pad_sequences(Xtest,maxlen=max_seq_length)\n",
    "\n",
    "Ytrain = pad_sequences(Ytrain,maxlen=max_seq_length)\n",
    "Ytest = pad_sequences(Ytest,maxlen=max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Ytrain = shuffle(Xtrain,Ytrain)\n",
    "Xtest,Ytest = shuffle(Xtest,Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain = Ytrain.astype('int64')\n",
    "Ytest = Ytest.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V = word2idx + 1 for padding\n",
    "V = len(word2idx) + 1\n",
    "# number of clasess\n",
    "K = len(pos2idx)\n",
    "# embedding dim\n",
    "embedding_dim = 10\n",
    "epochs = 20\n",
    "M = 10\n",
    "batch_size = 128\n",
    "learning_rate = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets create our model\n",
    "\n",
    "i = Input(shape=(Xtrain.shape[1]))\n",
    "embedding = Embedding(\n",
    "    V,\n",
    "    embedding_dim,\n",
    "    weights = [np.random.randn(V,embedding_dim)],\n",
    "    input_length=max_seq_length,\n",
    "    trainable = True\n",
    ")\n",
    "\n",
    "x = embedding(i)\n",
    "x = SimpleRNN(M,return_sequences=True)(x)\n",
    "o = Dense(K,activation='softmax')(x)\n",
    "model = Model(inputs = i,outputs=o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to make our own accuracy function \n",
    "class accuracy(Metric):\n",
    "\n",
    "    def __init__(self, name='accuracy', **kwargs):\n",
    "        super(accuracy, self).__init__(name=name, **kwargs)\n",
    "        self.right = self.add_weight(name='right', initializer='zeros')\n",
    "        self.wrong = self.add_weight(name='wrong', initializer='zeros')\n",
    "\n",
    "    def update_state(self, T,Y, sample_weight=None):\n",
    "        # T is of shape NxT\n",
    "        # Y is of shape NxTxK\n",
    "        Y = tf.math.argmax(Y,axis=-1) # so now Y is of shape NxT\n",
    "        # we need to filter out padding , remember those have a class of 0\n",
    "        T = T[Y>0]\n",
    "        Y = Y[Y>0]\n",
    "        # from here it is the cross entropy\n",
    "        right = tf.cast(T==Y,tf.float32)\n",
    "        wrong = tf.cast(T!=Y,tf.float32)\n",
    "        tf.math.reduce_sum(right)\n",
    "        self.right.assign(self.right+tf.math.reduce_sum(right)) \n",
    "        self.wrong.assign(self.wrong+tf.math.reduce_sum(wrong)) \n",
    "        \n",
    "    \n",
    "    def result(self):\n",
    "        return self.right/(self.right+self.wrong)\n",
    "    \n",
    "    def reset_states(self):\n",
    "        self.right.assign(0)\n",
    "        self.wrong.assign(0)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=Adam(learning_rate=learning_rate),\n",
    "    metrics = [accuracy()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "70/70 [==============================] - 4s 38ms/step - loss: 2.4584 - accuracy: 0.0774 - val_loss: 0.8190 - val_accuracy: 0.3873\n",
      "Epoch 2/20\n",
      "70/70 [==============================] - 1s 20ms/step - loss: 0.7287 - accuracy: 0.4564 - val_loss: 0.5054 - val_accuracy: 0.5722\n",
      "Epoch 3/20\n",
      "70/70 [==============================] - 1s 20ms/step - loss: 0.4285 - accuracy: 0.6475 - val_loss: 0.3568 - val_accuracy: 0.7258\n",
      "Epoch 4/20\n",
      "70/70 [==============================] - 1s 20ms/step - loss: 0.2782 - accuracy: 0.7924 - val_loss: 0.2859 - val_accuracy: 0.8078\n",
      "Epoch 5/20\n",
      "70/70 [==============================] - 1s 21ms/step - loss: 0.1942 - accuracy: 0.8636 - val_loss: 0.2492 - val_accuracy: 0.8383\n",
      "Epoch 6/20\n",
      "70/70 [==============================] - 1s 20ms/step - loss: 0.1452 - accuracy: 0.8934 - val_loss: 0.2297 - val_accuracy: 0.8562\n",
      "Epoch 7/20\n",
      "70/70 [==============================] - 1s 20ms/step - loss: 0.1149 - accuracy: 0.9149 - val_loss: 0.2198 - val_accuracy: 0.8721\n",
      "Epoch 8/20\n",
      "70/70 [==============================] - 1s 21ms/step - loss: 0.0940 - accuracy: 0.9304 - val_loss: 0.2152 - val_accuracy: 0.8799\n",
      "Epoch 9/20\n",
      "70/70 [==============================] - 1s 21ms/step - loss: 0.0787 - accuracy: 0.9411 - val_loss: 0.2120 - val_accuracy: 0.8863\n",
      "Epoch 10/20\n",
      "70/70 [==============================] - 1s 21ms/step - loss: 0.0683 - accuracy: 0.9487 - val_loss: 0.2109 - val_accuracy: 0.8916\n",
      "Epoch 11/20\n",
      "70/70 [==============================] - 1s 21ms/step - loss: 0.0598 - accuracy: 0.9541 - val_loss: 0.2118 - val_accuracy: 0.8961\n",
      "Epoch 12/20\n",
      "70/70 [==============================] - 1s 21ms/step - loss: 0.0531 - accuracy: 0.9586 - val_loss: 0.2125 - val_accuracy: 0.8985\n",
      "Epoch 13/20\n",
      "70/70 [==============================] - 1s 20ms/step - loss: 0.0487 - accuracy: 0.9612 - val_loss: 0.2126 - val_accuracy: 0.9009\n",
      "Epoch 14/20\n",
      "70/70 [==============================] - 1s 21ms/step - loss: 0.0446 - accuracy: 0.9636 - val_loss: 0.2161 - val_accuracy: 0.9026\n",
      "Epoch 15/20\n",
      "70/70 [==============================] - 1s 21ms/step - loss: 0.0419 - accuracy: 0.9654 - val_loss: 0.2162 - val_accuracy: 0.9035\n",
      "Epoch 16/20\n",
      "70/70 [==============================] - 2s 22ms/step - loss: 0.0384 - accuracy: 0.9684 - val_loss: 0.2168 - val_accuracy: 0.9049\n",
      "Epoch 17/20\n",
      "70/70 [==============================] - 1s 21ms/step - loss: 0.0360 - accuracy: 0.9702 - val_loss: 0.2193 - val_accuracy: 0.9058\n",
      "Epoch 18/20\n",
      "70/70 [==============================] - 1s 21ms/step - loss: 0.0340 - accuracy: 0.9711 - val_loss: 0.2195 - val_accuracy: 0.9058\n",
      "Epoch 19/20\n",
      "70/70 [==============================] - 2s 23ms/step - loss: 0.0325 - accuracy: 0.9721 - val_loss: 0.2224 - val_accuracy: 0.9063\n",
      "Epoch 20/20\n",
      "70/70 [==============================] - 1s 21ms/step - loss: 0.0317 - accuracy: 0.9737 - val_loss: 0.2234 - val_accuracy: 0.9068\n"
     ]
    }
   ],
   "source": [
    "r = model.fit(\n",
    "    Xtrain,Ytrain,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data = (Xtest,Ytest)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(r.history['loss'],label='loss')\n",
    "plt.plot(r.history['val_loss'],label='val_loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(r.history['accuracy'],label='acc')\n",
    "plt.plot(r.history['val_accuracy'],label='val_acc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score :  0.9738424217244399\n"
     ]
    }
   ],
   "source": [
    "p = model.predict(Xtest)\n",
    "Ypred = np.argmax(p,axis=-1)\n",
    "f1 = f1_score(Ytest.flatten(),Ypred.flatten(),average='weighted')\n",
    "print('f1-score : ',f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Math</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next we discuss another classical NLP problem , Named Entity Recognition\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Named Entity Recognition</h4>\n",
    "\n",
    "This is similar to POS tagging , where we want to tag each token in a sentence\n",
    "\n",
    "However with NER we are interested in what type of entity the token is , for ex :\n",
    "\n",
    "<ul>\n",
    "    <li>person</li>\n",
    "    <li>company</li>\n",
    "    <li>location</li>\n",
    "</ul>\n",
    "\n",
    "so they are all proper nouns\n",
    "\n",
    "one difference between this problem and POS tagging is that the NER data is very imbalanced\n",
    "\n",
    "by that we mean that most words in the dataset are not entities at all , they are just regular words\n",
    "\n",
    "we can already see , for example , how most of the words written in this sentence are not entities (not a person's/company's name , location ...) , but just regular words\n",
    "\n",
    "That is something we may/may not need to account for (we will see in the code)\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Easy NER</h4>\n",
    "\n",
    "Now what is one way to make NER easy ?\n",
    "\n",
    "In Classical NER solutions , they would use the fact that the first letter was capitalised to tell if it was a Named Entity or not  but we can see how this may be considered cheating\n",
    "\n",
    "we would rather use the structure of the sentence than the fact that it starts with a capital letter to determine whether its a named entity t\n",
    "\n",
    "in modern times the capital letter approach wouldnt work well anyway\n",
    "\n",
    "well , on sites liek twitter and in chat messages , people often dont capitalise proper nouns\n",
    "\n",
    "so we cant use rules like : if a word starts with a capital letter , then it has a higher probability of being a proper noun\n",
    "\n",
    "at that point we are not even doing machine learning , we are doing regular programming\n",
    "\n",
    "because of this , in our code , we are going to lowercase everything first\n",
    "\n",
    "we also dont want to consider @usernames as actual names since that would also be regular programming (in which we could achieve 100% very easily)\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Data</h4>\n",
    "\n",
    "the data can be found <a href = 'https://github.com/aritter/twitter_nlp/tree/master/data/annotated'>here</a>\n",
    "\n",
    "the file we are interested in is ner.txt\n",
    "\n",
    "a good idea is to establish a baseline first , for example using logistic regression (but lets be lazy :) )\n",
    "\n",
    "---\n",
    "\n",
    "<h4>Sample</h4>\n",
    "\n",
    "```\n",
    "@paulwalk\tO\n",
    "It\tO\n",
    "'s\tO\n",
    "the\tO\n",
    "view\tO\n",
    "from\tO\n",
    "where\tO\n",
    "I\tO\n",
    "'m\tO\n",
    "living\tO\n",
    "for\tO\n",
    "two\tO\n",
    "weeks\tO\n",
    ".\tO\n",
    "Empire\tB-facility\n",
    "State\tI-facility\n",
    "Building\tI-facility\n",
    "=\tO\n",
    "ESB\tB-facility\n",
    "```\n",
    "Its again a very simple format , again each token is on a single line and the tag is beside it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>code</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the code should look pretty similar to before\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from tensorflow.keras.layers import Input,Dense,LSTM,Embedding,SimpleRNN,GRU\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.metrics import Metric\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first lets load in the data\n",
    "# an empty line marks the end of a sentence\n",
    "\n",
    "# first train data\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "# none token represents something we would see in train but not in test\n",
    "word2idx = {'<none>':1}\n",
    "ne2idx = {'<pad>':0}\n",
    "# start from one since we are going to pad\n",
    "i = 2\n",
    "# this starts from 1 , so pad has its own class\n",
    "j = 1\n",
    "sent = []\n",
    "nes = []\n",
    "\n",
    "for line in open('datasets/ner.txt'):\n",
    "    line = line.rstrip().split()\n",
    "    if line == []:\n",
    "        X.append(sent)\n",
    "        Y.append(nes)\n",
    "        sent = []\n",
    "        nes = []\n",
    "        continue\n",
    "\n",
    "    w,ne = line\n",
    "    if w not in word2idx:\n",
    "        word2idx[w] = i\n",
    "        i+=1\n",
    "    if ne not in ne2idx:\n",
    "        ne2idx[ne] = j\n",
    "        j+=1\n",
    "    sent.append(word2idx[w])\n",
    "    nes.append(ne2idx[ne])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad sequences\n",
    "# next lets pad our sequences\n",
    "max_seq_length = max([len(sent) for sent in X])\n",
    "\n",
    "X = pad_sequences(X,maxlen=max_seq_length)\n",
    "Y = pad_sequences(Y,maxlen=max_seq_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Xtest,Ytrain,Ytest = train_test_split(X,Y,test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain = Ytrain.astype('int64')\n",
    "Ytest = Ytest.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V = word2idx + 1 for padding\n",
    "V = len(word2idx) + 1\n",
    "# number of clasess\n",
    "K = len(pos2idx)\n",
    "# embedding dim\n",
    "embedding_dim = 10\n",
    "epochs = 20\n",
    "M = 10\n",
    "batch_size = 128\n",
    "learning_rate = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets create our model\n",
    "\n",
    "i = Input(shape=(Xtrain.shape[1]))\n",
    "embedding = Embedding(\n",
    "    V,\n",
    "    embedding_dim,\n",
    "    weights = [np.random.randn(V,embedding_dim)],\n",
    "    input_length=max_seq_length,\n",
    "    trainable = True\n",
    ")\n",
    "\n",
    "x = embedding(i)\n",
    "x = SimpleRNN(M,return_sequences=True)(x)\n",
    "o = Dense(K,activation='softmax')(x)\n",
    "model = Model(inputs = i,outputs=o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to make our own accuracy function \n",
    "class accuracy(Metric):\n",
    "\n",
    "    def __init__(self, name='accuracy', **kwargs):\n",
    "        super(accuracy, self).__init__(name=name, **kwargs)\n",
    "        self.right = self.add_weight(name='right', initializer='zeros')\n",
    "        self.wrong = self.add_weight(name='wrong', initializer='zeros')\n",
    "\n",
    "    def update_state(self, T,Y, sample_weight=None):\n",
    "        # T is of shape NxT\n",
    "        # Y is of shape NxTxK\n",
    "        Y = tf.math.argmax(Y,axis=-1) # so now Y is of shape NxT\n",
    "        # we need to filter out padding , remember those have a class of 0\n",
    "        T = T[Y>0]\n",
    "        Y = Y[Y>0]\n",
    "        # from here it is the cross entropy\n",
    "        right = tf.cast(T==Y,tf.float32)\n",
    "        wrong = tf.cast(T!=Y,tf.float32)\n",
    "        tf.math.reduce_sum(right)\n",
    "        self.right.assign(self.right+tf.math.reduce_sum(right)) \n",
    "        self.wrong.assign(self.wrong+tf.math.reduce_sum(wrong)) \n",
    "        \n",
    "    \n",
    "    def result(self):\n",
    "        return self.right/(self.right+self.wrong)\n",
    "    \n",
    "    def reset_states(self):\n",
    "        self.right.assign(0)\n",
    "        self.wrong.assign(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=Adam(learning_rate=learning_rate),\n",
    "    metrics = [accuracy()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "13/13 [==============================] - 2s 48ms/step - loss: 3.1353 - accuracy: 0.1504 - val_loss: 1.6168 - val_accuracy: 0.8683\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 1.2660 - accuracy: 0.9249 - val_loss: 0.6463 - val_accuracy: 0.9511\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.5952 - accuracy: 0.9464 - val_loss: 0.4249 - val_accuracy: 0.9522\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.4036 - accuracy: 0.9474 - val_loss: 0.3076 - val_accuracy: 0.9516\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.3005 - accuracy: 0.9480 - val_loss: 0.2531 - val_accuracy: 0.9512\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.2649 - accuracy: 0.9444 - val_loss: 0.2267 - val_accuracy: 0.9507\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.2271 - accuracy: 0.9477 - val_loss: 0.2117 - val_accuracy: 0.9506\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.2117 - accuracy: 0.9482 - val_loss: 0.2015 - val_accuracy: 0.9506\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.2172 - accuracy: 0.9410 - val_loss: 0.1942 - val_accuracy: 0.9506\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.1966 - accuracy: 0.9439 - val_loss: 0.1882 - val_accuracy: 0.9504\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.1832 - accuracy: 0.9455 - val_loss: 0.1840 - val_accuracy: 0.9504\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.1727 - accuracy: 0.9462 - val_loss: 0.1788 - val_accuracy: 0.9504\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.1736 - accuracy: 0.9433 - val_loss: 0.1754 - val_accuracy: 0.9503\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.1531 - accuracy: 0.9472 - val_loss: 0.1715 - val_accuracy: 0.9505\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.1528 - accuracy: 0.9451 - val_loss: 0.1691 - val_accuracy: 0.9505\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.1395 - accuracy: 0.9477 - val_loss: 0.1666 - val_accuracy: 0.9505\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.1397 - accuracy: 0.9454 - val_loss: 0.1656 - val_accuracy: 0.9506\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.1365 - accuracy: 0.9440 - val_loss: 0.1648 - val_accuracy: 0.9503\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.1305 - accuracy: 0.9453 - val_loss: 0.1644 - val_accuracy: 0.9506\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.1194 - accuracy: 0.9489 - val_loss: 0.1640 - val_accuracy: 0.9509\n"
     ]
    }
   ],
   "source": [
    "r = model.fit(\n",
    "    Xtrain,Ytrain,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data = (Xtest,Ytest)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(r.history['loss'],label='loss')\n",
    "plt.plot(r.history['val_loss'],label='val_loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(r.history['accuracy'],label='acc')\n",
    "plt.plot(r.history['val_accuracy'],label='val_acc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score :  0.963112475012743\n"
     ]
    }
   ],
   "source": [
    "p = model.predict(Xtest)\n",
    "Ypred = np.argmax(p,axis=-1)\n",
    "f1 = f1_score(Ytest.flatten(),Ypred.flatten(),average='weighted')\n",
    "print('f1-score : ',f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
